{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "DIM = 56\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "#     fake_data = fake_data.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 56 56\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 56 56\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 56 56\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 28 28\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        out = out.view(x.size(0), 1, 56, 56)\n",
    "        out = self.br(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "d.weight_init(.0, 0.02)\n",
    "g.weight_init(.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_wgan_gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"cnn_wgan_img\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5064425382643f3a422c279a613f4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 5.225162, g_loss: -0.930020, real_scores: 0.113600, fake_scores: 0.355711\n",
      "Finish Epoch [1/100], D Loss: 804.437692, G Loss: -71.471367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2bda93597cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0md_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mg_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_img = img.cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z).detach()\n",
    "        fake_out = d(fake_img)\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(d, real_img, fake_img)\n",
    "        \n",
    "        d_loss = d_loss_fake - d_loss_real + gradient_penalty\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        #######################\n",
    "        w_dist = d_loss_fake - d_loss_real\n",
    "        \n",
    "        ########## G ##########\n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = fake_out.mean()\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward(mone)\n",
    "        g_loss = -g_loss\n",
    "        g_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "            writer.add_scalar('Wasserstein Distance', w_dist.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * BATCH_SIZE, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/wgan_gp_discriminator.pt')\n",
    "torch.save(g.state_dict(), './ser/wgan_gp_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEKlJREFUeJzt3XuMVGWax/HvIwJeg6CILq2iLkFFHRiJaVQMXiaCO8gY14mGuK4aMOq6oIYdWCRGY4KbNboab+kMCm7wBgNCiOI4gOJ6QS7eYRB0VoVwM65XEEGf/aPOeX1buujq6rr0Ofw+Saefequ6znP6NA9vvec97zF3R0RE8mOfeicgIiKVpcIuIpIzKuwiIjmjwi4ikjMq7CIiOaPCLiKSMyrsIiI5067CbmbDzGyNma0zswmVSkpERMpn5V6gZGadgA+B3wDrgWXA5e6+qnLpiYhIW+3bjp89HVjn7h8DmNlTwEigaGE3M13mKiLSdp+7e89SX9yeoZjewGfR4/VJWzNmNsbMlpvZ8nZsS0Rkb/ZJW17cnh57Sdy9CWgC9dhFRGqhPT32DcBR0eOGpE1EROqoPYV9GdDXzI41sy7AZcC8yqQlIiLlKnsoxt13mdm/AC8AnYBH3f2DimUmIiJlKXu6Y1kb0xi7iEg5Vrj7oFJfrCtPRURyRoVdRCRnVNhFRHJGhV1EJGdU2EVEckaFXUQkZ1TYRURyRoVdRCRnVNhFRHJGhV1EJGdU2EVEckaFXUQkZ6p+ow3JvwcffDDEN9xwQx0zERFQj11EJHdU2EVEckZDMVKW0047LcTDhg2rYyYipbnoootCPGvWrBDvu+/PZXDSpEkATJkypXaJVYF67CIiOaPCLiKSMxqKKdHgwYMBiG8l+MYbb4S4U6dOIf7xxx9rl1idrFixIsRdunSpyjYmT54c4i+++CLE8SwcaV3//v1D3K9fvxDPnj27HunU3IUXXghAU1NTi8/H/6bPOeccYC8YijGzR81si5m9H7X1MLMXzWxt8r17ddMUEZFSldJjnwY8ADwetU0AFrr7XWY2IXn8h8qnV3nLli0Lcd++fYHmPc64521mu8VxW/w//Y4dO0K8dOlSAM4777xKpd2h7dq1q2Lvdfjhh4f4rLPOCvETTzxRsW3UwtSpUwE4//zzQ9uWLVtCfNxxx4X4oIMOApr/bcV/T6tXrw7xm2++CUCvXr1C2yuvvBLihoaGEI8aNQqAnTt3tpjj3tJjHz9+PPDz7wNg4cKFIZ47d26I4083WdZqj93dlwBf/KJ5JDA9iacDv6twXiIiUqZyx9h7ufvGJN4E9Cr2QjMbA4wpczsiItJG7T556u5uZr6H55uAJoA9va7SFi1aFOKBAweG+OCDDw5x+hE1Hkr4+OOPQ3z77beHeJ99Ch9uhgwZEtrOPPPMEB9xxBEh/umnn9qVe9a8/vrrFXuveOji+eefD/Gzzz5bsW1U0ujRo0M8YcKEEHfvXjjttP/++4e2Hj16hLhr164hTv+24pPuBxxwQIjjv984To0YMSLEnTt3DnH6971t27bQFs/ZzrOHH344xOkJ0WJGjhwZ4nQYNevKne642cyOBEi+b2nl9SIiUiPlFvZ5wJVJfCUwdw+vFRGRGmr1c5mZPQkMBQ4zs/XAbcBdwDNmdg3wCfD7aibZkpNPPjnEV199dYiPPvpoAL7++uvQFl/yHn8U7datGwDPPfdcydt9+umnW2z/5ptvQjx06FAAZs6cGdouvfTSkreRBfFc8k8//bRi75vO+gDYvn17iL/66quKbaOS7r333hCnQyrw8wyXeJjv888/D3E8RJMO3cW/x3g4Lx4ePOOMMwA49NBDQ1s8kyt+j3Qb8TBhPJMrz8oduot/l1nWamF398uLPLV3zOUTEckYLSkgIpIzmTpFPmPGjBBffPHFIf7uu+9CfMoppwCwadOmqudz3XXXhXi//fYLcfqRfMCAAVXPoV5++OGHEL/00ksVe9/bbrstxFdccUXF3rdaWhpSAdi4sTAb+J577glt8SyfNWvWVD23dAgnHl6Ih7fy7IUXXij5tfFFSZW82K6e1GMXEcmZTPXY45Og8YmqJUuWhLiSPfV43vH1118PwEMPPRTa0sWFoHmvKO25xXnlTby/N998c4gXLFhQ1vul62Cnl9d3ZIsXLw5xvAxALD2JX0/xv5HU5s2b65BJxzZ//vwQ5+XeAuqxi4jkjAq7iEjOZGooJr5M+JhjjgnxuHHjqrK9eA3wO++8c7fnv//++xDH84O3bt0KND+5mjeVWAVv5cqVIT7wwAMBuOWWW1p8bboSJ8DatWvbve32iJeSiI/7hg0b6pFOUT179tytLb6HgBT07t07xLU4qV0L6rGLiOSMCruISM5kaijm1ltvrXcKzTQ2NoY4vjFCeoONeK533sRzsuMlHR555JEQpzeIuO+++0JbfIODeOZIOt87viYhvplER1qVMD6ucV59+vSpQzbNxauapnPs41UjH3jggZrn1BHFw2bFZjZlmXrsIiI5o8IuIpIzHefzbUbEMw3iVfPmzJkT4lWrVtU0p3q4++67QxwvpxDPBLr88sL6cVdddVVoi2e3pJfdA7z88ssAvPrqqy1uryNdWNPRLqK64IILQpyu/hiLL69/7bXXapJTRxcv//Dll1/WMZPqUI9dRCRn1GNvo/iO8PEl29OmTatDNh1DPMe/pfn+sfjEY7zkQrGeurQu/kQU3xovPWl644031jynji6+NWF63UmeqMcuIpIzKuwiIjljtbxVlpll/r5c8TIC8fzX+KOdFLdu3boQ9+vXL8TxXGtpXbyi5pQpU0Icz6v/8MMPATjxxBNrl1hGfPvttyG+5JJLQtyWddxrbIW7Dyr1xa322M3sKDNbbGarzOwDMxubtPcwsxfNbG3yvXt7shYRkcooZShmF3CLu58ENAI3mNlJwARgobv3BRYmj0VEpM5KuZn1RmBjEn9jZquB3sBIYGjysunAS8AfqpJlB5B+XOvSpUto62ir+XVUTU1NIb7//vtDrOGXths8eDDQ/BaC8UyYeH52evMS2V08dNqBh1/K1qbpjmbWBxgILAV6JUUfYBPQq8jPjAHGlJ+iiIi0RcmzYszsIOBPwDh3/zp+zgtnYFs8MeruTe4+qC0D/yIiUr6Seuxm1plCUZ/h7rOT5s1mdqS7bzSzI4Et1UqyI5gwYfdTCKNHj65DJtnT0NAQ4nhWjLRduvRCfHFcPLMtvufv7NmzkZbt3Lmz3ilUVSmzYgyYCqx293uip+YBVybxlcDcyqcnIiJtVUqP/UzgCuA9M3s7aft34C7gGTO7BvgE+H11UuwY0jnXce9owYIF9UonU957770Q5/FEVbXFy1ik89TjE8/btm0LcfzpSJqbP39+iOt9e8VqK2VWzP8AxVaiP6+y6YiISHtpSQERkZzR6o57MHPmzBCna3DHSwpIaeLhqzyupFdtJ5xwwm5t8e807ycCKyW9BgDg8ccfr2Mm1aceu4hIzqiwi4jkjIZifqGxsTHEw4cPD3H60XfUqFE1zynrRowYEeI1a9aE+LHHHqtHOpkwefLkEMcrNqazYeLhl/Xr19cusQyLlxG46aab6phJ9anHLiKSMyrsIiI5o6GYX1i0aFGI449u6cL8c+bMqXlOWdWtWzeg+VDCO++8U690Orx4mK9///4hjmfApPeMjYdi5s2bV4PssuvUU08FoFOnTnXOpHbUYxcRyRn12IEhQ4aEuNgt7saPH1+rdHJj7NixALz11luhbeXKlfVKp8M7++yzQ3zYYYeFOL4HQNrr3LFjR2jT73TP0sXQ4qUX8k49dhGRnFFhFxHJGQ3FALt27WqxPf7oFt/eTUpzxx131DuFTNm+fXuI42UE4lvfFVbRbr5ipk7o79nSpUuBvevEvXrsIiI5o8IuIpIzGooBjj/++BDHd3lftmxZPdKRvdS4ceNCHA8bXHvttSFevHgxABMnTqxdYhm3Ny4Doh67iEjOqLCLiOSMxZcrt/gCs/2AJUBXCkM3s9z9NjM7FngKOBRYAVzh7j+08l573piIiLRkhbsPKvXFpfTYdwDnuvuvgAHAMDNrBP4DuNfd/x74P+CacrIVEZHKarWwe8G3ycPOyZcD5wKzkvbpwO+qkqGIiLRJSWPsZtbJzN4GtgAvAh8BX7p7emXPeqB3dVIUEZG2KKmwu/uP7j4AaABOB3a/u24RZjbGzJab2fIycxQRkTZo06wYd/8SWAwMBg4xs3QefAOwocjPNLn7oLYM/IuISPlaLexm1tPMDkni/YHfAKspFPh/TF52JTC3WkmKiEjpSrny9Ehgupl1ovAfwTPuPt/MVgFPmdmdwFvA1CrmKSIiJWp1HntFN2a2FfgO+LxmG62tw9C+ZZH2LZv2pn07xt17lvrDNS3sAGa2PK/j7dq3bNK+ZZP2rTgtKSAikjMq7CIiOVOPwp7nWxFp37JJ+5ZN2rciaj7GLiIi1aWhGBGRnFFhFxHJmZoWdjMbZmZrzGydmU2o5bYrzcyOMrPFZrbKzD4ws7FJew8ze9HM1ibfu9c713IkC7+9ZWbzk8fHmtnS5Ng9bWZd6p1jOczsEDObZWZ/NbPVZjY4R8fspuRv8X0ze9LM9svqcTOzR81si5m9H7W1eJys4P5kH981s1/XL/PWFdm3/0z+Jt81sznp1f7JcxOTfVtjZheUso2aFfbkytUHgeHAScDlZnZSrbZfBbuAW9z9JKARuCHZnwnAQnfvCyxMHmfRWApLR6Tysv7+fcACdz8B+BWFfcz8MTOz3sC/AoPc/WSgE3AZ2T1u04Bhv2grdpyGA32TrzHAwzXKsVzT2H3fXgROdvdTgQ+BiQBJTbkM6J/8zENJLd2jWvbYTwfWufvHyZ2WngJG1nD7FeXuG919ZRJ/Q6FA9KawT9OTl2VynXozawD+Afhj8tjIwfr7ZtYNOJtk+Qt3/yFZ2C7zxyyxL7B/sjjfAcBGMnrc3H0J8MUvmosdp5HA48m9I96gsEDhkbXJtO1a2jd3/3O0DPobFBZWhMK+PeXuO9z9b8A6CrV0j2pZ2HsDn0WPc7OGu5n1AQYCS4Fe7r4xeWoT0KtOabXHfwH/BvyUPD6UfKy/fyywFXgsGWb6o5kdSA6OmbtvAO4GPqVQ0L+icMvKPBy3VLHjlLfacjXwfBKXtW86edpOZnYQ8CdgnLt/HT/nhbmkmZpPama/Bba4+4p651IF+wK/Bh5294EU1i1qNuySxWMGkIw3j6Twn9ffAQey+8f93MjqcWqNmU2iMMw7oz3vU8vCvgE4KnpcdA33rDCzzhSK+gx3n500b04/Bibft9QrvzKdCVxkZv9LYbjsXArj0iWtv9/BrQfWu/vS5PEsCoU+68cM4Hzgb+6+1d13ArMpHMs8HLdUseOUi9piZv8M/BYY5T9fYFTWvtWysC8D+iZn6btQOCEwr4bbr6hk3HkqsNrd74memkdhfXrI4Dr17j7R3RvcvQ+FY7TI3UeRg/X33X0T8JmZ9UuazgNWkfFjlvgUaDSzA5K/zXTfMn/cIsWO0zzgn5LZMY3AV9GQTSaY2TAKw58Xufu26Kl5wGVm1tXMjqVwgvjNVt/Q3Wv2BVxI4YzvR8CkWm67CvtyFoWPgu8CbydfF1IYj14IrAX+AvSod67t2MehwPwkPi75g1oHzAS61ju/MvdpALA8OW7PAt3zcsyA24G/Au8D/w10zepxA56kcK5gJ4VPWtcUO06AUZhx9xHwHoWZQXXfhzbu2zoKY+lpLXkkev2kZN/WAMNL2YaWFBARyRmdPBURyRkVdhGRnFFhFxHJGRV2EZGcUWEXEckZFXYRkZxRYRcRyZn/BzRovYTkMO+iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
