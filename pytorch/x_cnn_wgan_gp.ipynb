{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "DIM = 56\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "#     fake_data = fake_data.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 56 56\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 56 56\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 56 56\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 28 28\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        out = out.view(x.size(0), 1, 56, 56)\n",
    "        out = self.br(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "d.weight_init(.0, 0.02)\n",
    "g.weight_init(.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_wgan_gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"save_images/cnn_wgan_img\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fca87dc0af45798b0891252fe4ead9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 3.854897, g_loss: -0.631798, real_scores: 0.608996, fake_scores: 0.631798\n",
      "Finish Epoch [1/100], D Loss: 798.145375, G Loss: -70.545018\n",
      "Epoch [2/100], Step:  38400, d_loss: 2.890842, g_loss: -0.842648, real_scores: 0.746383, fake_scores: 0.842648\n",
      "Finish Epoch [2/100], D Loss: 227.671858, G Loss: -37.719078\n",
      "Epoch [3/100], Step:  38400, d_loss: 1.624478, g_loss: -0.387505, real_scores: 0.240072, fake_scores: 0.387505\n",
      "Finish Epoch [3/100], D Loss: 70.181841, G Loss: -24.716593\n",
      "Epoch [4/100], Step:  38400, d_loss: 0.149170, g_loss: -0.499402, real_scores: 0.490075, fake_scores: 0.499402\n",
      "Finish Epoch [4/100], D Loss: 27.153447, G Loss: -18.164344\n",
      "Epoch [5/100], Step:  38400, d_loss: 0.018105, g_loss: -0.637981, real_scores: 0.708996, fake_scores: 0.637981\n",
      "Finish Epoch [5/100], D Loss: 13.465449, G Loss: -13.772727\n",
      "Epoch [6/100], Step:  38400, d_loss: -0.059894, g_loss: -0.483419, real_scores: 0.546689, fake_scores: 0.483419\n",
      "Finish Epoch [6/100], D Loss: 7.138488, G Loss: -10.784952\n",
      "Epoch [7/100], Step:  38400, d_loss: 2.010977, g_loss: -0.135927, real_scores: 0.181940, fake_scores: 0.135927\n",
      "Finish Epoch [7/100], D Loss: 4.168118, G Loss: -9.198087\n",
      "Epoch [8/100], Step:  38400, d_loss: -0.071936, g_loss: -0.453252, real_scores: 0.532768, fake_scores: 0.453252\n",
      "Finish Epoch [8/100], D Loss: 2.554656, G Loss: -8.123498\n",
      "Epoch [9/100], Step:  38400, d_loss: 0.000807, g_loss: -0.269278, real_scores: 0.337742, fake_scores: 0.269278\n",
      "Finish Epoch [9/100], D Loss: 2.030994, G Loss: -7.091865\n",
      "Epoch [10/100], Step:  38400, d_loss: -0.065128, g_loss: -0.569190, real_scores: 0.644442, fake_scores: 0.569190\n",
      "Finish Epoch [10/100], D Loss: 1.575199, G Loss: -6.440494\n",
      "Epoch [11/100], Step:  38400, d_loss: -0.067321, g_loss: -0.497306, real_scores: 0.569612, fake_scores: 0.497306\n",
      "Finish Epoch [11/100], D Loss: 1.139547, G Loss: -5.837926\n",
      "Epoch [12/100], Step:  38400, d_loss: -0.078041, g_loss: -0.530130, real_scores: 0.612381, fake_scores: 0.530130\n",
      "Finish Epoch [12/100], D Loss: 0.914719, G Loss: -5.373822\n",
      "Epoch [13/100], Step:  38400, d_loss: -0.073858, g_loss: -0.531437, real_scores: 0.608632, fake_scores: 0.531437\n",
      "Finish Epoch [13/100], D Loss: 0.715397, G Loss: -4.990615\n",
      "Epoch [14/100], Step:  38400, d_loss: 0.178787, g_loss: -0.386415, real_scores: 0.449093, fake_scores: 0.386415\n",
      "Finish Epoch [14/100], D Loss: 0.615441, G Loss: -4.686096\n",
      "Epoch [15/100], Step:  38400, d_loss: -0.026505, g_loss: -0.549526, real_scores: 0.584573, fake_scores: 0.549526\n",
      "Finish Epoch [15/100], D Loss: 0.626580, G Loss: -4.333514\n",
      "Epoch [16/100], Step:  38400, d_loss: -0.043440, g_loss: -0.479298, real_scores: 0.529565, fake_scores: 0.479298\n",
      "Finish Epoch [16/100], D Loss: 0.519711, G Loss: -4.107611\n",
      "Epoch [17/100], Step:  38400, d_loss: -0.040460, g_loss: -0.545571, real_scores: 0.589285, fake_scores: 0.545571\n",
      "Finish Epoch [17/100], D Loss: 0.420767, G Loss: -3.887644\n",
      "Epoch [18/100], Step:  38400, d_loss: -0.029953, g_loss: -0.487095, real_scores: 0.526200, fake_scores: 0.487095\n",
      "Finish Epoch [18/100], D Loss: 0.332865, G Loss: -3.633854\n",
      "Epoch [19/100], Step:  38400, d_loss: -0.045250, g_loss: -0.584973, real_scores: 0.637259, fake_scores: 0.584973\n",
      "Finish Epoch [19/100], D Loss: 0.252941, G Loss: -3.498325\n",
      "Epoch [20/100], Step:  38400, d_loss: 0.516443, g_loss: -0.216284, real_scores: 0.258797, fake_scores: 0.216284\n",
      "Finish Epoch [20/100], D Loss: 0.224721, G Loss: -3.310761\n",
      "Epoch [21/100], Step:  38400, d_loss: -0.052674, g_loss: -0.529442, real_scores: 0.595466, fake_scores: 0.529442\n",
      "Finish Epoch [21/100], D Loss: 0.219629, G Loss: -3.110656\n",
      "Epoch [22/100], Step:  38400, d_loss: -0.052868, g_loss: -0.526466, real_scores: 0.583629, fake_scores: 0.526466\n",
      "Finish Epoch [22/100], D Loss: 0.135198, G Loss: -2.941849\n",
      "Epoch [23/100], Step:  38400, d_loss: -0.025582, g_loss: -0.509782, real_scores: 0.550784, fake_scores: 0.509782\n",
      "Finish Epoch [23/100], D Loss: 0.088813, G Loss: -2.855320\n",
      "Epoch [24/100], Step:  38400, d_loss: -0.049567, g_loss: -0.479513, real_scores: 0.537158, fake_scores: 0.479513\n",
      "Finish Epoch [24/100], D Loss: 0.070230, G Loss: -2.744359\n",
      "Epoch [25/100], Step:  38400, d_loss: -0.048007, g_loss: -0.501030, real_scores: 0.564300, fake_scores: 0.501030\n",
      "Finish Epoch [25/100], D Loss: 0.087059, G Loss: -2.639012\n",
      "Epoch [26/100], Step:  38400, d_loss: -0.066340, g_loss: -0.480560, real_scores: 0.559663, fake_scores: 0.480560\n",
      "Finish Epoch [26/100], D Loss: 0.012977, G Loss: -2.513597\n",
      "Epoch [27/100], Step:  38400, d_loss: -0.063423, g_loss: -0.467548, real_scores: 0.544406, fake_scores: 0.467548\n",
      "Finish Epoch [27/100], D Loss: 0.011396, G Loss: -2.433779\n",
      "Epoch [28/100], Step:  38400, d_loss: -0.058794, g_loss: -0.567356, real_scores: 0.637233, fake_scores: 0.567356\n",
      "Finish Epoch [28/100], D Loss: -0.072195, G Loss: -2.309636\n",
      "Epoch [29/100], Step:  38400, d_loss: -0.082259, g_loss: -0.531663, real_scores: 0.619580, fake_scores: 0.531663\n",
      "Finish Epoch [29/100], D Loss: -0.057658, G Loss: -2.193894\n",
      "Epoch [30/100], Step:  38400, d_loss: -0.079596, g_loss: -0.455761, real_scores: 0.552037, fake_scores: 0.455761\n",
      "Finish Epoch [30/100], D Loss: -0.056736, G Loss: -1.956601\n",
      "Epoch [31/100], Step:  38400, d_loss: -0.092644, g_loss: -0.350381, real_scores: 0.461781, fake_scores: 0.350381\n",
      "Finish Epoch [31/100], D Loss: -0.103541, G Loss: -1.896589\n",
      "Epoch [32/100], Step:  38400, d_loss: -0.103816, g_loss: -0.446071, real_scores: 0.574008, fake_scores: 0.446071\n",
      "Finish Epoch [32/100], D Loss: -0.137800, G Loss: -1.759195\n",
      "Epoch [33/100], Step:  38400, d_loss: -0.193739, g_loss: -0.540493, real_scores: 0.755694, fake_scores: 0.540493\n",
      "Finish Epoch [33/100], D Loss: 0.202295, G Loss: -1.842596\n",
      "Epoch [34/100], Step:  38400, d_loss: -0.160700, g_loss: -0.319833, real_scores: 0.492862, fake_scores: 0.319833\n",
      "Finish Epoch [34/100], D Loss: -0.315296, G Loss: -1.570092\n",
      "Epoch [35/100], Step:  38400, d_loss: 0.248436, g_loss: -0.472905, real_scores: 0.828744, fake_scores: 0.472905\n",
      "Finish Epoch [35/100], D Loss: 0.712681, G Loss: -1.736868\n",
      "Epoch [36/100], Step:  38400, d_loss: -0.018547, g_loss: -0.461314, real_scores: 0.648863, fake_scores: 0.461314\n",
      "Finish Epoch [36/100], D Loss: -0.179296, G Loss: -1.541486\n",
      "Epoch [37/100], Step:  38400, d_loss: -0.179920, g_loss: -0.469755, real_scores: 0.668662, fake_scores: 0.469755\n",
      "Finish Epoch [37/100], D Loss: -0.299333, G Loss: -1.482056\n",
      "Epoch [38/100], Step:  38400, d_loss: 3.779971, g_loss: -0.894800, real_scores: 0.862690, fake_scores: 0.894800\n",
      "Finish Epoch [38/100], D Loss: 0.027389, G Loss: -1.506477\n",
      "Epoch [39/100], Step:  38400, d_loss: -0.222740, g_loss: -0.386285, real_scores: 0.617249, fake_scores: 0.386285\n",
      "Finish Epoch [39/100], D Loss: -0.298879, G Loss: -1.406455\n",
      "Epoch [40/100], Step:  38400, d_loss: -0.115997, g_loss: -0.169616, real_scores: 0.328361, fake_scores: 0.169616\n",
      "Finish Epoch [40/100], D Loss: -0.379462, G Loss: -1.317397\n",
      "Epoch [41/100], Step:  38400, d_loss: -0.241919, g_loss: -0.265985, real_scores: 0.548863, fake_scores: 0.265985\n",
      "Finish Epoch [41/100], D Loss: -0.312869, G Loss: -1.318441\n",
      "Epoch [42/100], Step:  38400, d_loss: -0.216709, g_loss: -0.441772, real_scores: 0.665480, fake_scores: 0.441772\n",
      "Finish Epoch [42/100], D Loss: -0.348109, G Loss: -1.330296\n",
      "Epoch [43/100], Step:  38400, d_loss: -0.040614, g_loss: -0.883094, real_scores: 0.967547, fake_scores: 0.883094\n",
      "Finish Epoch [43/100], D Loss: -0.319902, G Loss: -1.275088\n",
      "Epoch [44/100], Step:  38400, d_loss: -0.248271, g_loss: -0.526153, real_scores: 0.799351, fake_scores: 0.526153\n",
      "Finish Epoch [44/100], D Loss: -0.383557, G Loss: -1.229215\n",
      "Epoch [45/100], Step:  38400, d_loss: -0.244950, g_loss: -0.390904, real_scores: 0.662147, fake_scores: 0.390904\n",
      "Finish Epoch [45/100], D Loss: -0.424463, G Loss: -1.184592\n",
      "Epoch [46/100], Step:  38400, d_loss: -0.362630, g_loss: -0.484714, real_scores: 0.852963, fake_scores: 0.484714\n",
      "Finish Epoch [46/100], D Loss: -0.358662, G Loss: -1.203646\n",
      "Epoch [47/100], Step:  38400, d_loss: -0.279053, g_loss: -0.424285, real_scores: 0.707607, fake_scores: 0.424285\n",
      "Finish Epoch [47/100], D Loss: -0.291235, G Loss: -1.160775\n",
      "Epoch [48/100], Step:  38400, d_loss: -0.132871, g_loss: -0.150117, real_scores: 0.354489, fake_scores: 0.150117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Epoch [48/100], D Loss: -0.361599, G Loss: -1.119469\n",
      "Epoch [49/100], Step:  38400, d_loss: -0.374522, g_loss: -0.438550, real_scores: 0.821450, fake_scores: 0.438550\n",
      "Finish Epoch [49/100], D Loss: -0.224620, G Loss: -1.098021\n",
      "Epoch [50/100], Step:  38400, d_loss: -0.402356, g_loss: -0.472710, real_scores: 0.915060, fake_scores: 0.472710\n",
      "Finish Epoch [50/100], D Loss: -0.442995, G Loss: -1.085754\n",
      "Epoch [51/100], Step:  38400, d_loss: -0.349355, g_loss: -0.469489, real_scores: 0.822431, fake_scores: 0.469489\n",
      "Finish Epoch [51/100], D Loss: -0.347930, G Loss: -1.053855\n",
      "Epoch [52/100], Step:  38400, d_loss: -0.135631, g_loss: -0.533278, real_scores: 0.911762, fake_scores: 0.533278\n",
      "Finish Epoch [52/100], D Loss: -0.326745, G Loss: -1.039836\n",
      "Epoch [53/100], Step:  38400, d_loss: -0.155248, g_loss: -0.240196, real_scores: 0.407385, fake_scores: 0.240196\n",
      "Finish Epoch [53/100], D Loss: -0.370121, G Loss: -0.998428\n",
      "Epoch [54/100], Step:  38400, d_loss: -0.276382, g_loss: -0.283189, real_scores: 0.566616, fake_scores: 0.283189\n",
      "Finish Epoch [54/100], D Loss: -0.364234, G Loss: -0.972716\n",
      "Epoch [55/100], Step:  38400, d_loss: -0.263484, g_loss: -0.588021, real_scores: 0.857483, fake_scores: 0.588021\n",
      "Finish Epoch [55/100], D Loss: -0.313821, G Loss: -0.965708\n",
      "Epoch [56/100], Step:  38400, d_loss: -0.480936, g_loss: -0.459889, real_scores: 0.951011, fake_scores: 0.459889\n",
      "Finish Epoch [56/100], D Loss: -0.373948, G Loss: -0.943781\n",
      "Epoch [57/100], Step:  38400, d_loss: -0.114336, g_loss: -0.346742, real_scores: 0.668782, fake_scores: 0.346742\n",
      "Finish Epoch [57/100], D Loss: -0.418327, G Loss: -0.910588\n",
      "Epoch [58/100], Step:  38400, d_loss: -0.211484, g_loss: -0.447189, real_scores: 0.675140, fake_scores: 0.447189\n",
      "Finish Epoch [58/100], D Loss: -0.286417, G Loss: -0.921522\n",
      "Epoch [59/100], Step:  38400, d_loss: -0.377907, g_loss: -0.544004, real_scores: 0.989968, fake_scores: 0.544004\n",
      "Finish Epoch [59/100], D Loss: -0.207716, G Loss: -0.949386\n",
      "Epoch [60/100], Step:  38400, d_loss: -0.444269, g_loss: -0.430001, real_scores: 0.891529, fake_scores: 0.430001\n",
      "Finish Epoch [60/100], D Loss: -0.215881, G Loss: -0.881471\n",
      "Epoch [61/100], Step:  38400, d_loss: -0.343152, g_loss: -0.368127, real_scores: 0.720965, fake_scores: 0.368127\n",
      "Finish Epoch [61/100], D Loss: -0.386962, G Loss: -0.839419\n",
      "Epoch [62/100], Step:  38400, d_loss: -0.317421, g_loss: -0.354497, real_scores: 0.680418, fake_scores: 0.354497\n",
      "Finish Epoch [62/100], D Loss: -0.242947, G Loss: -0.806799\n",
      "Epoch [63/100], Step:  38400, d_loss: -0.453184, g_loss: -0.399348, real_scores: 0.859933, fake_scores: 0.399348\n",
      "Finish Epoch [63/100], D Loss: -0.228858, G Loss: -0.840241\n",
      "Epoch [64/100], Step:  38400, d_loss: -0.479159, g_loss: -0.387941, real_scores: 0.879903, fake_scores: 0.387941\n",
      "Finish Epoch [64/100], D Loss: -0.276787, G Loss: -0.820342\n",
      "Epoch [65/100], Step:  38400, d_loss: -0.164779, g_loss: -0.669840, real_scores: 0.887994, fake_scores: 0.669840\n",
      "Finish Epoch [65/100], D Loss: -0.416959, G Loss: -0.762081\n",
      "Epoch [66/100], Step:  38400, d_loss: -0.173383, g_loss: -0.404685, real_scores: 0.762938, fake_scores: 0.404685\n",
      "Finish Epoch [66/100], D Loss: 0.086241, G Loss: -0.742424\n",
      "Epoch [67/100], Step:  38400, d_loss: -0.307829, g_loss: -0.405794, real_scores: 0.726523, fake_scores: 0.405794\n",
      "Finish Epoch [67/100], D Loss: 0.023438, G Loss: -0.778204\n",
      "Epoch [68/100], Step:  38400, d_loss: -0.329112, g_loss: -0.347575, real_scores: 0.680827, fake_scores: 0.347575\n",
      "Finish Epoch [68/100], D Loss: -0.409695, G Loss: -0.741657\n",
      "Epoch [69/100], Step:  38400, d_loss: -0.353540, g_loss: -0.387047, real_scores: 0.781785, fake_scores: 0.387047\n",
      "Finish Epoch [69/100], D Loss: -0.381524, G Loss: -0.731728\n",
      "Epoch [70/100], Step:  38400, d_loss: 3.176912, g_loss: -0.101158, real_scores: 0.217564, fake_scores: 0.101158\n",
      "Finish Epoch [70/100], D Loss: -0.292521, G Loss: -0.749534\n",
      "Epoch [71/100], Step:  38400, d_loss: -0.304232, g_loss: -0.332410, real_scores: 0.658890, fake_scores: 0.332410\n",
      "Finish Epoch [71/100], D Loss: -0.362042, G Loss: -0.698175\n",
      "Epoch [72/100], Step:  38400, d_loss: -0.196584, g_loss: -0.371460, real_scores: 0.965818, fake_scores: 0.371460\n",
      "Finish Epoch [72/100], D Loss: -0.296367, G Loss: -0.703206\n",
      "Epoch [73/100], Step:  38400, d_loss: -0.264594, g_loss: -0.438264, real_scores: 0.729891, fake_scores: 0.438264\n",
      "Finish Epoch [73/100], D Loss: -0.340095, G Loss: -0.706885\n",
      "Epoch [74/100], Step:  38400, d_loss: -0.240552, g_loss: -0.406087, real_scores: 0.678680, fake_scores: 0.406087\n",
      "Finish Epoch [74/100], D Loss: -0.347973, G Loss: -0.710111\n",
      "Epoch [75/100], Step:  38400, d_loss: -0.122592, g_loss: -0.821791, real_scores: 0.963682, fake_scores: 0.821791\n",
      "Finish Epoch [75/100], D Loss: -0.290042, G Loss: -0.716289\n",
      "Epoch [76/100], Step:  38400, d_loss: -0.441363, g_loss: -0.502668, real_scores: 0.991153, fake_scores: 0.502668\n",
      "Finish Epoch [76/100], D Loss: -0.316001, G Loss: -0.680725\n",
      "Epoch [77/100], Step:  38400, d_loss: 2.001001, g_loss: -0.385209, real_scores: 0.922398, fake_scores: 0.385209\n",
      "Finish Epoch [77/100], D Loss: -0.190242, G Loss: -0.654057\n",
      "Epoch [78/100], Step:  38400, d_loss: -0.548674, g_loss: -0.417042, real_scores: 0.969235, fake_scores: 0.417042\n",
      "Finish Epoch [78/100], D Loss: -0.287441, G Loss: -0.647285\n",
      "Epoch [79/100], Step:  38400, d_loss: -0.319735, g_loss: -0.298221, real_scores: 0.631432, fake_scores: 0.298221\n",
      "Finish Epoch [79/100], D Loss: -0.258172, G Loss: -0.629742\n",
      "Epoch [80/100], Step:  38400, d_loss: -0.556225, g_loss: -0.365342, real_scores: 0.939775, fake_scores: 0.365342\n",
      "Finish Epoch [80/100], D Loss: -0.105623, G Loss: -0.649960\n",
      "Epoch [81/100], Step:  38400, d_loss: -0.433925, g_loss: -0.481827, real_scores: 0.926886, fake_scores: 0.481827\n",
      "Finish Epoch [81/100], D Loss: -0.281063, G Loss: -0.623884\n",
      "Epoch [82/100], Step:  38400, d_loss: -0.329766, g_loss: -0.321017, real_scores: 0.654091, fake_scores: 0.321017\n",
      "Finish Epoch [82/100], D Loss: -0.315118, G Loss: -0.629007\n",
      "Epoch [83/100], Step:  38400, d_loss: -0.310121, g_loss: -0.341604, real_scores: 0.663007, fake_scores: 0.341604\n",
      "Finish Epoch [83/100], D Loss: -0.287780, G Loss: -0.636476\n",
      "Epoch [84/100], Step:  38400, d_loss: -0.310917, g_loss: -0.317125, real_scores: 0.644979, fake_scores: 0.317125\n",
      "Finish Epoch [84/100], D Loss: -0.292251, G Loss: -0.606227\n",
      "Epoch [85/100], Step:  38400, d_loss: -0.327792, g_loss: -0.395928, real_scores: 0.835288, fake_scores: 0.395928\n",
      "Finish Epoch [85/100], D Loss: -0.299440, G Loss: -0.611477\n",
      "Epoch [86/100], Step:  38400, d_loss: -0.256247, g_loss: -0.611303, real_scores: 0.896106, fake_scores: 0.611303\n",
      "Finish Epoch [86/100], D Loss: -0.297790, G Loss: -0.603789\n",
      "Epoch [87/100], Step:  38400, d_loss: -0.567420, g_loss: -0.400744, real_scores: 0.973508, fake_scores: 0.400744\n",
      "Finish Epoch [87/100], D Loss: 0.698273, G Loss: -0.614797\n",
      "Epoch [88/100], Step:  38400, d_loss: -0.369861, g_loss: -0.313569, real_scores: 0.704029, fake_scores: 0.313569\n",
      "Finish Epoch [88/100], D Loss: -0.295300, G Loss: -0.588413\n",
      "Epoch [89/100], Step:  38400, d_loss: -0.152262, g_loss: -0.414456, real_scores: 0.571010, fake_scores: 0.414456\n",
      "Finish Epoch [89/100], D Loss: -0.339958, G Loss: -0.582178\n",
      "Epoch [90/100], Step:  38400, d_loss: -0.310766, g_loss: -0.309831, real_scores: 0.635286, fake_scores: 0.309831\n",
      "Finish Epoch [90/100], D Loss: -0.297421, G Loss: -0.580910\n",
      "Epoch [91/100], Step:  38400, d_loss: -0.314762, g_loss: -0.458272, real_scores: 0.787156, fake_scores: 0.458272\n",
      "Finish Epoch [91/100], D Loss: -0.265282, G Loss: -0.565553\n",
      "Epoch [92/100], Step:  38400, d_loss: -0.392590, g_loss: -0.465487, real_scores: 0.866909, fake_scores: 0.465487\n",
      "Finish Epoch [92/100], D Loss: -0.263743, G Loss: -0.561088\n",
      "Epoch [93/100], Step:  38400, d_loss: -0.406972, g_loss: -0.510851, real_scores: 0.927510, fake_scores: 0.510851\n",
      "Finish Epoch [93/100], D Loss: -0.287735, G Loss: -0.533488\n",
      "Epoch [94/100], Step:  38400, d_loss: -0.287462, g_loss: -0.513709, real_scores: 0.988493, fake_scores: 0.513709\n",
      "Finish Epoch [94/100], D Loss: -0.290774, G Loss: -0.530690\n",
      "Epoch [95/100], Step:  38400, d_loss: -0.278851, g_loss: -0.435911, real_scores: 0.718838, fake_scores: 0.435911\n",
      "Finish Epoch [95/100], D Loss: -0.241019, G Loss: -0.544245\n",
      "Epoch [96/100], Step:  38400, d_loss: -0.160910, g_loss: -0.299663, real_scores: 0.535213, fake_scores: 0.299663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Epoch [96/100], D Loss: -0.204410, G Loss: -0.523494\n",
      "Epoch [97/100], Step:  38400, d_loss: -0.507575, g_loss: -0.371188, real_scores: 0.897422, fake_scores: 0.371188\n",
      "Finish Epoch [97/100], D Loss: -0.312184, G Loss: -0.550085\n",
      "Epoch [98/100], Step:  38400, d_loss: -0.581140, g_loss: -0.360121, real_scores: 0.960339, fake_scores: 0.360121\n",
      "Finish Epoch [98/100], D Loss: -0.294715, G Loss: -0.537799\n",
      "Epoch [99/100], Step:  38400, d_loss: -0.116036, g_loss: -0.785529, real_scores: 0.938844, fake_scores: 0.785529\n",
      "Finish Epoch [99/100], D Loss: -0.308753, G Loss: -0.476755\n",
      "Epoch [100/100], Step:  38400, d_loss: -0.249928, g_loss: -0.574315, real_scores: 0.967254, fake_scores: 0.574315\n",
      "Finish Epoch [100/100], D Loss: -0.293754, G Loss: -0.518001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        ########## G ##########\n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = fake_out.mean()\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward(mone)\n",
    "        g_loss = -g_loss\n",
    "        g_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_img = img.cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "#         z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "#         fake_img = g(z).detach()\n",
    "        fake_out = d(fake_img.detach())\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(d, real_img, fake_img)\n",
    "        \n",
    "        d_loss = d_loss_fake - d_loss_real + gradient_penalty\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        #######################\n",
    "        w_dist = d_loss_fake - d_loss_real\n",
    "        \n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "            writer.add_scalar('Wasserstein Distance', w_dist.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * BATCH_SIZE, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/wgan_gp_discriminator.pt')\n",
    "torch.save(g.state_dict(), './ser/wgan_gp_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.load_state_dict(torch.load('./ser/wgan_gp_discriminator.pt'))\n",
    "g.load_state_dict(torch.load('./ser/wgan_gp_generator.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(10, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
