{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./cnn_dcgan_img'): os.mkdir('./cnn_dcgan_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('./datas/mnist/', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
    "        \n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        outs = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        outs = F.leaky_relu(self.conv2_bn(self.conv2(outs)), 0.2)\n",
    "        outs = F.leaky_relu(self.conv3_bn(self.conv3(outs)), 0.2)\n",
    "        outs = F.leaky_relu(self.conv4_bn(self.conv4(outs)), 0.2)\n",
    "        outs = F.sigmoid(self.conv5(outs))\n",
    "\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0) # b d*8 \n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 100 28 28\n",
    "        outs = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
    "        outs = F.relu(self.deconv2_bn(self.deconv2(outs)))\n",
    "        outs = F.relu(self.deconv3_bn(self.deconv3(outs)))\n",
    "        outs = F.relu(self.deconv4_bn(self.deconv4(outs)))\n",
    "        outs = F.tanh(self.deconv5(outs))\n",
    "\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "d = Discriminator(128).to(device)\n",
    "g = Generator(128).to(device)\n",
    "\n",
    "d.weight_init(.0, 0.02)\n",
    "g.weight_init(.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_dcgan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659b1804b8be4ff596df19bf47c0eae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  25600, d_loss: 0.000090, g_loss: 27.630657, real_scores: 0.999910, fake_scores: 0.000000\n",
      "Epoch [1/100], Step:  51200, d_loss: 0.235794, g_loss: 3.080480, real_scores: 0.881561, fake_scores: 0.093847\n",
      "Finish Epoch [1/100], D Loss: 54.357024, G Loss: 1907.984655\n",
      "Epoch [2/100], Step:  25600, d_loss: 0.880478, g_loss: 0.838485, real_scores: 0.550610, fake_scores: 0.164468\n",
      "Epoch [2/100], Step:  51200, d_loss: 0.529139, g_loss: 2.508429, real_scores: 0.811086, fake_scores: 0.242364\n",
      "Finish Epoch [2/100], D Loss: 45.530316, G Loss: 145.858855\n",
      "Epoch [3/100], Step:  25600, d_loss: 0.634092, g_loss: 1.238972, real_scores: 0.613096, fake_scores: 0.038738\n",
      "Epoch [3/100], Step:  51200, d_loss: 0.563286, g_loss: 1.264220, real_scores: 0.674065, fake_scores: 0.102723\n",
      "Finish Epoch [3/100], D Loss: 28.892624, G Loss: 112.096306\n",
      "Epoch [4/100], Step:  25600, d_loss: 0.211732, g_loss: 4.091733, real_scores: 0.902209, fake_scores: 0.091500\n",
      "Epoch [4/100], Step:  51200, d_loss: 0.347864, g_loss: 2.530031, real_scores: 0.779872, fake_scores: 0.068231\n",
      "Finish Epoch [4/100], D Loss: 19.211421, G Loss: 98.310538\n",
      "Epoch [5/100], Step:  25600, d_loss: 0.338996, g_loss: 1.331559, real_scores: 0.750554, fake_scores: 0.018840\n",
      "Epoch [5/100], Step:  51200, d_loss: 0.111743, g_loss: 3.372821, real_scores: 0.918257, fake_scores: 0.021351\n",
      "Finish Epoch [5/100], D Loss: 13.052230, G Loss: 83.225005\n",
      "Epoch [6/100], Step:  25600, d_loss: 0.224984, g_loss: 3.045858, real_scores: 0.914600, fake_scores: 0.115594\n",
      "Epoch [6/100], Step:  51200, d_loss: 0.451433, g_loss: 2.033204, real_scores: 0.793128, fake_scores: 0.151329\n",
      "Finish Epoch [6/100], D Loss: 11.193028, G Loss: 69.835479\n",
      "Epoch [7/100], Step:  25600, d_loss: 0.158229, g_loss: 2.795727, real_scores: 0.897301, fake_scores: 0.042041\n",
      "Epoch [7/100], Step:  51200, d_loss: 0.061339, g_loss: 5.082229, real_scores: 0.990370, fake_scores: 0.048494\n",
      "Finish Epoch [7/100], D Loss: 8.729688, G Loss: 64.654546\n",
      "Epoch [8/100], Step:  25600, d_loss: 0.077805, g_loss: 4.088067, real_scores: 0.972830, fake_scores: 0.047350\n",
      "Epoch [8/100], Step:  51200, d_loss: 0.079399, g_loss: 4.182629, real_scores: 0.970952, fake_scores: 0.046928\n",
      "Finish Epoch [8/100], D Loss: 8.346356, G Loss: 54.843733\n",
      "Epoch [9/100], Step:  25600, d_loss: 0.055897, g_loss: 4.422222, real_scores: 0.956118, fake_scores: 0.009999\n",
      "Epoch [9/100], Step:  51200, d_loss: 0.202459, g_loss: 3.265564, real_scores: 0.949599, fake_scores: 0.127770\n",
      "Finish Epoch [9/100], D Loss: 7.386554, G Loss: 48.278604\n",
      "Epoch [10/100], Step:  25600, d_loss: 0.682360, g_loss: 2.530495, real_scores: 0.859130, fake_scores: 0.361427\n",
      "Epoch [10/100], Step:  51200, d_loss: 0.078405, g_loss: 3.484515, real_scores: 0.960242, fake_scores: 0.035644\n",
      "Finish Epoch [10/100], D Loss: 5.446168, G Loss: 44.424737\n",
      "Epoch [11/100], Step:  25600, d_loss: 0.096060, g_loss: 4.455232, real_scores: 0.946228, fake_scores: 0.038171\n",
      "Epoch [11/100], Step:  51200, d_loss: 0.043854, g_loss: 3.863198, real_scores: 0.974810, fake_scores: 0.017730\n",
      "Finish Epoch [11/100], D Loss: 5.916203, G Loss: 39.953774\n",
      "Epoch [12/100], Step:  25600, d_loss: 0.295035, g_loss: 4.168883, real_scores: 0.972085, fake_scores: 0.216628\n",
      "Epoch [12/100], Step:  51200, d_loss: 0.165367, g_loss: 3.374396, real_scores: 0.934432, fake_scores: 0.084155\n",
      "Finish Epoch [12/100], D Loss: 5.863321, G Loss: 35.388877\n",
      "Epoch [13/100], Step:  25600, d_loss: 0.198773, g_loss: 3.459346, real_scores: 0.929101, fake_scores: 0.107503\n",
      "Epoch [13/100], Step:  51200, d_loss: 0.149946, g_loss: 4.611877, real_scores: 0.965825, fake_scores: 0.102156\n",
      "Finish Epoch [13/100], D Loss: 5.225526, G Loss: 33.481745\n",
      "Epoch [14/100], Step:  25600, d_loss: 0.288438, g_loss: 5.211711, real_scores: 0.966873, fake_scores: 0.202851\n",
      "Epoch [14/100], Step:  51200, d_loss: 0.022482, g_loss: 5.340393, real_scores: 0.992000, fake_scores: 0.014163\n",
      "Finish Epoch [14/100], D Loss: 4.161699, G Loss: 34.471857\n",
      "Epoch [15/100], Step:  25600, d_loss: 0.123572, g_loss: 4.285771, real_scores: 0.923102, fake_scores: 0.038412\n",
      "Epoch [15/100], Step:  51200, d_loss: 0.050984, g_loss: 5.458931, real_scores: 0.987671, fake_scores: 0.036642\n",
      "Finish Epoch [15/100], D Loss: 4.117537, G Loss: 28.100413\n",
      "Epoch [16/100], Step:  25600, d_loss: 0.901019, g_loss: 2.249060, real_scores: 0.733469, fake_scores: 0.392724\n",
      "Epoch [16/100], Step:  51200, d_loss: 0.866904, g_loss: 2.460018, real_scores: 0.930749, fake_scores: 0.476773\n",
      "Finish Epoch [16/100], D Loss: 4.515987, G Loss: 27.283123\n",
      "Epoch [17/100], Step:  25600, d_loss: 0.108800, g_loss: 3.827430, real_scores: 0.972062, fake_scores: 0.073233\n",
      "Epoch [17/100], Step:  51200, d_loss: 0.343698, g_loss: 2.408065, real_scores: 0.790852, fake_scores: 0.072559\n",
      "Finish Epoch [17/100], D Loss: 3.227999, G Loss: 26.717756\n",
      "Epoch [18/100], Step:  25600, d_loss: 0.058755, g_loss: 4.353538, real_scores: 0.961880, fake_scores: 0.018348\n",
      "Epoch [18/100], Step:  51200, d_loss: 2.499708, g_loss: 6.658349, real_scores: 0.999123, fake_scores: 0.847966\n",
      "Finish Epoch [18/100], D Loss: 2.788413, G Loss: 27.157331\n",
      "Epoch [19/100], Step:  25600, d_loss: 0.475749, g_loss: 1.980668, real_scores: 0.768986, fake_scores: 0.124652\n",
      "Epoch [19/100], Step:  51200, d_loss: 0.019253, g_loss: 5.251976, real_scores: 0.993538, fake_scores: 0.012536\n",
      "Finish Epoch [19/100], D Loss: 1.800704, G Loss: 28.385014\n",
      "Epoch [20/100], Step:  25600, d_loss: 0.053897, g_loss: 5.304996, real_scores: 0.985222, fake_scores: 0.037028\n",
      "Epoch [20/100], Step:  51200, d_loss: 0.687781, g_loss: 2.060314, real_scores: 0.803468, fake_scores: 0.337105\n",
      "Finish Epoch [20/100], D Loss: 2.475877, G Loss: 25.602275\n",
      "Epoch [21/100], Step:  25600, d_loss: 0.129369, g_loss: 2.705527, real_scores: 0.910896, fake_scores: 0.030565\n",
      "Epoch [21/100], Step:  51200, d_loss: 0.015774, g_loss: 4.462751, real_scores: 0.991898, fake_scores: 0.007537\n",
      "Finish Epoch [21/100], D Loss: 1.540728, G Loss: 27.100402\n",
      "Epoch [22/100], Step:  25600, d_loss: 0.719996, g_loss: 3.616266, real_scores: 0.591251, fake_scores: 0.037333\n",
      "Epoch [22/100], Step:  51200, d_loss: 0.123755, g_loss: 3.747586, real_scores: 0.952524, fake_scores: 0.067328\n",
      "Finish Epoch [22/100], D Loss: 3.835385, G Loss: 18.822952\n",
      "Epoch [23/100], Step:  25600, d_loss: 0.165565, g_loss: 3.357653, real_scores: 0.920863, fake_scores: 0.074166\n",
      "Epoch [23/100], Step:  51200, d_loss: 0.024676, g_loss: 5.640471, real_scores: 0.990114, fake_scores: 0.014332\n",
      "Finish Epoch [23/100], D Loss: 1.773385, G Loss: 22.543873\n",
      "Epoch [24/100], Step:  25600, d_loss: 0.161554, g_loss: 3.345803, real_scores: 0.965843, fake_scores: 0.114006\n",
      "Epoch [24/100], Step:  51200, d_loss: 0.188052, g_loss: 3.299428, real_scores: 0.971680, fake_scores: 0.135313\n",
      "Finish Epoch [24/100], D Loss: 2.427345, G Loss: 20.488618\n",
      "Epoch [25/100], Step:  25600, d_loss: 0.191505, g_loss: 3.362394, real_scores: 0.860270, fake_scores: 0.025140\n",
      "Epoch [25/100], Step:  51200, d_loss: 0.042086, g_loss: 4.549849, real_scores: 0.970002, fake_scores: 0.010892\n",
      "Finish Epoch [25/100], D Loss: 1.590493, G Loss: 21.262992\n",
      "Epoch [26/100], Step:  25600, d_loss: 0.495386, g_loss: 2.385139, real_scores: 0.774714, fake_scores: 0.180267\n",
      "Epoch [26/100], Step:  51200, d_loss: 0.022504, g_loss: 4.367306, real_scores: 0.989389, fake_scores: 0.011586\n",
      "Finish Epoch [26/100], D Loss: 1.143236, G Loss: 22.057901\n",
      "Epoch [27/100], Step:  25600, d_loss: 0.229488, g_loss: 3.764467, real_scores: 0.919623, fake_scores: 0.119441\n",
      "Epoch [27/100], Step:  51200, d_loss: 0.204074, g_loss: 4.310174, real_scores: 0.904322, fake_scores: 0.087083\n",
      "Finish Epoch [27/100], D Loss: 2.522887, G Loss: 17.175997\n",
      "Epoch [28/100], Step:  25600, d_loss: 0.024475, g_loss: 4.847461, real_scores: 0.980201, fake_scores: 0.004282\n",
      "Epoch [28/100], Step:  51200, d_loss: 0.018314, g_loss: 6.601162, real_scores: 0.989501, fake_scores: 0.007424\n",
      "Finish Epoch [28/100], D Loss: 0.837825, G Loss: 22.507934\n",
      "Epoch [29/100], Step:  25600, d_loss: 0.167928, g_loss: 2.392602, real_scores: 0.934284, fake_scores: 0.088465\n",
      "Epoch [29/100], Step:  51200, d_loss: 0.479770, g_loss: 1.792565, real_scores: 0.724031, fake_scores: 0.105714\n",
      "Finish Epoch [29/100], D Loss: 1.882587, G Loss: 18.160669\n",
      "Epoch [30/100], Step:  25600, d_loss: 0.010545, g_loss: 5.676111, real_scores: 0.995749, fake_scores: 0.006210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Step:  51200, d_loss: 0.013141, g_loss: 6.445673, real_scores: 0.998958, fake_scores: 0.011889\n",
      "Finish Epoch [30/100], D Loss: 0.137315, G Loss: 23.840983\n",
      "Epoch [31/100], Step:  25600, d_loss: 0.319310, g_loss: 3.297762, real_scores: 0.925557, fake_scores: 0.189978\n",
      "Epoch [31/100], Step:  51200, d_loss: 0.269485, g_loss: 7.028339, real_scores: 0.993620, fake_scores: 0.213109\n",
      "Finish Epoch [31/100], D Loss: 1.829819, G Loss: 17.866706\n",
      "Epoch [32/100], Step:  25600, d_loss: 0.207546, g_loss: 7.670907, real_scores: 0.997803, fake_scores: 0.172751\n",
      "Epoch [32/100], Step:  51200, d_loss: 0.847670, g_loss: 2.020749, real_scores: 0.700767, fake_scores: 0.288667\n",
      "Finish Epoch [32/100], D Loss: 1.859366, G Loss: 14.646003\n",
      "Epoch [33/100], Step:  25600, d_loss: 0.077761, g_loss: 5.304980, real_scores: 0.992387, fake_scores: 0.065423\n",
      "Epoch [33/100], Step:  51200, d_loss: 0.016864, g_loss: 5.763041, real_scores: 0.991904, fake_scores: 0.008623\n",
      "Finish Epoch [33/100], D Loss: 0.990279, G Loss: 17.287277\n",
      "Epoch [34/100], Step:  25600, d_loss: 1.187637, g_loss: 2.693170, real_scores: 0.786137, fake_scores: 0.450639\n",
      "Epoch [34/100], Step:  51200, d_loss: 0.108742, g_loss: 4.300051, real_scores: 0.984545, fake_scores: 0.085419\n",
      "Finish Epoch [34/100], D Loss: 1.359276, G Loss: 16.511857\n",
      "Epoch [35/100], Step:  25600, d_loss: 0.018760, g_loss: 5.724648, real_scores: 0.994306, fake_scores: 0.012686\n",
      "Epoch [35/100], Step:  51200, d_loss: 0.752767, g_loss: 1.833512, real_scores: 0.734539, fake_scores: 0.274414\n",
      "Finish Epoch [35/100], D Loss: 1.107624, G Loss: 16.050857\n",
      "Epoch [36/100], Step:  25600, d_loss: 0.303594, g_loss: 3.826949, real_scores: 0.804292, fake_scores: 0.052259\n",
      "Epoch [36/100], Step:  51200, d_loss: 0.050889, g_loss: 4.585301, real_scores: 0.978854, fake_scores: 0.028411\n",
      "Finish Epoch [36/100], D Loss: 1.321163, G Loss: 14.310665\n",
      "Epoch [37/100], Step:  25600, d_loss: 0.192290, g_loss: 3.857791, real_scores: 0.952968, fake_scores: 0.119505\n",
      "Epoch [37/100], Step:  51200, d_loss: 0.460190, g_loss: 1.974145, real_scores: 0.817132, fake_scores: 0.193638\n",
      "Finish Epoch [37/100], D Loss: 1.209876, G Loss: 14.301457\n",
      "Epoch [38/100], Step:  25600, d_loss: 0.316069, g_loss: 3.405873, real_scores: 0.815073, fake_scores: 0.087678\n",
      "Epoch [38/100], Step:  51200, d_loss: 0.011691, g_loss: 6.118251, real_scores: 0.993948, fake_scores: 0.005539\n",
      "Finish Epoch [38/100], D Loss: 0.713199, G Loss: 15.614459\n",
      "Epoch [39/100], Step:  25600, d_loss: 0.004799, g_loss: 6.538880, real_scores: 0.998210, fake_scores: 0.002991\n",
      "Epoch [39/100], Step:  51200, d_loss: 0.004673, g_loss: 6.602478, real_scores: 0.996760, fake_scores: 0.001420\n",
      "Finish Epoch [39/100], D Loss: 0.405426, G Loss: 20.674869\n",
      "Epoch [40/100], Step:  25600, d_loss: 0.209914, g_loss: 4.948155, real_scores: 0.975847, fake_scores: 0.150740\n",
      "Epoch [40/100], Step:  51200, d_loss: 0.333805, g_loss: 2.226658, real_scores: 0.789524, fake_scores: 0.061702\n",
      "Finish Epoch [40/100], D Loss: 1.586492, G Loss: 11.167863\n",
      "Epoch [41/100], Step:  25600, d_loss: 0.089722, g_loss: 4.590002, real_scores: 0.964736, fake_scores: 0.049145\n",
      "Epoch [41/100], Step:  51200, d_loss: 0.009613, g_loss: 6.855132, real_scores: 0.997592, fake_scores: 0.007132\n",
      "Finish Epoch [41/100], D Loss: 0.814613, G Loss: 14.279633\n",
      "Epoch [42/100], Step:  25600, d_loss: 2.009495, g_loss: 6.050454, real_scores: 0.999032, fake_scores: 0.794219\n",
      "Epoch [42/100], Step:  51200, d_loss: 0.007919, g_loss: 6.118778, real_scores: 0.997518, fake_scores: 0.005376\n",
      "Finish Epoch [42/100], D Loss: 0.420230, G Loss: 16.537025\n",
      "Epoch [43/100], Step:  25600, d_loss: 0.143309, g_loss: 2.986370, real_scores: 0.909906, fake_scores: 0.037733\n",
      "Epoch [43/100], Step:  51200, d_loss: 0.013696, g_loss: 6.065018, real_scores: 0.993276, fake_scores: 0.006832\n",
      "Finish Epoch [43/100], D Loss: 0.995389, G Loss: 12.999390\n",
      "Epoch [44/100], Step:  25600, d_loss: 0.168631, g_loss: 3.450689, real_scores: 0.901702, fake_scores: 0.055331\n",
      "Epoch [44/100], Step:  51200, d_loss: 0.108446, g_loss: 5.086917, real_scores: 0.944306, fake_scores: 0.045348\n",
      "Finish Epoch [44/100], D Loss: 0.959537, G Loss: 13.010274\n",
      "Epoch [45/100], Step:  25600, d_loss: 0.067036, g_loss: 5.098216, real_scores: 0.992832, fake_scores: 0.056007\n",
      "Epoch [45/100], Step:  51200, d_loss: 0.049873, g_loss: 3.738426, real_scores: 0.962328, fake_scores: 0.010061\n",
      "Finish Epoch [45/100], D Loss: 0.958350, G Loss: 12.417235\n",
      "Epoch [46/100], Step:  25600, d_loss: 0.023887, g_loss: 5.251477, real_scores: 0.990825, fake_scores: 0.014400\n",
      "Epoch [46/100], Step:  51200, d_loss: 0.009273, g_loss: 5.898662, real_scores: 0.997438, fake_scores: 0.006635\n",
      "Finish Epoch [46/100], D Loss: 0.435469, G Loss: 14.035238\n",
      "Epoch [47/100], Step:  25600, d_loss: 0.002402, g_loss: 6.633402, real_scores: 0.998339, fake_scores: 0.000736\n",
      "Epoch [47/100], Step:  51200, d_loss: 0.536222, g_loss: 2.270866, real_scores: 0.878272, fake_scores: 0.279214\n",
      "Finish Epoch [47/100], D Loss: 1.070045, G Loss: 13.308680\n",
      "Epoch [48/100], Step:  25600, d_loss: 0.014121, g_loss: 5.577202, real_scores: 0.991065, fake_scores: 0.005023\n",
      "Epoch [48/100], Step:  51200, d_loss: 0.006503, g_loss: 6.545668, real_scores: 0.995845, fake_scores: 0.002315\n",
      "Finish Epoch [48/100], D Loss: 0.303807, G Loss: 14.307922\n",
      "Epoch [49/100], Step:  25600, d_loss: 0.771630, g_loss: 1.212409, real_scores: 0.573740, fake_scores: 0.108037\n",
      "Epoch [49/100], Step:  51200, d_loss: 0.065700, g_loss: 4.348691, real_scores: 0.966327, fake_scores: 0.029605\n",
      "Finish Epoch [49/100], D Loss: 1.239012, G Loss: 9.458375\n",
      "Epoch [50/100], Step:  25600, d_loss: 0.021307, g_loss: 5.730420, real_scores: 0.997842, fake_scores: 0.018616\n",
      "Epoch [50/100], Step:  51200, d_loss: 0.005971, g_loss: 6.477953, real_scores: 0.997419, fake_scores: 0.003365\n",
      "Finish Epoch [50/100], D Loss: 0.432920, G Loss: 13.103281\n",
      "Epoch [51/100], Step:  25600, d_loss: 0.324417, g_loss: 4.224345, real_scores: 0.923408, fake_scores: 0.185328\n",
      "Epoch [51/100], Step:  51200, d_loss: 0.024950, g_loss: 5.205709, real_scores: 0.990807, fake_scores: 0.015388\n",
      "Finish Epoch [51/100], D Loss: 0.850276, G Loss: 11.524526\n",
      "Epoch [52/100], Step:  25600, d_loss: 0.296351, g_loss: 2.977029, real_scores: 0.823613, fake_scores: 0.061467\n",
      "Epoch [52/100], Step:  51200, d_loss: 0.012656, g_loss: 5.540322, real_scores: 0.990219, fake_scores: 0.002753\n",
      "Finish Epoch [52/100], D Loss: 1.017339, G Loss: 9.385715\n",
      "Epoch [53/100], Step:  25600, d_loss: 0.004396, g_loss: 6.053704, real_scores: 0.998567, fake_scores: 0.002943\n",
      "Epoch [53/100], Step:  51200, d_loss: 0.456502, g_loss: 3.249954, real_scores: 0.912034, fake_scores: 0.260382\n",
      "Finish Epoch [53/100], D Loss: 0.563302, G Loss: 11.792051\n",
      "Epoch [54/100], Step:  25600, d_loss: 0.008374, g_loss: 6.122309, real_scores: 0.995194, fake_scores: 0.003513\n",
      "Epoch [54/100], Step:  51200, d_loss: 1.552737, g_loss: 6.136505, real_scores: 0.862758, fake_scores: 0.592723\n",
      "Finish Epoch [54/100], D Loss: 0.894701, G Loss: 9.858773\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(xrange(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        mini_batch = img.size(0)\n",
    "        real_img = img.cuda()\n",
    "        real_labels = torch.ones(mini_batch, 1, 1, 1).cuda()\n",
    "        fake_labels = torch.zeros(mini_batch, 1, 1, 1).cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = criterion(real_out, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).view(-1, 100, 1, 1).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).view(-1, 100, 1, 1).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = criterion(fake_out, real_labels)\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 200 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 64, 64).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 64, 64).cpu().data\n",
    "        save_image(real_images, './cnn_dcgan_img/real_images.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 64, 64).cpu().data\n",
    "    save_image(fake_images, './cnn_dcgan_img/fake_images-{}.png'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/discriminator.pkl')\n",
    "torch.save(g.state_dict(), './ser/generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f607731d690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
