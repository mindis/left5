{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature_x1 = 192\n",
    "num_feature_x2 = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('./datas/faces', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module): # b 3 96 96\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 48 48\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 24 24\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(4, 4),\n",
    "        ) # b 64 6 6\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 6 * 6, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "    \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature_x1, num_feature_x2):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.num_feature_x1 = num_feature_x1\n",
    "        self.num_feature_x2 = num_feature_x2\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature_x1 * num_feature_x2)\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 192 192\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 192 192\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 192 192\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 3, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 3 96 96\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = out.view(x.size(0), 1, self.num_feature_x1, self.num_feature_x2)\n",
    "        out = self.br(out)\n",
    "\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "d = Discriminator()#.cuda(device_ids[0])\n",
    "g = Generator(z_dimension, num_feature_x1, num_feature_x2)#.cuda(device_ids[0])\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=1e-4)\n",
    "# d_optimezer = nn.DataParallel(d_optimezer, device_ids=device_ids)\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=1e-4)\n",
    "# g_optimezer = nn.DataParallel(g_optimezer, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_gan_faces_multip_gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a0f5780e164eaba4e9110e78b76b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step:  32000, d_loss: 0.054164, g_loss: 7.191885, real_scores: 0.975190, fake_scores: 0.007158\n",
      "Finish Epoch [1/1000], D Loss: 21.932961, G Loss: 245.072496\n",
      "Epoch [2/1000], Step:  32000, d_loss: 0.267216, g_loss: 3.399000, real_scores: 0.896402, fake_scores: 0.100556\n",
      "Finish Epoch [2/1000], D Loss: 16.346100, G Loss: 82.266996\n",
      "Epoch [3/1000], Step:  32000, d_loss: 0.392418, g_loss: 2.323717, real_scores: 0.870723, fake_scores: 0.149981\n",
      "Finish Epoch [3/1000], D Loss: 15.015400, G Loss: 47.042996\n",
      "Epoch [4/1000], Step:  32000, d_loss: 0.141008, g_loss: 4.168742, real_scores: 0.932382, fake_scores: 0.027019\n",
      "Finish Epoch [4/1000], D Loss: 11.034464, G Loss: 32.813597\n",
      "Epoch [5/1000], Step:  32000, d_loss: 0.476203, g_loss: 2.338293, real_scores: 0.882729, fake_scores: 0.233534\n",
      "Finish Epoch [5/1000], D Loss: 7.580066, G Loss: 29.334026\n",
      "Epoch [6/1000], Step:  32000, d_loss: 0.444863, g_loss: 1.939400, real_scores: 0.814008, fake_scores: 0.170997\n",
      "Finish Epoch [6/1000], D Loss: 6.906185, G Loss: 21.558560\n",
      "Epoch [7/1000], Step:  32000, d_loss: 0.777052, g_loss: 1.476164, real_scores: 0.808215, fake_scores: 0.356765\n",
      "Finish Epoch [7/1000], D Loss: 8.041311, G Loss: 14.715541\n",
      "Epoch [8/1000], Step:  32000, d_loss: 0.959725, g_loss: 1.186244, real_scores: 0.685889, fake_scores: 0.386870\n",
      "Finish Epoch [8/1000], D Loss: 8.393087, G Loss: 9.774675\n",
      "Epoch [9/1000], Step:  32000, d_loss: 0.942829, g_loss: 1.789111, real_scores: 0.680783, fake_scores: 0.335301\n",
      "Finish Epoch [9/1000], D Loss: 7.763824, G Loss: 9.140645\n",
      "Epoch [10/1000], Step:  32000, d_loss: 0.812809, g_loss: 1.148209, real_scores: 0.740202, fake_scores: 0.345540\n",
      "Finish Epoch [10/1000], D Loss: 6.660039, G Loss: 7.844569\n",
      "Epoch [11/1000], Step:  32000, d_loss: 1.266690, g_loss: 1.109725, real_scores: 0.634593, fake_scores: 0.414344\n",
      "Finish Epoch [11/1000], D Loss: 6.821856, G Loss: 6.542781\n",
      "Epoch [12/1000], Step:  32000, d_loss: 1.137578, g_loss: 1.062133, real_scores: 0.624485, fake_scores: 0.419499\n",
      "Finish Epoch [12/1000], D Loss: 5.886570, G Loss: 6.137597\n",
      "Epoch [13/1000], Step:  32000, d_loss: 1.238707, g_loss: 0.773156, real_scores: 0.645072, fake_scores: 0.504959\n",
      "Finish Epoch [13/1000], D Loss: 5.670430, G Loss: 5.594037\n",
      "Epoch [14/1000], Step:  32000, d_loss: 1.094172, g_loss: 1.186569, real_scores: 0.601461, fake_scores: 0.338156\n",
      "Finish Epoch [14/1000], D Loss: 5.030136, G Loss: 5.079765\n",
      "Epoch [15/1000], Step:  32000, d_loss: 0.991288, g_loss: 1.038822, real_scores: 0.661201, fake_scores: 0.391664\n",
      "Finish Epoch [15/1000], D Loss: 4.496945, G Loss: 4.423289\n",
      "Epoch [16/1000], Step:  32000, d_loss: 1.002416, g_loss: 1.685399, real_scores: 0.676367, fake_scores: 0.332563\n",
      "Finish Epoch [16/1000], D Loss: 3.773960, G Loss: 5.707053\n",
      "Epoch [17/1000], Step:  32000, d_loss: 0.822369, g_loss: 1.201684, real_scores: 0.715991, fake_scores: 0.328753\n",
      "Finish Epoch [17/1000], D Loss: 3.664729, G Loss: 5.587293\n",
      "Epoch [18/1000], Step:  32000, d_loss: 0.996663, g_loss: 1.171940, real_scores: 0.733082, fake_scores: 0.397157\n",
      "Finish Epoch [18/1000], D Loss: 3.129498, G Loss: 5.029280\n",
      "Epoch [19/1000], Step:  32000, d_loss: 0.931779, g_loss: 1.017346, real_scores: 0.711236, fake_scores: 0.327866\n",
      "Finish Epoch [19/1000], D Loss: 3.064098, G Loss: 5.315170\n",
      "Epoch [20/1000], Step:  32000, d_loss: 0.887243, g_loss: 1.218125, real_scores: 0.711945, fake_scores: 0.313665\n",
      "Finish Epoch [20/1000], D Loss: 2.609326, G Loss: 4.640972\n",
      "Epoch [21/1000], Step:  32000, d_loss: 0.570862, g_loss: 1.700923, real_scores: 0.840847, fake_scores: 0.280750\n",
      "Finish Epoch [21/1000], D Loss: 2.310271, G Loss: 5.109385\n",
      "Epoch [22/1000], Step:  32000, d_loss: 0.696386, g_loss: 0.959962, real_scores: 0.737979, fake_scores: 0.235632\n",
      "Finish Epoch [22/1000], D Loss: 2.120362, G Loss: 5.122056\n",
      "Epoch [23/1000], Step:  32000, d_loss: 0.724416, g_loss: 1.337890, real_scores: 0.760812, fake_scores: 0.261644\n",
      "Finish Epoch [23/1000], D Loss: 1.988835, G Loss: 5.050153\n",
      "Epoch [24/1000], Step:  32000, d_loss: 0.734079, g_loss: 1.527646, real_scores: 0.700904, fake_scores: 0.165777\n",
      "Finish Epoch [24/1000], D Loss: 1.802672, G Loss: 4.919244\n",
      "Epoch [25/1000], Step:  32000, d_loss: 0.729445, g_loss: 2.221073, real_scores: 0.758674, fake_scores: 0.230651\n",
      "Finish Epoch [25/1000], D Loss: 1.707957, G Loss: 4.846307\n",
      "Epoch [26/1000], Step:  32000, d_loss: 0.756120, g_loss: 1.823113, real_scores: 0.742015, fake_scores: 0.181018\n",
      "Finish Epoch [26/1000], D Loss: 1.679005, G Loss: 4.592221\n",
      "Epoch [27/1000], Step:  32000, d_loss: 0.594746, g_loss: 1.594003, real_scores: 0.852140, fake_scores: 0.290466\n",
      "Finish Epoch [27/1000], D Loss: 1.644846, G Loss: 4.292323\n",
      "Epoch [28/1000], Step:  32000, d_loss: 0.951026, g_loss: 1.720218, real_scores: 0.832978, fake_scores: 0.391742\n",
      "Finish Epoch [28/1000], D Loss: 1.715882, G Loss: 4.140431\n",
      "Epoch [29/1000], Step:  32000, d_loss: 0.716814, g_loss: 1.462243, real_scores: 0.830768, fake_scores: 0.345339\n",
      "Finish Epoch [29/1000], D Loss: 1.674834, G Loss: 3.830972\n",
      "Epoch [30/1000], Step:  32000, d_loss: 0.710714, g_loss: 2.364713, real_scores: 0.730161, fake_scores: 0.184351\n",
      "Finish Epoch [30/1000], D Loss: 1.557267, G Loss: 3.686235\n",
      "Epoch [31/1000], Step:  32000, d_loss: 0.804140, g_loss: 2.156279, real_scores: 0.737216, fake_scores: 0.265202\n",
      "Finish Epoch [31/1000], D Loss: 1.497077, G Loss: 3.700573\n",
      "Epoch [32/1000], Step:  32000, d_loss: 0.914589, g_loss: 1.751216, real_scores: 0.732532, fake_scores: 0.265527\n",
      "Finish Epoch [32/1000], D Loss: 1.383789, G Loss: 3.702325\n",
      "Epoch [33/1000], Step:  32000, d_loss: 0.584882, g_loss: 1.892667, real_scores: 0.815274, fake_scores: 0.246138\n",
      "Finish Epoch [33/1000], D Loss: 1.333504, G Loss: 3.588046\n",
      "Epoch [34/1000], Step:  32000, d_loss: 0.628732, g_loss: 2.704448, real_scores: 0.769963, fake_scores: 0.182828\n",
      "Finish Epoch [34/1000], D Loss: 1.284595, G Loss: 3.571570\n",
      "Epoch [35/1000], Step:  32000, d_loss: 0.585184, g_loss: 1.626266, real_scores: 0.754775, fake_scores: 0.178875\n",
      "Finish Epoch [35/1000], D Loss: 1.212990, G Loss: 3.549583\n",
      "Epoch [36/1000], Step:  32000, d_loss: 0.635245, g_loss: 2.319367, real_scores: 0.866819, fake_scores: 0.300680\n",
      "Finish Epoch [36/1000], D Loss: 1.135154, G Loss: 3.487320\n",
      "Epoch [37/1000], Step:  32000, d_loss: 0.649232, g_loss: 1.119785, real_scores: 0.807571, fake_scores: 0.259685\n",
      "Finish Epoch [37/1000], D Loss: 1.094861, G Loss: 3.487520\n",
      "Epoch [38/1000], Step:  32000, d_loss: 0.534657, g_loss: 2.516876, real_scores: 0.799102, fake_scores: 0.187342\n",
      "Finish Epoch [38/1000], D Loss: 1.026707, G Loss: 3.452271\n",
      "Epoch [39/1000], Step:  32000, d_loss: 0.868947, g_loss: 1.886034, real_scores: 0.818239, fake_scores: 0.409049\n",
      "Finish Epoch [39/1000], D Loss: 0.976917, G Loss: 3.432908\n",
      "Epoch [40/1000], Step:  32000, d_loss: 0.526137, g_loss: 2.334141, real_scores: 0.810155, fake_scores: 0.167323\n",
      "Finish Epoch [40/1000], D Loss: 0.937801, G Loss: 3.424442\n",
      "Epoch [41/1000], Step:  32000, d_loss: 0.404418, g_loss: 1.934147, real_scores: 0.893845, fake_scores: 0.201959\n",
      "Finish Epoch [41/1000], D Loss: 0.886332, G Loss: 3.378893\n",
      "Epoch [42/1000], Step:  32000, d_loss: 0.580141, g_loss: 2.066709, real_scores: 0.879892, fake_scores: 0.272489\n",
      "Finish Epoch [42/1000], D Loss: 0.876352, G Loss: 3.385938\n",
      "Epoch [43/1000], Step:  32000, d_loss: 0.549349, g_loss: 2.600081, real_scores: 0.815371, fake_scores: 0.172117\n",
      "Finish Epoch [43/1000], D Loss: 0.814447, G Loss: 3.360352\n",
      "Epoch [44/1000], Step:  32000, d_loss: 0.677112, g_loss: 2.173352, real_scores: 0.758689, fake_scores: 0.171565\n",
      "Finish Epoch [44/1000], D Loss: 0.780985, G Loss: 3.347587\n",
      "Epoch [45/1000], Step:  32000, d_loss: 0.530930, g_loss: 2.155580, real_scores: 0.754358, fake_scores: 0.063724\n",
      "Finish Epoch [45/1000], D Loss: 0.743033, G Loss: 3.310001\n",
      "Epoch [46/1000], Step:  32000, d_loss: 0.415469, g_loss: 2.957186, real_scores: 0.812855, fake_scores: 0.065451\n",
      "Finish Epoch [46/1000], D Loss: 0.710102, G Loss: 3.360673\n",
      "Epoch [47/1000], Step:  32000, d_loss: 0.613366, g_loss: 2.545344, real_scores: 0.739196, fake_scores: 0.085764\n",
      "Finish Epoch [47/1000], D Loss: 0.674107, G Loss: 3.269056\n",
      "Epoch [48/1000], Step:  32000, d_loss: 0.513537, g_loss: 1.828726, real_scores: 0.883566, fake_scores: 0.235822\n",
      "Finish Epoch [48/1000], D Loss: 0.643182, G Loss: 3.378579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/1000], Step:  32000, d_loss: 0.515902, g_loss: 1.914449, real_scores: 0.876801, fake_scores: 0.240451\n",
      "Finish Epoch [49/1000], D Loss: 0.605097, G Loss: 3.303579\n",
      "Epoch [50/1000], Step:  32000, d_loss: 0.319007, g_loss: 2.090187, real_scores: 0.930550, fake_scores: 0.166616\n",
      "Finish Epoch [50/1000], D Loss: 0.576846, G Loss: 3.320785\n",
      "Epoch [51/1000], Step:  32000, d_loss: 0.538726, g_loss: 3.460716, real_scores: 0.761366, fake_scores: 0.032149\n",
      "Finish Epoch [51/1000], D Loss: 0.536505, G Loss: 3.378083\n",
      "Epoch [52/1000], Step:  32000, d_loss: 0.356284, g_loss: 2.320139, real_scores: 0.877112, fake_scores: 0.132763\n",
      "Finish Epoch [52/1000], D Loss: 0.513332, G Loss: 3.336861\n",
      "Epoch [53/1000], Step:  32000, d_loss: 0.506870, g_loss: 2.407567, real_scores: 0.846604, fake_scores: 0.190875\n",
      "Finish Epoch [53/1000], D Loss: 0.491287, G Loss: 3.404518\n",
      "Epoch [54/1000], Step:  32000, d_loss: 0.525008, g_loss: 1.897930, real_scores: 0.838367, fake_scores: 0.151591\n",
      "Finish Epoch [54/1000], D Loss: 0.480999, G Loss: 3.343300\n",
      "Epoch [55/1000], Step:  32000, d_loss: 0.302763, g_loss: 3.382003, real_scores: 0.905387, fake_scores: 0.139147\n",
      "Finish Epoch [55/1000], D Loss: 0.444923, G Loss: 3.343513\n",
      "Epoch [56/1000], Step:  32000, d_loss: 0.334214, g_loss: 3.232779, real_scores: 0.894885, fake_scores: 0.139865\n",
      "Finish Epoch [56/1000], D Loss: 0.444244, G Loss: 3.341588\n",
      "Epoch [57/1000], Step:  32000, d_loss: 0.335474, g_loss: 2.066019, real_scores: 0.895005, fake_scores: 0.140031\n",
      "Finish Epoch [57/1000], D Loss: 0.421877, G Loss: 3.277398\n",
      "Epoch [58/1000], Step:  32000, d_loss: 0.432381, g_loss: 3.874087, real_scores: 0.869204, fake_scores: 0.116601\n",
      "Finish Epoch [58/1000], D Loss: 0.406211, G Loss: 3.247196\n",
      "Epoch [59/1000], Step:  32000, d_loss: 0.405750, g_loss: 3.621631, real_scores: 0.826506, fake_scores: 0.080417\n",
      "Finish Epoch [59/1000], D Loss: 0.403390, G Loss: 3.214357\n",
      "Epoch [60/1000], Step:  32000, d_loss: 0.539536, g_loss: 3.784718, real_scores: 0.805172, fake_scores: 0.074195\n",
      "Finish Epoch [60/1000], D Loss: 0.381364, G Loss: 3.235035\n",
      "Epoch [61/1000], Step:  32000, d_loss: 0.400199, g_loss: 3.651800, real_scores: 0.839028, fake_scores: 0.072381\n",
      "Finish Epoch [61/1000], D Loss: 0.376685, G Loss: 3.118494\n",
      "Epoch [62/1000], Step:  32000, d_loss: 0.429057, g_loss: 2.849615, real_scores: 0.860023, fake_scores: 0.158455\n",
      "Finish Epoch [62/1000], D Loss: 0.374292, G Loss: 3.082621\n",
      "Epoch [63/1000], Step:  32000, d_loss: 0.482053, g_loss: 3.168115, real_scores: 0.942107, fake_scores: 0.236255\n",
      "Finish Epoch [63/1000], D Loss: 0.391242, G Loss: 3.061525\n",
      "Epoch [64/1000], Step:  32000, d_loss: 0.309723, g_loss: 3.376160, real_scores: 0.887937, fake_scores: 0.115677\n",
      "Finish Epoch [64/1000], D Loss: 0.378075, G Loss: 2.932187\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(xrange(num_epochs)):\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        real_labels = torch.ones(img.size(0), 1).cuda()\n",
    "        fake_labels = torch.zeros(img.size(0), 1).cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = criterion(real_out, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = criterion(fake_out, real_labels)\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = epoch * total_count + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 500 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 3, 96, 96).cpu().data\n",
    "        save_image(real_images, './cnn_gan_faces_multip_gpu/real_images.png')\n",
    "\n",
    "    fake_images = fake_img.view(-1, 3, 96, 96).cpu().data\n",
    "    save_image(fake_images, './cnn_gan_faces_multip_gpu/fake_images-{}.png'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/faces_discriminator.pkl')\n",
    "torch.save(g.state_dict(), './ser/faces_generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
