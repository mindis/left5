{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 200\n",
    "\n",
    "z_dimension = 100\n",
    "\n",
    "img_shape = (1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(10, 10)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(10 + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(z_dimension + 10, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "adversarial_loss = nn.MSELoss()\n",
    "\n",
    "D_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "G_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = torch.from_numpy(np.arange(10)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cgan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"save_images/cgan\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c240421c3a204c9aa07575e2f4eed7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Step:  38400, d_loss: 5.032085, g_loss: 0.045761, real_scores: 4.352533, fake_scores: 0.959923\n",
      "Finish Epoch [1/200], D Loss: 672.894625, G Loss: 56.092402\n",
      "Epoch [2/200], Step:  38400, d_loss: 4.713851, g_loss: 0.082458, real_scores: 4.699137, fake_scores: 1.013919\n",
      "Finish Epoch [2/200], D Loss: 340.268344, G Loss: 43.904060\n",
      "Epoch [3/200], Step:  38400, d_loss: 6.079758, g_loss: 1.934808, real_scores: 2.974598, fake_scores: -0.343483\n",
      "Finish Epoch [3/200], D Loss: 226.891616, G Loss: 34.252754\n",
      "Epoch [4/200], Step:  38400, d_loss: 5.129977, g_loss: 0.422094, real_scores: 4.062723, fake_scores: 0.532064\n",
      "Finish Epoch [4/200], D Loss: 166.580704, G Loss: 27.087468\n",
      "Epoch [5/200], Step:  38400, d_loss: 5.382316, g_loss: 0.840755, real_scores: 3.673585, fake_scores: 0.118331\n",
      "Finish Epoch [5/200], D Loss: 131.034551, G Loss: 20.906386\n",
      "Epoch [6/200], Step:  38400, d_loss: 5.416888, g_loss: 0.486483, real_scores: 4.292892, fake_scores: 0.501630\n",
      "Finish Epoch [6/200], D Loss: 109.608798, G Loss: 17.348299\n",
      "Epoch [7/200], Step:  38400, d_loss: 6.192887, g_loss: 1.293334, real_scores: 3.319547, fake_scores: -0.069634\n",
      "Finish Epoch [7/200], D Loss: 94.175542, G Loss: 15.237741\n",
      "Epoch [8/200], Step:  38400, d_loss: 5.389965, g_loss: 0.400547, real_scores: 4.502464, fake_scores: 0.696226\n",
      "Finish Epoch [8/200], D Loss: 83.054484, G Loss: 13.543396\n",
      "Epoch [9/200], Step:  38400, d_loss: 5.477056, g_loss: 0.349436, real_scores: 4.469396, fake_scores: 1.025428\n",
      "Finish Epoch [9/200], D Loss: 74.053637, G Loss: 12.150812\n",
      "Epoch [10/200], Step:  38400, d_loss: 5.312647, g_loss: 0.426765, real_scores: 4.527295, fake_scores: 0.849486\n",
      "Finish Epoch [10/200], D Loss: 66.967344, G Loss: 11.650777\n",
      "Epoch [11/200], Step:  38400, d_loss: 4.714012, g_loss: 0.633772, real_scores: 3.638509, fake_scores: 0.356513\n",
      "Finish Epoch [11/200], D Loss: 61.163121, G Loss: 10.618722\n",
      "Epoch [12/200], Step:  38400, d_loss: 5.874755, g_loss: 1.166471, real_scores: 3.247600, fake_scores: -0.040899\n",
      "Finish Epoch [12/200], D Loss: 56.000630, G Loss: 10.085468\n",
      "Epoch [13/200], Step:  38400, d_loss: 4.835708, g_loss: 0.818856, real_scores: 4.236354, fake_scores: 0.316349\n",
      "Finish Epoch [13/200], D Loss: 51.576971, G Loss: 9.136351\n",
      "Epoch [14/200], Step:  38400, d_loss: 5.047661, g_loss: 0.755534, real_scores: 4.089444, fake_scores: 0.435273\n",
      "Finish Epoch [14/200], D Loss: 48.301599, G Loss: 8.562009\n",
      "Epoch [15/200], Step:  38400, d_loss: 5.352248, g_loss: 1.151840, real_scores: 3.616191, fake_scores: 0.049446\n",
      "Finish Epoch [15/200], D Loss: 44.708844, G Loss: 8.060582\n",
      "Epoch [16/200], Step:  38400, d_loss: 5.352894, g_loss: 0.935113, real_scores: 3.926367, fake_scores: 0.360701\n",
      "Finish Epoch [16/200], D Loss: 42.335541, G Loss: 7.566612\n",
      "Epoch [17/200], Step:  38400, d_loss: 5.120978, g_loss: 0.528107, real_scores: 4.614197, fake_scores: 1.094687\n",
      "Finish Epoch [17/200], D Loss: 39.858964, G Loss: 6.991796\n",
      "Epoch [18/200], Step:  38400, d_loss: 4.833106, g_loss: 0.765908, real_scores: 3.808304, fake_scores: 0.480306\n",
      "Finish Epoch [18/200], D Loss: 37.955203, G Loss: 6.773875\n",
      "Epoch [19/200], Step:  38400, d_loss: 5.794233, g_loss: 1.048573, real_scores: 3.636421, fake_scores: 0.277087\n",
      "Finish Epoch [19/200], D Loss: 36.151103, G Loss: 6.635234\n",
      "Epoch [20/200], Step:  38400, d_loss: 4.384513, g_loss: 0.882994, real_scores: 3.949628, fake_scores: 0.249376\n",
      "Finish Epoch [20/200], D Loss: 34.061983, G Loss: 6.411165\n",
      "Epoch [21/200], Step:  38400, d_loss: 5.162216, g_loss: 0.742520, real_scores: 4.390822, fake_scores: 0.555844\n",
      "Finish Epoch [21/200], D Loss: 32.624591, G Loss: 5.995025\n",
      "Epoch [22/200], Step:  38400, d_loss: 4.972260, g_loss: 1.610293, real_scores: 3.420508, fake_scores: 0.094427\n",
      "Finish Epoch [22/200], D Loss: 31.532828, G Loss: 5.539651\n",
      "Epoch [23/200], Step:  38400, d_loss: 4.851406, g_loss: 1.453466, real_scores: 3.394155, fake_scores: -0.004964\n",
      "Finish Epoch [23/200], D Loss: 30.204892, G Loss: 5.554118\n",
      "Epoch [24/200], Step:  38400, d_loss: 4.858436, g_loss: 0.723296, real_scores: 4.080030, fake_scores: 0.586632\n",
      "Finish Epoch [24/200], D Loss: 28.773777, G Loss: 5.414873\n",
      "Epoch [25/200], Step:  38400, d_loss: 5.069416, g_loss: 1.188637, real_scores: 3.500875, fake_scores: -0.093564\n",
      "Finish Epoch [25/200], D Loss: 27.619372, G Loss: 4.959791\n",
      "Epoch [26/200], Step:  38400, d_loss: 5.712860, g_loss: 0.758430, real_scores: 4.295982, fake_scores: 0.643680\n",
      "Finish Epoch [26/200], D Loss: 26.622551, G Loss: 4.970378\n",
      "Epoch [27/200], Step:  38400, d_loss: 5.871833, g_loss: 0.585494, real_scores: 4.184350, fake_scores: 0.919845\n",
      "Finish Epoch [27/200], D Loss: 25.851274, G Loss: 4.699584\n",
      "Epoch [28/200], Step:  38400, d_loss: 5.041636, g_loss: 0.560905, real_scores: 3.932041, fake_scores: 0.744362\n",
      "Finish Epoch [28/200], D Loss: 24.819380, G Loss: 4.582969\n",
      "Epoch [29/200], Step:  38400, d_loss: 5.889882, g_loss: 1.287261, real_scores: 3.322256, fake_scores: 0.048630\n",
      "Finish Epoch [29/200], D Loss: 23.913830, G Loss: 4.311379\n",
      "Epoch [30/200], Step:  38400, d_loss: 6.038869, g_loss: 1.195887, real_scores: 3.410434, fake_scores: 0.089730\n",
      "Finish Epoch [30/200], D Loss: 23.160539, G Loss: 4.272444\n",
      "Epoch [31/200], Step:  38400, d_loss: 5.702106, g_loss: 0.554580, real_scores: 3.799581, fake_scores: 0.804412\n",
      "Finish Epoch [31/200], D Loss: 22.453308, G Loss: 4.091495\n",
      "Epoch [32/200], Step:  38400, d_loss: 5.886791, g_loss: 2.037008, real_scores: 3.746774, fake_scores: -0.145506\n",
      "Finish Epoch [32/200], D Loss: 21.692453, G Loss: 4.020234\n",
      "Epoch [33/200], Step:  38400, d_loss: 5.232892, g_loss: 1.213883, real_scores: 3.811606, fake_scores: 0.206540\n",
      "Finish Epoch [33/200], D Loss: 21.080506, G Loss: 3.722926\n",
      "Epoch [34/200], Step:  38400, d_loss: 6.122834, g_loss: 0.734703, real_scores: 4.245602, fake_scores: 1.131145\n",
      "Finish Epoch [34/200], D Loss: 20.542129, G Loss: 3.548531\n",
      "Epoch [35/200], Step:  38400, d_loss: 5.771880, g_loss: 0.612459, real_scores: 4.056751, fake_scores: 0.788265\n",
      "Finish Epoch [35/200], D Loss: 19.786872, G Loss: 3.536501\n",
      "Epoch [36/200], Step:  38400, d_loss: 5.675812, g_loss: 0.597979, real_scores: 4.283115, fake_scores: 1.004392\n",
      "Finish Epoch [36/200], D Loss: 19.312556, G Loss: 3.418271\n",
      "Epoch [37/200], Step:  38400, d_loss: 6.430556, g_loss: 1.300056, real_scores: 4.833938, fake_scores: 1.467862\n",
      "Finish Epoch [37/200], D Loss: 18.865262, G Loss: 3.359528\n",
      "Epoch [38/200], Step:  38400, d_loss: 4.628477, g_loss: 0.712097, real_scores: 3.697365, fake_scores: 0.436852\n",
      "Finish Epoch [38/200], D Loss: 18.125316, G Loss: 3.311377\n",
      "Epoch [39/200], Step:  38400, d_loss: 6.023696, g_loss: 1.628999, real_scores: 3.313110, fake_scores: -0.094921\n",
      "Finish Epoch [39/200], D Loss: 17.715909, G Loss: 3.217815\n",
      "Epoch [40/200], Step:  38400, d_loss: 5.530689, g_loss: 1.406671, real_scores: 3.207366, fake_scores: -0.111911\n",
      "Finish Epoch [40/200], D Loss: 17.324724, G Loss: 3.073332\n",
      "Epoch [41/200], Step:  38400, d_loss: 6.215833, g_loss: 0.661691, real_scores: 4.431670, fake_scores: 1.037334\n",
      "Finish Epoch [41/200], D Loss: 16.920227, G Loss: 2.999030\n",
      "Epoch [42/200], Step:  38400, d_loss: 4.868381, g_loss: 0.926254, real_scores: 3.780351, fake_scores: 0.458490\n",
      "Finish Epoch [42/200], D Loss: 16.708590, G Loss: 2.979628\n",
      "Epoch [43/200], Step:  38400, d_loss: 5.196582, g_loss: 0.881136, real_scores: 3.479760, fake_scores: 0.234576\n",
      "Finish Epoch [43/200], D Loss: 16.149358, G Loss: 2.787494\n",
      "Epoch [44/200], Step:  38400, d_loss: 5.896031, g_loss: 1.052261, real_scores: 3.630263, fake_scores: 0.202263\n",
      "Finish Epoch [44/200], D Loss: 15.832793, G Loss: 2.745884\n",
      "Epoch [45/200], Step:  38400, d_loss: 6.009654, g_loss: 0.577281, real_scores: 4.557118, fake_scores: 0.982138\n",
      "Finish Epoch [45/200], D Loss: 15.508348, G Loss: 2.690134\n",
      "Epoch [46/200], Step:  38400, d_loss: 4.897533, g_loss: 0.499508, real_scores: 4.518600, fake_scores: 0.837844\n",
      "Finish Epoch [46/200], D Loss: 15.121771, G Loss: 2.691162\n",
      "Epoch [47/200], Step:  38400, d_loss: 5.570774, g_loss: 0.675153, real_scores: 4.332195, fake_scores: 0.641343\n",
      "Finish Epoch [47/200], D Loss: 14.857482, G Loss: 2.636874\n",
      "Epoch [48/200], Step:  38400, d_loss: 5.555553, g_loss: 0.671980, real_scores: 3.895530, fake_scores: 0.657598\n",
      "Finish Epoch [48/200], D Loss: 14.500322, G Loss: 2.541636\n",
      "Epoch [49/200], Step:  38400, d_loss: 5.446046, g_loss: 0.588960, real_scores: 4.310831, fake_scores: 1.046183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Epoch [49/200], D Loss: 14.124173, G Loss: 2.462198\n",
      "Epoch [50/200], Step:  38400, d_loss: 5.241833, g_loss: 1.304793, real_scores: 3.758764, fake_scores: 0.191509\n",
      "Finish Epoch [50/200], D Loss: 13.934399, G Loss: 2.470427\n",
      "Epoch [51/200], Step:  38400, d_loss: 5.497291, g_loss: 0.772377, real_scores: 4.241997, fake_scores: 1.040512\n",
      "Finish Epoch [51/200], D Loss: 13.738873, G Loss: 2.419567\n",
      "Epoch [52/200], Step:  38400, d_loss: 5.698829, g_loss: 0.928124, real_scores: 4.110771, fake_scores: 0.632853\n",
      "Finish Epoch [52/200], D Loss: 13.356619, G Loss: 2.315060\n",
      "Epoch [53/200], Step:  38400, d_loss: 5.724307, g_loss: 1.205686, real_scores: 3.541277, fake_scores: 0.172730\n",
      "Finish Epoch [53/200], D Loss: 13.152846, G Loss: 2.296179\n",
      "Epoch [54/200], Step:  38400, d_loss: 5.463612, g_loss: 0.719357, real_scores: 4.555578, fake_scores: 1.279172\n",
      "Finish Epoch [54/200], D Loss: 12.915851, G Loss: 2.339034\n",
      "Epoch [55/200], Step:  38400, d_loss: 5.101917, g_loss: 1.246964, real_scores: 3.343451, fake_scores: 0.126192\n",
      "Finish Epoch [55/200], D Loss: 12.575209, G Loss: 2.311651\n",
      "Epoch [56/200], Step:  38400, d_loss: 5.140078, g_loss: 0.955136, real_scores: 3.777596, fake_scores: 0.318897\n",
      "Finish Epoch [56/200], D Loss: 12.481178, G Loss: 2.264169\n",
      "Epoch [57/200], Step:  38400, d_loss: 5.030419, g_loss: 0.867260, real_scores: 4.062793, fake_scores: 0.340772\n",
      "Finish Epoch [57/200], D Loss: 12.179446, G Loss: 2.195766\n",
      "Epoch [58/200], Step:  38400, d_loss: 5.564684, g_loss: 0.629461, real_scores: 3.995242, fake_scores: 0.802939\n",
      "Finish Epoch [58/200], D Loss: 12.055712, G Loss: 2.127995\n",
      "Epoch [59/200], Step:  38400, d_loss: 6.648097, g_loss: 2.152670, real_scores: 2.938975, fake_scores: -0.229100\n",
      "Finish Epoch [59/200], D Loss: 11.695202, G Loss: 2.116469\n",
      "Epoch [60/200], Step:  38400, d_loss: 5.337988, g_loss: 0.930635, real_scores: 3.912363, fake_scores: 0.517881\n",
      "Finish Epoch [60/200], D Loss: 11.536367, G Loss: 2.061927\n",
      "Epoch [61/200], Step:  38400, d_loss: 5.590005, g_loss: 1.016687, real_scores: 3.688784, fake_scores: 0.403829\n",
      "Finish Epoch [61/200], D Loss: 11.343053, G Loss: 2.071265\n",
      "Epoch [62/200], Step:  38400, d_loss: 5.587487, g_loss: 0.663312, real_scores: 4.168739, fake_scores: 0.817273\n",
      "Finish Epoch [62/200], D Loss: 11.051905, G Loss: 2.012930\n",
      "Epoch [63/200], Step:  38400, d_loss: 4.478177, g_loss: 1.137705, real_scores: 3.412504, fake_scores: 0.171817\n",
      "Finish Epoch [63/200], D Loss: 10.946828, G Loss: 1.981936\n",
      "Epoch [64/200], Step:  38400, d_loss: 5.898560, g_loss: 0.535365, real_scores: 4.163770, fake_scores: 0.889236\n",
      "Finish Epoch [64/200], D Loss: 10.829355, G Loss: 1.963409\n",
      "Epoch [65/200], Step:  38400, d_loss: 5.061592, g_loss: 0.806642, real_scores: 3.944577, fake_scores: 0.351209\n",
      "Finish Epoch [65/200], D Loss: 10.597062, G Loss: 1.923181\n",
      "Epoch [66/200], Step:  38400, d_loss: 5.122551, g_loss: 0.616071, real_scores: 4.043470, fake_scores: 0.913770\n",
      "Finish Epoch [66/200], D Loss: 10.441332, G Loss: 1.845341\n",
      "Epoch [67/200], Step:  38400, d_loss: 5.122522, g_loss: 0.679580, real_scores: 4.178522, fake_scores: 0.742691\n",
      "Finish Epoch [67/200], D Loss: 10.272029, G Loss: 1.864722\n",
      "Epoch [68/200], Step:  38400, d_loss: 4.934026, g_loss: 1.016291, real_scores: 3.747443, fake_scores: 0.185456\n",
      "Finish Epoch [68/200], D Loss: 10.056939, G Loss: 1.875190\n",
      "Epoch [69/200], Step:  38400, d_loss: 5.201087, g_loss: 0.785825, real_scores: 3.575013, fake_scores: 0.400700\n",
      "Finish Epoch [69/200], D Loss: 9.941202, G Loss: 1.778517\n",
      "Epoch [70/200], Step:  38400, d_loss: 4.808604, g_loss: 1.080858, real_scores: 3.893367, fake_scores: 0.246594\n",
      "Finish Epoch [70/200], D Loss: 9.734296, G Loss: 1.794061\n",
      "Epoch [71/200], Step:  38400, d_loss: 4.657610, g_loss: 0.745362, real_scores: 3.981033, fake_scores: 0.642941\n",
      "Finish Epoch [71/200], D Loss: 9.627084, G Loss: 1.791205\n",
      "Epoch [72/200], Step:  38400, d_loss: 5.280357, g_loss: 0.663725, real_scores: 4.008451, fake_scores: 0.421115\n",
      "Finish Epoch [72/200], D Loss: 9.549453, G Loss: 1.735955\n",
      "Epoch [73/200], Step:  38400, d_loss: 5.575070, g_loss: 1.197957, real_scores: 3.745989, fake_scores: 0.169390\n",
      "Finish Epoch [73/200], D Loss: 9.404335, G Loss: 1.710526\n",
      "Epoch [74/200], Step:  38400, d_loss: 4.820202, g_loss: 0.728560, real_scores: 4.171789, fake_scores: 0.503482\n",
      "Finish Epoch [74/200], D Loss: 9.285572, G Loss: 1.657073\n",
      "Epoch [75/200], Step:  38400, d_loss: 5.288066, g_loss: 0.814271, real_scores: 4.323885, fake_scores: 0.859219\n",
      "Finish Epoch [75/200], D Loss: 9.160170, G Loss: 1.650538\n",
      "Epoch [76/200], Step:  38400, d_loss: 4.963400, g_loss: 0.672737, real_scores: 4.292698, fake_scores: 0.733085\n",
      "Finish Epoch [76/200], D Loss: 9.062389, G Loss: 1.634744\n",
      "Epoch [77/200], Step:  38400, d_loss: 5.672643, g_loss: 0.755853, real_scores: 4.145505, fake_scores: 0.791535\n",
      "Finish Epoch [77/200], D Loss: 8.965514, G Loss: 1.607157\n",
      "Epoch [78/200], Step:  38400, d_loss: 4.356820, g_loss: 1.055265, real_scores: 3.744332, fake_scores: 0.180777\n",
      "Finish Epoch [78/200], D Loss: 8.840577, G Loss: 1.608537\n",
      "Epoch [79/200], Step:  38400, d_loss: 5.045123, g_loss: 0.825999, real_scores: 4.101310, fake_scores: 0.674311\n",
      "Finish Epoch [79/200], D Loss: 8.681378, G Loss: 1.628838\n",
      "Epoch [80/200], Step:  38400, d_loss: 5.371671, g_loss: 0.847992, real_scores: 4.534259, fake_scores: 0.632478\n",
      "Finish Epoch [80/200], D Loss: 8.565826, G Loss: 1.553361\n",
      "Epoch [81/200], Step:  38400, d_loss: 4.906951, g_loss: 0.889843, real_scores: 3.996611, fake_scores: 0.446294\n",
      "Finish Epoch [81/200], D Loss: 8.476689, G Loss: 1.543930\n",
      "Epoch [82/200], Step:  38400, d_loss: 5.562741, g_loss: 0.623254, real_scores: 4.121849, fake_scores: 0.841830\n",
      "Finish Epoch [82/200], D Loss: 8.364275, G Loss: 1.566581\n",
      "Epoch [83/200], Step:  38400, d_loss: 6.301095, g_loss: 2.059165, real_scores: 3.105505, fake_scores: -0.124437\n",
      "Finish Epoch [83/200], D Loss: 8.254075, G Loss: 1.523359\n",
      "Epoch [84/200], Step:  38400, d_loss: 5.271662, g_loss: 0.822908, real_scores: 4.169214, fake_scores: 0.648061\n",
      "Finish Epoch [84/200], D Loss: 8.103142, G Loss: 1.462640\n",
      "Epoch [85/200], Step:  38400, d_loss: 5.807765, g_loss: 1.537675, real_scores: 3.273138, fake_scores: 0.050486\n",
      "Finish Epoch [85/200], D Loss: 7.998587, G Loss: 1.469660\n",
      "Epoch [86/200], Step:  38400, d_loss: 5.785437, g_loss: 0.938965, real_scores: 3.602500, fake_scores: 0.282074\n",
      "Finish Epoch [86/200], D Loss: 7.895912, G Loss: 1.469033\n",
      "Epoch [87/200], Step:  38400, d_loss: 6.138274, g_loss: 1.270793, real_scores: 3.530692, fake_scores: 0.036466\n",
      "Finish Epoch [87/200], D Loss: 7.835372, G Loss: 1.463732\n",
      "Epoch [88/200], Step:  38400, d_loss: 5.537510, g_loss: 1.151766, real_scores: 3.844468, fake_scores: 0.251014\n",
      "Finish Epoch [88/200], D Loss: 7.713214, G Loss: 1.406963\n",
      "Epoch [89/200], Step:  38400, d_loss: 5.270096, g_loss: 0.952938, real_scores: 3.624118, fake_scores: 0.127567\n",
      "Finish Epoch [89/200], D Loss: 7.587608, G Loss: 1.384737\n",
      "Epoch [90/200], Step:  38400, d_loss: 5.406204, g_loss: 1.107117, real_scores: 3.469441, fake_scores: 0.111108\n",
      "Finish Epoch [90/200], D Loss: 7.527554, G Loss: 1.414554\n",
      "Epoch [91/200], Step:  38400, d_loss: 4.764189, g_loss: 0.664547, real_scores: 4.049991, fake_scores: 0.601476\n",
      "Finish Epoch [91/200], D Loss: 7.425805, G Loss: 1.364274\n",
      "Epoch [92/200], Step:  38400, d_loss: 6.370958, g_loss: 1.622009, real_scores: 2.951752, fake_scores: -0.129747\n",
      "Finish Epoch [92/200], D Loss: 7.319705, G Loss: 1.380402\n",
      "Epoch [93/200], Step:  38400, d_loss: 5.948304, g_loss: 0.764669, real_scores: 4.245741, fake_scores: 0.878591\n",
      "Finish Epoch [93/200], D Loss: 7.282308, G Loss: 1.339656\n",
      "Epoch [94/200], Step:  38400, d_loss: 4.865795, g_loss: 0.982057, real_scores: 3.891992, fake_scores: 0.254821\n",
      "Finish Epoch [94/200], D Loss: 7.163909, G Loss: 1.326995\n",
      "Epoch [95/200], Step:  38400, d_loss: 5.177991, g_loss: 1.292633, real_scores: 3.604174, fake_scores: 0.078672\n",
      "Finish Epoch [95/200], D Loss: 7.097961, G Loss: 1.313288\n",
      "Epoch [96/200], Step:  38400, d_loss: 5.080565, g_loss: 0.641365, real_scores: 3.926257, fake_scores: 0.487617\n",
      "Finish Epoch [96/200], D Loss: 7.022054, G Loss: 1.284126\n",
      "Epoch [97/200], Step:  38400, d_loss: 4.965824, g_loss: 0.833197, real_scores: 4.313037, fake_scores: 0.980439\n",
      "Finish Epoch [97/200], D Loss: 6.958208, G Loss: 1.320412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200], Step:  38400, d_loss: 4.888964, g_loss: 0.791891, real_scores: 4.074574, fake_scores: 0.371766\n",
      "Finish Epoch [98/200], D Loss: 6.897167, G Loss: 1.318188\n",
      "Epoch [99/200], Step:  38400, d_loss: 4.892773, g_loss: 0.774994, real_scores: 4.453850, fake_scores: 0.621761\n",
      "Finish Epoch [99/200], D Loss: 6.851233, G Loss: 1.262522\n",
      "Epoch [100/200], Step:  38400, d_loss: 5.089312, g_loss: 0.967450, real_scores: 3.655733, fake_scores: 0.187647\n",
      "Finish Epoch [100/200], D Loss: 6.759334, G Loss: 1.264559\n",
      "Epoch [101/200], Step:  38400, d_loss: 5.227621, g_loss: 0.984046, real_scores: 3.557869, fake_scores: 0.166415\n",
      "Finish Epoch [101/200], D Loss: 6.677160, G Loss: 1.282206\n",
      "Epoch [102/200], Step:  38400, d_loss: 5.186668, g_loss: 0.993106, real_scores: 4.090302, fake_scores: 0.159618\n",
      "Finish Epoch [102/200], D Loss: 6.589483, G Loss: 1.261393\n",
      "Epoch [103/200], Step:  38400, d_loss: 5.650578, g_loss: 0.971261, real_scores: 3.918968, fake_scores: 0.405782\n",
      "Finish Epoch [103/200], D Loss: 6.596469, G Loss: 1.219315\n",
      "Epoch [104/200], Step:  38400, d_loss: 5.876459, g_loss: 1.259827, real_scores: 3.422003, fake_scores: 0.072548\n",
      "Finish Epoch [104/200], D Loss: 6.532042, G Loss: 1.221699\n",
      "Epoch [105/200], Step:  38400, d_loss: 5.498096, g_loss: 0.753615, real_scores: 4.222829, fake_scores: 0.847977\n",
      "Finish Epoch [105/200], D Loss: 6.443190, G Loss: 1.193256\n",
      "Epoch [106/200], Step:  38400, d_loss: 4.667911, g_loss: 1.883476, real_scores: 3.603539, fake_scores: -0.092493\n",
      "Finish Epoch [106/200], D Loss: 6.394543, G Loss: 1.192825\n",
      "Epoch [107/200], Step:  38400, d_loss: 5.598711, g_loss: 0.813362, real_scores: 3.946217, fake_scores: 0.366574\n",
      "Finish Epoch [107/200], D Loss: 6.359633, G Loss: 1.197523\n",
      "Epoch [108/200], Step:  38400, d_loss: 4.932220, g_loss: 0.880385, real_scores: 3.874481, fake_scores: 0.382473\n",
      "Finish Epoch [108/200], D Loss: 6.273617, G Loss: 1.175767\n",
      "Epoch [109/200], Step:  38400, d_loss: 5.128576, g_loss: 0.799612, real_scores: 4.301992, fake_scores: 0.765124\n",
      "Finish Epoch [109/200], D Loss: 6.189292, G Loss: 1.138785\n",
      "Epoch [110/200], Step:  38400, d_loss: 4.465022, g_loss: 0.746583, real_scores: 4.053073, fake_scores: 0.458401\n",
      "Finish Epoch [110/200], D Loss: 6.127200, G Loss: 1.177990\n",
      "Epoch [111/200], Step:  38400, d_loss: 4.512941, g_loss: 1.014038, real_scores: 4.295018, fake_scores: 0.428473\n",
      "Finish Epoch [111/200], D Loss: 6.091408, G Loss: 1.136585\n",
      "Epoch [112/200], Step:  38400, d_loss: 6.104753, g_loss: 0.599145, real_scores: 4.044933, fake_scores: 0.582123\n",
      "Finish Epoch [112/200], D Loss: 6.034392, G Loss: 1.136736\n",
      "Epoch [113/200], Step:  38400, d_loss: 5.758810, g_loss: 0.778537, real_scores: 4.307057, fake_scores: 0.795615\n",
      "Finish Epoch [113/200], D Loss: 5.980627, G Loss: 1.132321\n",
      "Epoch [114/200], Step:  38400, d_loss: 4.995526, g_loss: 1.533693, real_scores: 3.395164, fake_scores: -0.004174\n",
      "Finish Epoch [114/200], D Loss: 5.893054, G Loss: 1.101455\n",
      "Epoch [115/200], Step:  38400, d_loss: 5.577610, g_loss: 0.755559, real_scores: 4.410064, fake_scores: 0.758835\n",
      "Finish Epoch [115/200], D Loss: 5.879152, G Loss: 1.095854\n",
      "Epoch [116/200], Step:  38400, d_loss: 4.983607, g_loss: 1.124899, real_scores: 3.732621, fake_scores: 0.043858\n",
      "Finish Epoch [116/200], D Loss: 5.790773, G Loss: 1.113758\n",
      "Epoch [117/200], Step:  38400, d_loss: 5.597884, g_loss: 1.207476, real_scores: 3.591347, fake_scores: 0.146748\n",
      "Finish Epoch [117/200], D Loss: 5.745853, G Loss: 1.092095\n",
      "Epoch [118/200], Step:  38400, d_loss: 5.799288, g_loss: 2.090881, real_scores: 3.405911, fake_scores: -0.135885\n",
      "Finish Epoch [118/200], D Loss: 5.717293, G Loss: 1.077528\n",
      "Epoch [119/200], Step:  38400, d_loss: 4.842910, g_loss: 0.797645, real_scores: 4.370614, fake_scores: 0.994241\n",
      "Finish Epoch [119/200], D Loss: 5.628972, G Loss: 1.091940\n",
      "Epoch [120/200], Step:  38400, d_loss: 5.476091, g_loss: 0.775657, real_scores: 3.990116, fake_scores: 0.470486\n",
      "Finish Epoch [120/200], D Loss: 5.622098, G Loss: 1.066034\n",
      "Epoch [121/200], Step:  38400, d_loss: 4.924122, g_loss: 0.786530, real_scores: 4.169065, fake_scores: 0.705447\n",
      "Finish Epoch [121/200], D Loss: 5.561623, G Loss: 1.062181\n",
      "Epoch [122/200], Step:  38400, d_loss: 5.231482, g_loss: 0.950174, real_scores: 3.760098, fake_scores: 0.161808\n",
      "Finish Epoch [122/200], D Loss: 5.522493, G Loss: 1.033793\n",
      "Epoch [123/200], Step:  38400, d_loss: 6.936932, g_loss: 2.225964, real_scores: 2.898184, fake_scores: -0.256191\n",
      "Finish Epoch [123/200], D Loss: 5.455650, G Loss: 1.053591\n",
      "Epoch [124/200], Step:  38400, d_loss: 4.810605, g_loss: 0.577473, real_scores: 3.983666, fake_scores: 0.664389\n",
      "Finish Epoch [124/200], D Loss: 5.402193, G Loss: 1.050150\n",
      "Epoch [125/200], Step:  38400, d_loss: 4.752160, g_loss: 0.605351, real_scores: 4.117629, fake_scores: 0.639601\n",
      "Finish Epoch [125/200], D Loss: 5.334632, G Loss: 1.048207\n",
      "Epoch [126/200], Step:  38400, d_loss: 5.158657, g_loss: 0.729501, real_scores: 4.040424, fake_scores: 0.599006\n",
      "Finish Epoch [126/200], D Loss: 5.311331, G Loss: 1.014576\n",
      "Epoch [127/200], Step:  38400, d_loss: 4.943799, g_loss: 0.797861, real_scores: 3.681380, fake_scores: 0.257002\n",
      "Finish Epoch [127/200], D Loss: 5.255273, G Loss: 1.016162\n",
      "Epoch [128/200], Step:  38400, d_loss: 5.337830, g_loss: 0.729366, real_scores: 4.124650, fake_scores: 0.583756\n",
      "Finish Epoch [128/200], D Loss: 5.231048, G Loss: 1.002237\n",
      "Epoch [129/200], Step:  38400, d_loss: 4.288029, g_loss: 0.638523, real_scores: 4.288427, fake_scores: 0.545530\n",
      "Finish Epoch [129/200], D Loss: 5.215131, G Loss: 0.990893\n",
      "Epoch [130/200], Step:  38400, d_loss: 5.384105, g_loss: 1.089097, real_scores: 3.838223, fake_scores: 0.269719\n",
      "Finish Epoch [130/200], D Loss: 5.143432, G Loss: 0.993805\n",
      "Epoch [131/200], Step:  38400, d_loss: 5.227745, g_loss: 0.686850, real_scores: 4.206320, fake_scores: 0.632302\n",
      "Finish Epoch [131/200], D Loss: 5.103950, G Loss: 0.986607\n",
      "Epoch [132/200], Step:  38400, d_loss: 5.233915, g_loss: 0.615919, real_scores: 4.003715, fake_scores: 0.704503\n",
      "Finish Epoch [132/200], D Loss: 5.046198, G Loss: 0.987850\n",
      "Epoch [133/200], Step:  38400, d_loss: 5.033283, g_loss: 1.078722, real_scores: 3.949041, fake_scores: 0.135610\n",
      "Finish Epoch [133/200], D Loss: 5.011884, G Loss: 0.974712\n",
      "Epoch [134/200], Step:  38400, d_loss: 4.969616, g_loss: 0.782435, real_scores: 4.451629, fake_scores: 0.765977\n",
      "Finish Epoch [134/200], D Loss: 4.968501, G Loss: 0.955943\n",
      "Epoch [135/200], Step:  38400, d_loss: 4.356200, g_loss: 1.233673, real_scores: 3.875079, fake_scores: 0.139881\n",
      "Finish Epoch [135/200], D Loss: 4.925788, G Loss: 0.963621\n",
      "Epoch [136/200], Step:  38400, d_loss: 5.190348, g_loss: 0.746620, real_scores: 4.192439, fake_scores: 0.607938\n",
      "Finish Epoch [136/200], D Loss: 4.874440, G Loss: 0.959998\n",
      "Epoch [137/200], Step:  38400, d_loss: 5.037079, g_loss: 0.980660, real_scores: 3.669491, fake_scores: 0.426521\n",
      "Finish Epoch [137/200], D Loss: 4.845024, G Loss: 0.929986\n",
      "Epoch [138/200], Step:  38400, d_loss: 5.030413, g_loss: 0.984146, real_scores: 4.047345, fake_scores: 0.289617\n",
      "Finish Epoch [138/200], D Loss: 4.808678, G Loss: 0.950818\n",
      "Epoch [139/200], Step:  38400, d_loss: 4.822997, g_loss: 1.035527, real_scores: 3.738073, fake_scores: 0.145038\n",
      "Finish Epoch [139/200], D Loss: 4.776181, G Loss: 0.926471\n",
      "Epoch [140/200], Step:  38400, d_loss: 5.370043, g_loss: 0.690842, real_scores: 3.763945, fake_scores: 0.180302\n",
      "Finish Epoch [140/200], D Loss: 4.709088, G Loss: 0.938722\n",
      "Epoch [141/200], Step:  38400, d_loss: 5.282887, g_loss: 1.118878, real_scores: 4.089691, fake_scores: 0.316478\n",
      "Finish Epoch [141/200], D Loss: 4.655273, G Loss: 0.940998\n",
      "Epoch [142/200], Step:  38400, d_loss: 5.237634, g_loss: 1.035290, real_scores: 4.301287, fake_scores: 0.542230\n",
      "Finish Epoch [142/200], D Loss: 4.624842, G Loss: 0.927505\n",
      "Epoch [143/200], Step:  38400, d_loss: 4.987764, g_loss: 0.796443, real_scores: 4.247315, fake_scores: 0.939625\n",
      "Finish Epoch [143/200], D Loss: 4.623756, G Loss: 0.927585\n",
      "Epoch [144/200], Step:  38400, d_loss: 5.296714, g_loss: 0.779328, real_scores: 4.359228, fake_scores: 0.558090\n",
      "Finish Epoch [144/200], D Loss: 4.577751, G Loss: 0.903499\n",
      "Epoch [145/200], Step:  38400, d_loss: 5.265159, g_loss: 0.778942, real_scores: 4.123781, fake_scores: 0.668215\n",
      "Finish Epoch [145/200], D Loss: 4.566835, G Loss: 0.891685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/200], Step:  38400, d_loss: 4.856156, g_loss: 1.031819, real_scores: 4.296118, fake_scores: 0.305619\n",
      "Finish Epoch [146/200], D Loss: 4.519822, G Loss: 0.895125\n",
      "Epoch [147/200], Step:  38400, d_loss: 5.576004, g_loss: 1.011977, real_scores: 3.803638, fake_scores: 0.245002\n",
      "Finish Epoch [147/200], D Loss: 4.464695, G Loss: 0.891399\n",
      "Epoch [148/200], Step:  38400, d_loss: 5.544638, g_loss: 0.670462, real_scores: 4.500177, fake_scores: 0.881588\n",
      "Finish Epoch [148/200], D Loss: 4.464261, G Loss: 0.878158\n",
      "Epoch [149/200], Step:  38400, d_loss: 5.285899, g_loss: 0.830132, real_scores: 4.488027, fake_scores: 0.990971\n",
      "Finish Epoch [149/200], D Loss: 4.437479, G Loss: 0.890804\n",
      "Epoch [150/200], Step:  38400, d_loss: 5.199495, g_loss: 0.800617, real_scores: 4.039030, fake_scores: 0.421404\n",
      "Finish Epoch [150/200], D Loss: 4.415590, G Loss: 0.870540\n",
      "Epoch [151/200], Step:  38400, d_loss: 5.292921, g_loss: 0.995666, real_scores: 4.064771, fake_scores: 0.321110\n",
      "Finish Epoch [151/200], D Loss: 4.386635, G Loss: 0.868781\n",
      "Epoch [152/200], Step:  38400, d_loss: 5.135611, g_loss: 0.712399, real_scores: 3.725088, fake_scores: 0.424660\n",
      "Finish Epoch [152/200], D Loss: 4.309535, G Loss: 0.875928\n",
      "Epoch [153/200], Step:  38400, d_loss: 5.195225, g_loss: 0.807736, real_scores: 4.263449, fake_scores: 0.662410\n",
      "Finish Epoch [153/200], D Loss: 4.280539, G Loss: 0.859109\n",
      "Epoch [154/200], Step:  38400, d_loss: 5.251376, g_loss: 0.782460, real_scores: 4.273810, fake_scores: 1.121423\n",
      "Finish Epoch [154/200], D Loss: 4.286856, G Loss: 0.858552\n",
      "Epoch [155/200], Step:  38400, d_loss: 5.379560, g_loss: 1.303997, real_scores: 3.616920, fake_scores: 0.066504\n",
      "Finish Epoch [155/200], D Loss: 4.246662, G Loss: 0.851008\n",
      "Epoch [156/200], Step:  38400, d_loss: 5.191709, g_loss: 0.821151, real_scores: 3.784997, fake_scores: 0.331966\n",
      "Finish Epoch [156/200], D Loss: 4.242195, G Loss: 0.851343\n",
      "Epoch [157/200], Step:  38400, d_loss: 6.152297, g_loss: 1.448569, real_scores: 3.258794, fake_scores: -0.087720\n",
      "Finish Epoch [157/200], D Loss: 4.212544, G Loss: 0.852478\n",
      "Epoch [158/200], Step:  38400, d_loss: 4.853981, g_loss: 1.605466, real_scores: 3.391687, fake_scores: -0.058730\n",
      "Finish Epoch [158/200], D Loss: 4.177132, G Loss: 0.842989\n",
      "Epoch [159/200], Step:  38400, d_loss: 4.977060, g_loss: 1.723465, real_scores: 3.665148, fake_scores: -0.059938\n",
      "Finish Epoch [159/200], D Loss: 4.154617, G Loss: 0.834086\n",
      "Epoch [160/200], Step:  38400, d_loss: 4.461668, g_loss: 1.058062, real_scores: 4.196369, fake_scores: 0.196705\n",
      "Finish Epoch [160/200], D Loss: 4.129330, G Loss: 0.840215\n",
      "Epoch [161/200], Step:  38400, d_loss: 4.828966, g_loss: 1.222867, real_scores: 3.929420, fake_scores: 0.079055\n",
      "Finish Epoch [161/200], D Loss: 4.090875, G Loss: 0.829334\n",
      "Epoch [162/200], Step:  38400, d_loss: 5.087599, g_loss: 0.695898, real_scores: 4.458969, fake_scores: 0.987161\n",
      "Finish Epoch [162/200], D Loss: 4.059240, G Loss: 0.832926\n",
      "Epoch [163/200], Step:  38400, d_loss: 5.093653, g_loss: 0.745979, real_scores: 4.056443, fake_scores: 0.367382\n",
      "Finish Epoch [163/200], D Loss: 4.057749, G Loss: 0.822811\n",
      "Epoch [164/200], Step:  38400, d_loss: 4.885952, g_loss: 0.593186, real_scores: 4.380698, fake_scores: 0.763781\n",
      "Finish Epoch [164/200], D Loss: 4.033089, G Loss: 0.801933\n",
      "Epoch [165/200], Step:  38400, d_loss: 5.555625, g_loss: 1.280928, real_scores: 3.772567, fake_scores: 0.181325\n",
      "Finish Epoch [165/200], D Loss: 4.006291, G Loss: 0.805841\n",
      "Epoch [166/200], Step:  38400, d_loss: 5.828415, g_loss: 2.312600, real_scores: 3.373929, fake_scores: -0.162421\n",
      "Finish Epoch [166/200], D Loss: 3.960792, G Loss: 0.809704\n",
      "Epoch [167/200], Step:  38400, d_loss: 4.691065, g_loss: 0.907780, real_scores: 4.368468, fake_scores: 0.622913\n",
      "Finish Epoch [167/200], D Loss: 3.959784, G Loss: 0.802299\n",
      "Epoch [168/200], Step:  38400, d_loss: 5.691244, g_loss: 0.668451, real_scores: 4.195872, fake_scores: 1.070556\n",
      "Finish Epoch [168/200], D Loss: 3.930030, G Loss: 0.786975\n",
      "Epoch [169/200], Step:  38400, d_loss: 5.187479, g_loss: 0.817887, real_scores: 4.585228, fake_scores: 0.827052\n",
      "Finish Epoch [169/200], D Loss: 3.906464, G Loss: 0.791481\n",
      "Epoch [170/200], Step:  38400, d_loss: 5.214773, g_loss: 1.449888, real_scores: 3.657751, fake_scores: 0.032622\n",
      "Finish Epoch [170/200], D Loss: 3.876826, G Loss: 0.790870\n",
      "Epoch [171/200], Step:  38400, d_loss: 5.299076, g_loss: 0.904770, real_scores: 4.318757, fake_scores: 0.469159\n",
      "Finish Epoch [171/200], D Loss: 3.830445, G Loss: 0.773740\n",
      "Epoch [172/200], Step:  38400, d_loss: 5.036585, g_loss: 0.982354, real_scores: 4.070441, fake_scores: 0.479490\n",
      "Finish Epoch [172/200], D Loss: 3.811182, G Loss: 0.781344\n",
      "Epoch [173/200], Step:  38400, d_loss: 4.898585, g_loss: 0.909170, real_scores: 3.999810, fake_scores: 0.241555\n",
      "Finish Epoch [173/200], D Loss: 3.798493, G Loss: 0.765503\n",
      "Epoch [174/200], Step:  38400, d_loss: 5.090401, g_loss: 0.925605, real_scores: 3.912137, fake_scores: 0.277658\n",
      "Finish Epoch [174/200], D Loss: 3.764130, G Loss: 0.778119\n",
      "Epoch [175/200], Step:  38400, d_loss: 5.655751, g_loss: 1.361506, real_scores: 3.879959, fake_scores: 0.113106\n",
      "Finish Epoch [175/200], D Loss: 3.745125, G Loss: 0.776387\n",
      "Epoch [176/200], Step:  38400, d_loss: 4.649832, g_loss: 0.797691, real_scores: 4.228313, fake_scores: 0.300449\n",
      "Finish Epoch [176/200], D Loss: 3.718691, G Loss: 0.756051\n",
      "Epoch [177/200], Step:  38400, d_loss: 5.193945, g_loss: 0.615594, real_scores: 4.077038, fake_scores: 0.655089\n",
      "Finish Epoch [177/200], D Loss: 3.709842, G Loss: 0.746635\n",
      "Epoch [178/200], Step:  38400, d_loss: 5.271172, g_loss: 0.915653, real_scores: 4.384048, fake_scores: 0.574287\n",
      "Finish Epoch [178/200], D Loss: 3.689402, G Loss: 0.757103\n",
      "Epoch [179/200], Step:  38400, d_loss: 5.456882, g_loss: 1.493566, real_scores: 3.912882, fake_scores: 0.013891\n",
      "Finish Epoch [179/200], D Loss: 3.653208, G Loss: 0.751884\n",
      "Epoch [180/200], Step:  38400, d_loss: 5.151886, g_loss: 0.772292, real_scores: 4.626009, fake_scores: 0.730305\n",
      "Finish Epoch [180/200], D Loss: 3.649705, G Loss: 0.746754\n",
      "Epoch [181/200], Step:  38400, d_loss: 4.653806, g_loss: 1.212938, real_scores: 3.722218, fake_scores: 0.020074\n",
      "Finish Epoch [181/200], D Loss: 3.643193, G Loss: 0.742809\n",
      "Epoch [182/200], Step:  38400, d_loss: 5.436308, g_loss: 0.691725, real_scores: 4.000739, fake_scores: 0.439811\n",
      "Finish Epoch [182/200], D Loss: 3.608010, G Loss: 0.747971\n",
      "Epoch [183/200], Step:  38400, d_loss: 5.157768, g_loss: 1.119911, real_scores: 3.789872, fake_scores: 0.236771\n",
      "Finish Epoch [183/200], D Loss: 3.582644, G Loss: 0.743069\n",
      "Epoch [184/200], Step:  38400, d_loss: 5.030737, g_loss: 1.017604, real_scores: 3.894375, fake_scores: 0.393652\n",
      "Finish Epoch [184/200], D Loss: 3.565053, G Loss: 0.735751\n",
      "Epoch [185/200], Step:  38400, d_loss: 5.429392, g_loss: 1.538370, real_scores: 3.845221, fake_scores: -0.162438\n",
      "Finish Epoch [185/200], D Loss: 3.523377, G Loss: 0.742309\n",
      "Epoch [186/200], Step:  38400, d_loss: 5.975297, g_loss: 1.379559, real_scores: 3.441257, fake_scores: -0.051997\n",
      "Finish Epoch [186/200], D Loss: 3.513884, G Loss: 0.719485\n",
      "Epoch [187/200], Step:  38400, d_loss: 4.669241, g_loss: 1.175622, real_scores: 3.783962, fake_scores: 0.120023\n",
      "Finish Epoch [187/200], D Loss: 3.484907, G Loss: 0.720445\n",
      "Epoch [188/200], Step:  38400, d_loss: 5.067403, g_loss: 0.988859, real_scores: 3.871674, fake_scores: 0.212369\n",
      "Finish Epoch [188/200], D Loss: 3.473185, G Loss: 0.712065\n",
      "Epoch [189/200], Step:  38400, d_loss: 4.513961, g_loss: 0.713642, real_scores: 4.398009, fake_scores: 0.646980\n",
      "Finish Epoch [189/200], D Loss: 3.463975, G Loss: 0.710280\n",
      "Epoch [190/200], Step:  38400, d_loss: 4.884446, g_loss: 1.089630, real_scores: 3.937425, fake_scores: 0.200976\n",
      "Finish Epoch [190/200], D Loss: 3.444034, G Loss: 0.709526\n",
      "Epoch [191/200], Step:  38400, d_loss: 4.763459, g_loss: 1.061820, real_scores: 4.305985, fake_scores: 0.323777\n",
      "Finish Epoch [191/200], D Loss: 3.433077, G Loss: 0.721748\n",
      "Epoch [192/200], Step:  38400, d_loss: 5.330760, g_loss: 0.913315, real_scores: 4.317557, fake_scores: 0.398266\n",
      "Finish Epoch [192/200], D Loss: 3.388794, G Loss: 0.698864\n",
      "Epoch [193/200], Step:  38400, d_loss: 4.913859, g_loss: 0.726600, real_scores: 4.107572, fake_scores: 0.577450\n",
      "Finish Epoch [193/200], D Loss: 3.361372, G Loss: 0.695668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200], Step:  38400, d_loss: 5.661208, g_loss: 1.817704, real_scores: 3.397838, fake_scores: -0.132717\n",
      "Finish Epoch [194/200], D Loss: 3.350308, G Loss: 0.692577\n",
      "Epoch [195/200], Step:  38400, d_loss: 5.861861, g_loss: 1.701306, real_scores: 3.103317, fake_scores: -0.035656\n",
      "Finish Epoch [195/200], D Loss: 3.323675, G Loss: 0.687028\n",
      "Epoch [196/200], Step:  38400, d_loss: 4.945563, g_loss: 0.640148, real_scores: 4.041309, fake_scores: 0.527263\n",
      "Finish Epoch [196/200], D Loss: 3.317534, G Loss: 0.689602\n",
      "Epoch [197/200], Step:  38400, d_loss: 4.913246, g_loss: 1.070968, real_scores: 4.033340, fake_scores: 0.254002\n",
      "Finish Epoch [197/200], D Loss: 3.307643, G Loss: 0.684433\n",
      "Epoch [198/200], Step:  38400, d_loss: 4.906668, g_loss: 0.852445, real_scores: 3.923775, fake_scores: 0.291345\n",
      "Finish Epoch [198/200], D Loss: 3.302930, G Loss: 0.677669\n",
      "Epoch [199/200], Step:  38400, d_loss: 5.324225, g_loss: 1.028347, real_scores: 3.767110, fake_scores: 0.228408\n",
      "Finish Epoch [199/200], D Loss: 3.256097, G Loss: 0.680330\n",
      "Epoch [200/200], Step:  38400, d_loss: 5.145926, g_loss: 0.731180, real_scores: 4.427850, fake_scores: 0.622958\n",
      "Finish Epoch [200/200], D Loss: 3.242836, G Loss: 0.672628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        real_imgs = imgs.cuda()\n",
    "        real_labels = labels.float().cuda()\n",
    "        \n",
    "        real = torch.ones(imgs.size(0), 1).cuda()\n",
    "        fake = torch.zeros(imgs.size(0), 1).cuda()\n",
    "        \n",
    "        ########## G ##########\n",
    "        z = torch.randn(imgs.size(0), z_dimension).cuda()\n",
    "        fake_labels = torch.from_numpy(np.random.randint(0, 10, imgs.size(0))).cuda()\n",
    "        \n",
    "        fake_imgs = G(z, fake_labels)\n",
    "        fake_out = D(fake_imgs, fake_labels)\n",
    "        g_loss = adversarial_loss(fake_out, real)\n",
    "        \n",
    "        G_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        G_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_out = D(real_imgs, labels)\n",
    "        d_loss_real = adversarial_loss(real_out, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_out = D(fake_imgs.detach(), fake_labels)\n",
    "        d_loss_fake = adversarial_loss(fake_out, fake)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        D_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        D_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * imgs.size(0)\n",
    "        g_loss_total += g_loss.item() * imgs.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "        \n",
    "    noise = torch.randn(10, z_dimension).cuda()\n",
    "    condition_images = G(noise, condition)\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_imgs.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_images.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    fake_images = fake_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    save_image(condition_images, os.path.join(img_path, 'condition_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), './ser/cgan_discriminator.pkl')\n",
    "torch.save(G.state_dict(), './ser/cgan_generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = torch.from_numpy(np.array([4,5,1,3,0])).cuda()\n",
    "z = torch.randn(5, z_dimension).to(device)\n",
    "images = G(z, l)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
