{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = (128, 4, 4) # 64 * 64\n",
    "\n",
    "img_shape = (1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1, stride=2),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 16 16 16\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 8 8\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 4 4\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 512),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "        \n",
    "        self.label = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs): # b 1 32 32\n",
    "        \n",
    "        outs = self.conv1(imgs)\n",
    "        outs = self.conv2(outs)\n",
    "        outs = self.conv3(outs)\n",
    "        outs = outs.view(imgs.size(0), -1)\n",
    "        img = self.fc(outs)\n",
    "        lab = self.label(outs)\n",
    "        \n",
    "        return img, lab # b 1 1 1, b 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, np.prod(num_feature)),\n",
    "#             nn.Sigmoid(),\n",
    "        ) # b h*w\n",
    "        \n",
    "        self.upsample1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "#             nn.ConvTranspose2d(128, 128, 3, 1, 0)\n",
    "            nn.functional.interpolate(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 128 8 8\n",
    "        \n",
    "        self.upsample2 = nn.Sequential(\n",
    "            nn.functional.interpolate(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 16 16\n",
    "        \n",
    "        self.upsample3 = nn.Sequential(\n",
    "            nn.functional.interpolate(scale_factor=2),\n",
    "            nn.Conv2d(64, 1, 3, padding=1, stride=1),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 32 32\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.cat((labels.reshape(noise.size(0), -1), noise), -1)\n",
    "        \n",
    "        outs = self.fc(gen_input)\n",
    "        outs = outs.view(noise.size(0), *num_feature)\n",
    "        outs = self.upsample1(outs)\n",
    "        outs = self.upsample2(outs)\n",
    "        outs = self.upsample3(outs)\n",
    "        \n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "interpolate() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-70adf6723080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dimension\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8d7a46c679dc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inp_dim, num_feature)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#             nn.ConvTranspose2d(128, 128, 3, 1, 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: interpolate() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(z_dimension + 1, num_feature).to(device)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "adversarial_loss = nn.MSELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "D_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "G_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = torch.from_numpy(np.arange(10)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_cgan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"save_images/cnn_cgan\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73dc6239b9f46689f67234a57a9a341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 19.882215, g_loss: 0.000001, real_scores: 0.999768, fake_scores: 0.998951\n",
      "Finish Epoch [1/100], D Loss: 2726.151715, G Loss: 1.566885\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        real_imgs = imgs.cuda()\n",
    "        real_labels = labels.cuda()\n",
    "        \n",
    "        real = torch.ones(imgs.size(0), 1).cuda()\n",
    "        fake = torch.zeros(imgs.size(0), 1).cuda()\n",
    "        \n",
    "        ########## G ##########\n",
    "        z = torch.randn(imgs.size(0), z_dimension).cuda()\n",
    "        fake_labels = torch.from_numpy(np.random.randint(0, 10, imgs.size(0))).float().cuda()\n",
    "\n",
    "        fake_imgs = G(z, fake_labels)\n",
    "        fake_out, fake_out_labels = D(fake_imgs)\n",
    "        g_loss = adversarial_loss(fake_out, real)\n",
    "        \n",
    "        G_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        G_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_out, real_out_label = D(real_imgs)\n",
    "        d_loss_real = adversarial_loss(real_out, real_labels.float())\n",
    "        d_loss_real_label = auxiliary_loss(real_out_label, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_out, fake_out_label = D(fake_imgs.detach())\n",
    "        d_loss_fake = adversarial_loss(fake_out, fake)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake # + d_loss_real_label\n",
    "        D_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        D_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * imgs.size(0)\n",
    "        g_loss_total += g_loss.item() * imgs.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "        \n",
    "    noise = torch.randn(10, z_dimension).cuda()\n",
    "    condition_images = G(noise, condition.float())\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_imgs.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_images.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    fake_images = fake_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    save_image(condition_images, os.path.join(img_path, 'condition_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), './ser/cgan_discriminator.pt')\n",
    "torch.save(G.state_dict(), './ser/cgan_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = torch.from_numpy(np.array([4,5,1,3,0])).cuda()\n",
    "z = torch.randn(5, z_dimension).to(device)\n",
    "images = G(z, l)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
