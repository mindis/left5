{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 256\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('./datas', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "    \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature)\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 56 56\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 56 56\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 56 56\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 28 28\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        out = out.view(x.size(0), 1, 56, 56)\n",
    "        out = self.br(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=1e-4)\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        real_labels = torch.ones(img.size(0), 1).cuda()\n",
    "        fake_labels = torch.zeros(img.size(0), 1).cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = criterion(real_out, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = criterion(fake_out, real_labels)\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        \n",
    "        step = epoch * total_count + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 500 == 0:\n",
    "            print 'Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean())\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, './cnn_gan_img/real_images.png')\n",
    "\n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, './cnn_gan_img/fake_images-{}.png'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/discriminator.pkl')\n",
    "torch.save(g.state_dict(), './ser/generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAB8CAYAAABnjns5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f91ed8f8b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
