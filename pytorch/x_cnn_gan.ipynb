{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('./datas/mnist', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 56 56\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 56 56\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 56 56\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 28 28\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        out = out.view(x.size(0), 1, 56, 56)\n",
    "        out = self.br(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "d.weight_init(.0, 0.02)\n",
    "g.weight_init(.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4)\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3c45b7f7ba4a8c88735e5a7d811d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 0.937766, g_loss: 1.749669, real_scores: 0.878058, fake_scores: 0.457458\n",
      "Finish Epoch [1/100], D Loss: 60.760090, G Loss: 450.252879\n",
      "Epoch [2/100], Step:  38400, d_loss: 0.654950, g_loss: 2.124682, real_scores: 0.680493, fake_scores: 0.126063\n",
      "Finish Epoch [2/100], D Loss: 39.572537, G Loss: 123.840065\n",
      "Epoch [3/100], Step:  38400, d_loss: 0.516862, g_loss: 2.454146, real_scores: 0.923992, fake_scores: 0.292242\n",
      "Finish Epoch [3/100], D Loss: 19.627490, G Loss: 103.323877\n",
      "Epoch [4/100], Step:  38400, d_loss: 0.444043, g_loss: 1.562260, real_scores: 0.854906, fake_scores: 0.178196\n",
      "Finish Epoch [4/100], D Loss: 14.900813, G Loss: 80.510159\n",
      "Epoch [5/100], Step:  38400, d_loss: 0.493465, g_loss: 2.265056, real_scores: 0.842507, fake_scores: 0.206431\n",
      "Finish Epoch [5/100], D Loss: 13.175548, G Loss: 61.097728\n",
      "Epoch [6/100], Step:  38400, d_loss: 0.614002, g_loss: 1.776424, real_scores: 0.841668, fake_scores: 0.223994\n",
      "Finish Epoch [6/100], D Loss: 11.733626, G Loss: 49.947953\n",
      "Epoch [7/100], Step:  38400, d_loss: 0.569688, g_loss: 2.067055, real_scores: 0.830189, fake_scores: 0.215764\n",
      "Finish Epoch [7/100], D Loss: 10.577115, G Loss: 41.068438\n",
      "Epoch [8/100], Step:  38400, d_loss: 0.547220, g_loss: 1.845323, real_scores: 0.813650, fake_scores: 0.212150\n",
      "Finish Epoch [8/100], D Loss: 9.766672, G Loss: 34.232874\n",
      "Epoch [9/100], Step:  38400, d_loss: 0.678021, g_loss: 1.898742, real_scores: 0.730499, fake_scores: 0.160829\n",
      "Finish Epoch [9/100], D Loss: 9.006974, G Loss: 29.422440\n",
      "Epoch [10/100], Step:  38400, d_loss: 0.704214, g_loss: 1.459319, real_scores: 0.746183, fake_scores: 0.202662\n",
      "Finish Epoch [10/100], D Loss: 8.088179, G Loss: 25.927284\n",
      "Epoch [11/100], Step:  38400, d_loss: 0.661313, g_loss: 1.324831, real_scores: 0.773193, fake_scores: 0.206717\n",
      "Finish Epoch [11/100], D Loss: 7.448766, G Loss: 23.772902\n",
      "Epoch [12/100], Step:  38400, d_loss: 0.700272, g_loss: 2.066038, real_scores: 0.857467, fake_scores: 0.327632\n",
      "Finish Epoch [12/100], D Loss: 6.709407, G Loss: 21.704353\n",
      "Epoch [13/100], Step:  38400, d_loss: 0.593164, g_loss: 2.346456, real_scores: 0.761168, fake_scores: 0.141068\n",
      "Finish Epoch [13/100], D Loss: 6.230646, G Loss: 20.516474\n",
      "Epoch [14/100], Step:  38400, d_loss: 0.481158, g_loss: 2.013422, real_scores: 0.832350, fake_scores: 0.174294\n",
      "Finish Epoch [14/100], D Loss: 5.785539, G Loss: 18.894345\n",
      "Epoch [15/100], Step:  38400, d_loss: 0.661050, g_loss: 1.911704, real_scores: 0.830995, fake_scores: 0.290280\n",
      "Finish Epoch [15/100], D Loss: 5.367100, G Loss: 17.769492\n",
      "Epoch [16/100], Step:  38400, d_loss: 0.569254, g_loss: 2.681810, real_scores: 0.807047, fake_scores: 0.180932\n",
      "Finish Epoch [16/100], D Loss: 4.979204, G Loss: 16.955671\n",
      "Epoch [17/100], Step:  38400, d_loss: 0.642446, g_loss: 1.710525, real_scores: 0.765003, fake_scores: 0.187693\n",
      "Finish Epoch [17/100], D Loss: 4.736983, G Loss: 16.116162\n",
      "Epoch [18/100], Step:  38400, d_loss: 0.504936, g_loss: 2.071354, real_scores: 0.785414, fake_scores: 0.141194\n",
      "Finish Epoch [18/100], D Loss: 4.328334, G Loss: 15.120343\n",
      "Epoch [19/100], Step:  38400, d_loss: 0.734600, g_loss: 1.840335, real_scores: 0.727678, fake_scores: 0.173371\n",
      "Finish Epoch [19/100], D Loss: 4.082304, G Loss: 14.555791\n",
      "Epoch [20/100], Step:  38400, d_loss: 0.538140, g_loss: 1.930640, real_scores: 0.857331, fake_scores: 0.248904\n",
      "Finish Epoch [20/100], D Loss: 3.947211, G Loss: 14.190350\n",
      "Epoch [21/100], Step:  38400, d_loss: 0.469773, g_loss: 2.102040, real_scores: 0.862001, fake_scores: 0.220430\n",
      "Finish Epoch [21/100], D Loss: 3.622809, G Loss: 13.460632\n",
      "Epoch [22/100], Step:  38400, d_loss: 0.539415, g_loss: 2.371906, real_scores: 0.827365, fake_scores: 0.213106\n",
      "Finish Epoch [22/100], D Loss: 3.419764, G Loss: 13.028255\n",
      "Epoch [23/100], Step:  38400, d_loss: 0.722719, g_loss: 2.795389, real_scores: 0.869756, fake_scores: 0.332672\n",
      "Finish Epoch [23/100], D Loss: 3.240403, G Loss: 12.499448\n",
      "Epoch [24/100], Step:  38400, d_loss: 0.572172, g_loss: 2.366047, real_scores: 0.823628, fake_scores: 0.207265\n",
      "Finish Epoch [24/100], D Loss: 2.987411, G Loss: 12.084546\n",
      "Epoch [25/100], Step:  38400, d_loss: 0.567370, g_loss: 3.085855, real_scores: 0.753944, fake_scores: 0.102673\n",
      "Finish Epoch [25/100], D Loss: 2.977708, G Loss: 11.751940\n",
      "Epoch [26/100], Step:  38400, d_loss: 0.534067, g_loss: 2.083222, real_scores: 0.893845, fake_scores: 0.263918\n",
      "Finish Epoch [26/100], D Loss: 2.786308, G Loss: 11.334366\n",
      "Epoch [27/100], Step:  38400, d_loss: 0.579024, g_loss: 2.124279, real_scores: 0.796655, fake_scores: 0.177321\n",
      "Finish Epoch [27/100], D Loss: 2.653615, G Loss: 10.996792\n",
      "Epoch [28/100], Step:  38400, d_loss: 0.449207, g_loss: 1.914843, real_scores: 0.841163, fake_scores: 0.174586\n",
      "Finish Epoch [28/100], D Loss: 2.580959, G Loss: 10.685953\n",
      "Epoch [29/100], Step:  38400, d_loss: 0.546299, g_loss: 3.007876, real_scores: 0.813316, fake_scores: 0.182667\n",
      "Finish Epoch [29/100], D Loss: 2.469378, G Loss: 10.275627\n",
      "Epoch [30/100], Step:  38400, d_loss: 0.687418, g_loss: 2.707906, real_scores: 0.872537, fake_scores: 0.308062\n",
      "Finish Epoch [30/100], D Loss: 2.340498, G Loss: 10.170934\n",
      "Epoch [31/100], Step:  38400, d_loss: 0.565315, g_loss: 1.669432, real_scores: 0.796674, fake_scores: 0.182939\n",
      "Finish Epoch [31/100], D Loss: 2.242156, G Loss: 9.845460\n",
      "Epoch [32/100], Step:  38400, d_loss: 0.566884, g_loss: 2.933260, real_scores: 0.894920, fake_scores: 0.288946\n",
      "Finish Epoch [32/100], D Loss: 2.204733, G Loss: 9.571285\n",
      "Epoch [33/100], Step:  38400, d_loss: 0.514848, g_loss: 3.025748, real_scores: 0.898109, fake_scores: 0.258219\n",
      "Finish Epoch [33/100], D Loss: 2.111471, G Loss: 9.287854\n",
      "Epoch [34/100], Step:  38400, d_loss: 0.418056, g_loss: 2.546553, real_scores: 0.829121, fake_scores: 0.111568\n",
      "Finish Epoch [34/100], D Loss: 2.052203, G Loss: 9.135238\n",
      "Epoch [35/100], Step:  38400, d_loss: 0.569883, g_loss: 2.235519, real_scores: 0.829206, fake_scores: 0.233067\n",
      "Finish Epoch [35/100], D Loss: 2.026815, G Loss: 8.891766\n",
      "Epoch [36/100], Step:  38400, d_loss: 0.561169, g_loss: 2.081275, real_scores: 0.819894, fake_scores: 0.171599\n",
      "Finish Epoch [36/100], D Loss: 1.956231, G Loss: 8.560620\n",
      "Epoch [37/100], Step:  38400, d_loss: 0.540443, g_loss: 2.629748, real_scores: 0.867820, fake_scores: 0.237853\n",
      "Finish Epoch [37/100], D Loss: 1.902470, G Loss: 8.380890\n",
      "Epoch [38/100], Step:  38400, d_loss: 0.533255, g_loss: 1.354651, real_scores: 0.794851, fake_scores: 0.124939\n",
      "Finish Epoch [38/100], D Loss: 1.844395, G Loss: 8.189906\n",
      "Epoch [39/100], Step:  38400, d_loss: 0.478577, g_loss: 2.007408, real_scores: 0.822679, fake_scores: 0.126492\n",
      "Finish Epoch [39/100], D Loss: 1.789805, G Loss: 7.948119\n",
      "Epoch [40/100], Step:  38400, d_loss: 0.509892, g_loss: 2.040639, real_scores: 0.848376, fake_scores: 0.193467\n",
      "Finish Epoch [40/100], D Loss: 1.767849, G Loss: 7.788442\n",
      "Epoch [41/100], Step:  38400, d_loss: 0.579836, g_loss: 2.178193, real_scores: 0.747051, fake_scores: 0.103081\n",
      "Finish Epoch [41/100], D Loss: 1.689563, G Loss: 7.459911\n",
      "Epoch [42/100], Step:  38400, d_loss: 0.548735, g_loss: 2.326557, real_scores: 0.791510, fake_scores: 0.142429\n",
      "Finish Epoch [42/100], D Loss: 1.634364, G Loss: 7.369467\n",
      "Epoch [43/100], Step:  38400, d_loss: 0.685218, g_loss: 2.401074, real_scores: 0.866810, fake_scores: 0.314414\n",
      "Finish Epoch [43/100], D Loss: 1.621081, G Loss: 7.270441\n",
      "Epoch [44/100], Step:  38400, d_loss: 0.500967, g_loss: 2.396183, real_scores: 0.854320, fake_scores: 0.193169\n",
      "Finish Epoch [44/100], D Loss: 1.560705, G Loss: 7.065105\n",
      "Epoch [45/100], Step:  38400, d_loss: 0.707404, g_loss: 2.607037, real_scores: 0.929451, fake_scores: 0.377422\n",
      "Finish Epoch [45/100], D Loss: 1.524858, G Loss: 6.847054\n",
      "Epoch [46/100], Step:  38400, d_loss: 0.547366, g_loss: 2.810725, real_scores: 0.788556, fake_scores: 0.130992\n",
      "Finish Epoch [46/100], D Loss: 1.489608, G Loss: 6.767525\n",
      "Epoch [47/100], Step:  38400, d_loss: 0.422273, g_loss: 3.611912, real_scores: 0.849761, fake_scores: 0.129175\n",
      "Finish Epoch [47/100], D Loss: 1.464625, G Loss: 6.621748\n",
      "Epoch [48/100], Step:  38400, d_loss: 0.568605, g_loss: 2.531060, real_scores: 0.821066, fake_scores: 0.183862\n",
      "Finish Epoch [48/100], D Loss: 1.397700, G Loss: 6.423910\n",
      "Epoch [49/100], Step:  38400, d_loss: 0.777480, g_loss: 2.539021, real_scores: 0.912858, fake_scores: 0.376080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Epoch [49/100], D Loss: 1.391829, G Loss: 6.406394\n",
      "Epoch [50/100], Step:  38400, d_loss: 0.447054, g_loss: 2.630246, real_scores: 0.872728, fake_scores: 0.174988\n",
      "Finish Epoch [50/100], D Loss: 1.331816, G Loss: 6.197160\n",
      "Epoch [51/100], Step:  38400, d_loss: 0.435306, g_loss: 1.666748, real_scores: 0.866076, fake_scores: 0.143217\n",
      "Finish Epoch [51/100], D Loss: 1.341124, G Loss: 6.186675\n",
      "Epoch [52/100], Step:  38400, d_loss: 0.435988, g_loss: 2.178784, real_scores: 0.886872, fake_scores: 0.200372\n",
      "Finish Epoch [52/100], D Loss: 1.278023, G Loss: 5.969794\n",
      "Epoch [53/100], Step:  38400, d_loss: 0.510413, g_loss: 2.027502, real_scores: 0.814997, fake_scores: 0.156235\n",
      "Finish Epoch [53/100], D Loss: 1.279438, G Loss: 5.927099\n",
      "Epoch [54/100], Step:  38400, d_loss: 0.478498, g_loss: 2.801358, real_scores: 0.833819, fake_scores: 0.163186\n",
      "Finish Epoch [54/100], D Loss: 1.230781, G Loss: 5.791406\n",
      "Epoch [55/100], Step:  38400, d_loss: 0.437254, g_loss: 2.746707, real_scores: 0.853616, fake_scores: 0.129307\n",
      "Finish Epoch [55/100], D Loss: 1.234032, G Loss: 5.710978\n",
      "Epoch [56/100], Step:  38400, d_loss: 0.519592, g_loss: 2.713637, real_scores: 0.876191, fake_scores: 0.208282\n",
      "Finish Epoch [56/100], D Loss: 1.160078, G Loss: 5.550508\n",
      "Epoch [57/100], Step:  38400, d_loss: 0.557642, g_loss: 2.115456, real_scores: 0.816208, fake_scores: 0.168687\n",
      "Finish Epoch [57/100], D Loss: 1.186108, G Loss: 5.494068\n",
      "Epoch [58/100], Step:  38400, d_loss: 0.505151, g_loss: 2.539929, real_scores: 0.818597, fake_scores: 0.135811\n",
      "Finish Epoch [58/100], D Loss: 1.126529, G Loss: 5.377417\n",
      "Epoch [59/100], Step:  38400, d_loss: 0.430741, g_loss: 2.085646, real_scores: 0.888300, fake_scores: 0.172747\n",
      "Finish Epoch [59/100], D Loss: 1.134164, G Loss: 5.313253\n",
      "Epoch [60/100], Step:  38400, d_loss: 0.495794, g_loss: 2.363828, real_scores: 0.817800, fake_scores: 0.122188\n",
      "Finish Epoch [60/100], D Loss: 1.086646, G Loss: 5.209025\n",
      "Epoch [61/100], Step:  38400, d_loss: 0.454505, g_loss: 2.365621, real_scores: 0.890855, fake_scores: 0.215171\n",
      "Finish Epoch [61/100], D Loss: 1.108924, G Loss: 5.196788\n",
      "Epoch [62/100], Step:  38400, d_loss: 0.534881, g_loss: 1.940449, real_scores: 0.787158, fake_scores: 0.137859\n",
      "Finish Epoch [62/100], D Loss: 1.041893, G Loss: 5.088082\n",
      "Epoch [63/100], Step:  38400, d_loss: 0.446616, g_loss: 2.143502, real_scores: 0.868421, fake_scores: 0.197343\n",
      "Finish Epoch [63/100], D Loss: 1.043574, G Loss: 4.981767\n",
      "Epoch [64/100], Step:  38400, d_loss: 0.473319, g_loss: 2.414427, real_scores: 0.823089, fake_scores: 0.139616\n",
      "Finish Epoch [64/100], D Loss: 1.001263, G Loss: 4.952558\n",
      "Epoch [65/100], Step:  38400, d_loss: 0.579045, g_loss: 2.028383, real_scores: 0.924354, fake_scores: 0.331839\n",
      "Finish Epoch [65/100], D Loss: 0.994053, G Loss: 4.811616\n",
      "Epoch [66/100], Step:  38400, d_loss: 0.605220, g_loss: 2.561251, real_scores: 0.902426, fake_scores: 0.295844\n",
      "Finish Epoch [66/100], D Loss: 0.985227, G Loss: 4.803834\n",
      "Epoch [67/100], Step:  38400, d_loss: 0.480502, g_loss: 2.400758, real_scores: 0.800264, fake_scores: 0.119411\n",
      "Finish Epoch [67/100], D Loss: 0.961730, G Loss: 4.698244\n",
      "Epoch [68/100], Step:  38400, d_loss: 0.513662, g_loss: 2.529668, real_scores: 0.809013, fake_scores: 0.083986\n",
      "Finish Epoch [68/100], D Loss: 0.946185, G Loss: 4.645462\n",
      "Epoch [69/100], Step:  38400, d_loss: 0.473468, g_loss: 1.927604, real_scores: 0.862751, fake_scores: 0.209753\n",
      "Finish Epoch [69/100], D Loss: 0.916637, G Loss: 4.558647\n",
      "Epoch [70/100], Step:  38400, d_loss: 0.485973, g_loss: 1.928206, real_scores: 0.822650, fake_scores: 0.129121\n",
      "Finish Epoch [70/100], D Loss: 0.931705, G Loss: 4.581139\n",
      "Epoch [71/100], Step:  38400, d_loss: 0.491498, g_loss: 3.344988, real_scores: 0.832100, fake_scores: 0.135802\n",
      "Finish Epoch [71/100], D Loss: 0.893292, G Loss: 4.469376\n",
      "Epoch [72/100], Step:  38400, d_loss: 0.538551, g_loss: 1.959349, real_scores: 0.829512, fake_scores: 0.162601\n",
      "Finish Epoch [72/100], D Loss: 0.884937, G Loss: 4.431870\n",
      "Epoch [73/100], Step:  38400, d_loss: 0.487927, g_loss: 2.245956, real_scores: 0.820919, fake_scores: 0.118056\n",
      "Finish Epoch [73/100], D Loss: 0.855229, G Loss: 4.334263\n",
      "Epoch [74/100], Step:  38400, d_loss: 0.459084, g_loss: 2.277320, real_scores: 0.839464, fake_scores: 0.138892\n",
      "Finish Epoch [74/100], D Loss: 0.842401, G Loss: 4.306349\n",
      "Epoch [75/100], Step:  38400, d_loss: 0.335541, g_loss: 3.265349, real_scores: 0.868141, fake_scores: 0.104627\n",
      "Finish Epoch [75/100], D Loss: 0.855730, G Loss: 4.318528\n",
      "Epoch [76/100], Step:  38400, d_loss: 0.501476, g_loss: 2.342639, real_scores: 0.834392, fake_scores: 0.175112\n",
      "Finish Epoch [76/100], D Loss: 0.828888, G Loss: 4.184002\n",
      "Epoch [77/100], Step:  38400, d_loss: 0.415506, g_loss: 2.420837, real_scores: 0.852700, fake_scores: 0.122025\n",
      "Finish Epoch [77/100], D Loss: 0.809426, G Loss: 4.163245\n",
      "Epoch [78/100], Step:  38400, d_loss: 0.493293, g_loss: 2.288065, real_scores: 0.813701, fake_scores: 0.101583\n",
      "Finish Epoch [78/100], D Loss: 0.807503, G Loss: 4.117918\n",
      "Epoch [79/100], Step:  38400, d_loss: 0.470988, g_loss: 1.834145, real_scores: 0.843344, fake_scores: 0.173032\n",
      "Finish Epoch [79/100], D Loss: 0.789249, G Loss: 4.068109\n",
      "Epoch [80/100], Step:  38400, d_loss: 0.464748, g_loss: 2.343460, real_scores: 0.819399, fake_scores: 0.119514\n",
      "Finish Epoch [80/100], D Loss: 0.777792, G Loss: 4.017347\n",
      "Epoch [81/100], Step:  38400, d_loss: 0.540123, g_loss: 2.108676, real_scores: 0.795013, fake_scores: 0.099015\n",
      "Finish Epoch [81/100], D Loss: 0.761684, G Loss: 3.993723\n",
      "Epoch [82/100], Step:  38400, d_loss: 0.556118, g_loss: 2.254860, real_scores: 0.777394, fake_scores: 0.116493\n",
      "Finish Epoch [82/100], D Loss: 0.762108, G Loss: 3.931739\n",
      "Epoch [83/100], Step:  38400, d_loss: 0.563977, g_loss: 2.206954, real_scores: 0.785131, fake_scores: 0.072287\n",
      "Finish Epoch [83/100], D Loss: 0.739725, G Loss: 3.852774\n",
      "Epoch [84/100], Step:  38400, d_loss: 0.491755, g_loss: 2.768223, real_scores: 0.838753, fake_scores: 0.149787\n",
      "Finish Epoch [84/100], D Loss: 0.728628, G Loss: 3.827241\n",
      "Epoch [85/100], Step:  38400, d_loss: 0.421813, g_loss: 3.392857, real_scores: 0.892883, fake_scores: 0.169484\n",
      "Finish Epoch [85/100], D Loss: 0.712343, G Loss: 3.807165\n",
      "Epoch [86/100], Step:  38400, d_loss: 0.490865, g_loss: 2.364874, real_scores: 0.845713, fake_scores: 0.136386\n",
      "Finish Epoch [86/100], D Loss: 0.717799, G Loss: 3.786754\n",
      "Epoch [87/100], Step:  38400, d_loss: 0.449497, g_loss: 2.849152, real_scores: 0.817133, fake_scores: 0.104850\n",
      "Finish Epoch [87/100], D Loss: 0.706702, G Loss: 3.752430\n",
      "Epoch [88/100], Step:  38400, d_loss: 0.515334, g_loss: 3.111991, real_scores: 0.834427, fake_scores: 0.176726\n",
      "Finish Epoch [88/100], D Loss: 0.681753, G Loss: 3.662762\n",
      "Epoch [89/100], Step:  38400, d_loss: 0.491451, g_loss: 2.380916, real_scores: 0.889123, fake_scores: 0.212099\n",
      "Finish Epoch [89/100], D Loss: 0.670651, G Loss: 3.675524\n",
      "Epoch [90/100], Step:  38400, d_loss: 0.436583, g_loss: 3.016709, real_scores: 0.889698, fake_scores: 0.180471\n",
      "Finish Epoch [90/100], D Loss: 0.669506, G Loss: 3.631630\n",
      "Epoch [91/100], Step:  38400, d_loss: 0.493407, g_loss: 2.169043, real_scores: 0.865052, fake_scores: 0.190652\n",
      "Finish Epoch [91/100], D Loss: 0.654250, G Loss: 3.580589\n",
      "Epoch [92/100], Step:  38400, d_loss: 0.446084, g_loss: 3.585131, real_scores: 0.815548, fake_scores: 0.081158\n",
      "Finish Epoch [92/100], D Loss: 0.654046, G Loss: 3.605763\n",
      "Epoch [93/100], Step:  38400, d_loss: 0.488258, g_loss: 3.044634, real_scores: 0.799060, fake_scores: 0.041763\n",
      "Finish Epoch [93/100], D Loss: 0.636904, G Loss: 3.517379\n",
      "Epoch [94/100], Step:  38400, d_loss: 0.363173, g_loss: 2.595077, real_scores: 0.866262, fake_scores: 0.107689\n",
      "Finish Epoch [94/100], D Loss: 0.637464, G Loss: 3.519208\n",
      "Epoch [95/100], Step:  38400, d_loss: 0.484109, g_loss: 3.618727, real_scores: 0.796272, fake_scores: 0.097773\n",
      "Finish Epoch [95/100], D Loss: 0.618269, G Loss: 3.450713\n",
      "Epoch [96/100], Step:  38400, d_loss: 0.428614, g_loss: 2.557669, real_scores: 0.871104, fake_scores: 0.175200\n",
      "Finish Epoch [96/100], D Loss: 0.607539, G Loss: 3.418940\n",
      "Epoch [97/100], Step:  38400, d_loss: 0.447666, g_loss: 2.757391, real_scores: 0.845264, fake_scores: 0.089737\n",
      "Finish Epoch [97/100], D Loss: 0.613999, G Loss: 3.478057\n",
      "Epoch [98/100], Step:  38400, d_loss: 0.329100, g_loss: 3.729714, real_scores: 0.875592, fake_scores: 0.089714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Epoch [98/100], D Loss: 0.604336, G Loss: 3.399274\n",
      "Epoch [99/100], Step:  38400, d_loss: 0.378952, g_loss: 2.404691, real_scores: 0.876978, fake_scores: 0.142758\n",
      "Finish Epoch [99/100], D Loss: 0.594537, G Loss: 3.357696\n",
      "Epoch [100/100], Step:  38400, d_loss: 0.472929, g_loss: 2.992820, real_scores: 0.879532, fake_scores: 0.190114\n",
      "Finish Epoch [100/100], D Loss: 0.582962, G Loss: 3.293169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(xrange(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        real_labels = torch.ones(img.size(0), 1).cuda()\n",
    "        fake_labels = torch.zeros(img.size(0), 1).cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = criterion(real_out, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = criterion(fake_out, real_labels)\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, './cnn_gan_img/real_images.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, './cnn_gan_img/fake_images-{}.png'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/discriminator.pkl')\n",
    "torch.save(g.state_dict(), './ser/generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f607731d690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
