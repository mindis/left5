{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 56 56\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 56 56\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 56 56\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 28 28\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        out = out.view(x.size(0), 1, 56, 56)\n",
    "        out = self.br(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "d.weight_init(.0, 0.02)\n",
    "g.weight_init(.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4)\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e569e3311483479bae8446078f9e093b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 0.655987, g_loss: 1.732537, real_scores: 0.862682, fake_scores: 0.323364\n",
      "Finish Epoch [1/100], D Loss: 56.800571, G Loss: 399.942720\n",
      "Epoch [2/100], Step:  38400, d_loss: 0.457883, g_loss: 2.558699, real_scores: 0.844887, fake_scores: 0.202986\n",
      "Finish Epoch [2/100], D Loss: 34.943220, G Loss: 136.650664\n",
      "Epoch [3/100], Step:  38400, d_loss: 0.264920, g_loss: 2.694903, real_scores: 0.934118, fake_scores: 0.147648\n",
      "Finish Epoch [3/100], D Loss: 16.656673, G Loss: 114.253648\n",
      "Epoch [4/100], Step:  38400, d_loss: 0.342687, g_loss: 2.823973, real_scores: 0.880387, fake_scores: 0.122589\n",
      "Finish Epoch [4/100], D Loss: 13.707531, G Loss: 90.436572\n",
      "Epoch [5/100], Step:  38400, d_loss: 0.604085, g_loss: 2.813532, real_scores: 0.859972, fake_scores: 0.256187\n",
      "Finish Epoch [5/100], D Loss: 13.524943, G Loss: 66.986791\n",
      "Epoch [6/100], Step:  38400, d_loss: 0.479507, g_loss: 2.410071, real_scores: 0.903172, fake_scores: 0.255798\n",
      "Finish Epoch [6/100], D Loss: 11.182317, G Loss: 52.061082\n",
      "Epoch [7/100], Step:  38400, d_loss: 0.638552, g_loss: 2.303755, real_scores: 0.742242, fake_scores: 0.132589\n",
      "Finish Epoch [7/100], D Loss: 10.404597, G Loss: 43.191843\n",
      "Epoch [8/100], Step:  38400, d_loss: 0.496581, g_loss: 2.988422, real_scores: 0.860993, fake_scores: 0.224097\n",
      "Finish Epoch [8/100], D Loss: 9.164567, G Loss: 37.156049\n",
      "Epoch [9/100], Step:  38400, d_loss: 0.578896, g_loss: 1.771971, real_scores: 0.784963, fake_scores: 0.149714\n",
      "Finish Epoch [9/100], D Loss: 8.117623, G Loss: 32.598334\n",
      "Epoch [10/100], Step:  38400, d_loss: 0.538727, g_loss: 1.480504, real_scores: 0.857469, fake_scores: 0.232760\n",
      "Finish Epoch [10/100], D Loss: 7.182519, G Loss: 29.384289\n",
      "Epoch [11/100], Step:  38400, d_loss: 0.525347, g_loss: 2.324269, real_scores: 0.794407, fake_scores: 0.168428\n",
      "Finish Epoch [11/100], D Loss: 6.761216, G Loss: 27.170919\n",
      "Epoch [12/100], Step:  38400, d_loss: 0.558875, g_loss: 2.240723, real_scores: 0.816659, fake_scores: 0.210655\n",
      "Finish Epoch [12/100], D Loss: 6.028256, G Loss: 24.673564\n",
      "Epoch [13/100], Step:  38400, d_loss: 0.578133, g_loss: 2.450886, real_scores: 0.894308, fake_scores: 0.299152\n",
      "Finish Epoch [13/100], D Loss: 5.416272, G Loss: 22.506432\n",
      "Epoch [14/100], Step:  38400, d_loss: 0.574071, g_loss: 2.272546, real_scores: 0.802724, fake_scores: 0.166378\n",
      "Finish Epoch [14/100], D Loss: 5.060758, G Loss: 20.961807\n",
      "Epoch [15/100], Step:  38400, d_loss: 0.513135, g_loss: 2.103391, real_scores: 0.846895, fake_scores: 0.196998\n",
      "Finish Epoch [15/100], D Loss: 4.735761, G Loss: 19.845487\n",
      "Epoch [16/100], Step:  38400, d_loss: 0.444008, g_loss: 2.137999, real_scores: 0.847478, fake_scores: 0.172002\n",
      "Finish Epoch [16/100], D Loss: 4.513631, G Loss: 18.384225\n",
      "Epoch [17/100], Step:  38400, d_loss: 0.742200, g_loss: 2.686141, real_scores: 0.681508, fake_scores: 0.067137\n",
      "Finish Epoch [17/100], D Loss: 4.154424, G Loss: 17.227627\n",
      "Epoch [18/100], Step:  38400, d_loss: 0.556547, g_loss: 2.705868, real_scores: 0.839488, fake_scores: 0.214497\n",
      "Finish Epoch [18/100], D Loss: 3.975250, G Loss: 16.409721\n",
      "Epoch [19/100], Step:  38400, d_loss: 0.576035, g_loss: 2.380347, real_scores: 0.834118, fake_scores: 0.230956\n",
      "Finish Epoch [19/100], D Loss: 3.765170, G Loss: 15.483101\n",
      "Epoch [20/100], Step:  38400, d_loss: 0.551353, g_loss: 1.755893, real_scores: 0.801109, fake_scores: 0.173030\n",
      "Finish Epoch [20/100], D Loss: 3.575206, G Loss: 14.758026\n",
      "Epoch [21/100], Step:  38400, d_loss: 0.534268, g_loss: 2.912460, real_scores: 0.815175, fake_scores: 0.192811\n",
      "Finish Epoch [21/100], D Loss: 3.374319, G Loss: 14.070982\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e05a562f7a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfake_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfake_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfake_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2027\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        real_labels = torch.ones(img.size(0), 1).cuda()\n",
    "        fake_labels = torch.zeros(img.size(0), 1).cuda()\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = criterion(real_out, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## G ##########\n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = criterion(fake_out, real_labels)\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, './cnn_gan_img/real_images.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, './cnn_gan_img/fake_images-{}.png'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/discriminator.pkl')\n",
    "torch.save(g.state_dict(), './ser/generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
