{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = (32, 4, 4)\n",
    "\n",
    "img_shape = (1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "#     fake_data = fake_data.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates, _ = netD(interpolates)\n",
    "    \n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.shape).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise_label(batch_size):\n",
    "    label = np.random.randint(0, 10, batch_size)\n",
    "    #prefix = np.zeros((batch_size, 10))\n",
    "    #prefix[np.arange(batch_size), label] = 1\n",
    "    return label # prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, 10))\n",
    "    prefix[np.arange(batch_size), label] = 1\n",
    "    z = np.random.normal(0, 1, (batch_size, z_dimension))\n",
    "#     prefix = prefix / np.linalg.norm(prefix)\n",
    "    z[:, :10] = prefix\n",
    "    return torch.from_numpy(z).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = label = np.random.randint(0, 10, 20)\n",
    "b = gen_noise(20, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "#         self.label_embedding = nn.Embedding(10, np.prod(img_shape))\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1, stride=2),\n",
    "#             nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 16 16 16\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2),\n",
    "#             nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 8 8\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 64 4 4\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1, stride=2),\n",
    "#             nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 128 2 2\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 2 * 2, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "#             nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "        \n",
    "        self.label = nn.Sequential(\n",
    "            nn.Linear(128 * 2 * 2, 10),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs): # b 1 32 32\n",
    "        \n",
    "#         if(fake_labels is None):\n",
    "#             _imgs = torch.cat((imgs, self.label_embedding(real_labels).reshape(imgs.size(0), *img_shape)), 1)\n",
    "#         else:\n",
    "#             _labs = self.label_embedding(real_labels).reshape(imgs.size(0), *img_shape) + self.label_embedding(real_labels).reshape(imgs.size(0), *img_shape)\n",
    "#             _imgs = torch.cat((imgs, _labs), 1)\n",
    "\n",
    "        outs = self.conv1(imgs)\n",
    "        outs = self.conv2(outs)\n",
    "        outs = self.conv3(outs)\n",
    "        outs = self.conv4(outs)\n",
    "        outs = outs.view(imgs.size(0), -1)\n",
    "        img = self.fc(outs)\n",
    "        lab = self.label(outs)\n",
    "        \n",
    "        return img, lab # b 1 1 1, b 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "#         self.label_emb = nn.Embedding(inp_dim, inp_dim)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, np.prod(num_feature)),\n",
    "#             nn.Sigmoid(),\n",
    "        ) # b *num_feature  b 32 4 4\n",
    "        \n",
    "        self.upsample1 = nn.Sequential(\n",
    "#             nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1),\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(32, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(True),\n",
    "        ) # b 16 8 8\n",
    "        \n",
    "        self.upsample2 = nn.Sequential(\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "            nn.ConvTranspose2d(16, 8, 4, 2, 1, 0),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(True),\n",
    "        ) # b 8 16 16\n",
    "        \n",
    "        self.upsample3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 4, 4, 2, 1),\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(8, 4, 3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(True),\n",
    "        ) # b 4 32 32\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "            nn.Conv2d(4, 1, 3, padding=1, stride=1),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 32 32\n",
    "\n",
    "    def forward(self, noise):\n",
    "        \n",
    "#         gen_input = torch.cat((labels.reshape(noise.size(0), -1), noise), -1)\n",
    "#         gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "#         gen_input = self.label_emb(noise)\n",
    "        \n",
    "        outs = self.fc(noise)\n",
    "        outs = outs.view(noise.size(0), *num_feature)\n",
    "        outs = self.upsample1(outs)\n",
    "        outs = self.upsample2(outs)\n",
    "        outs = self.upsample3(outs)\n",
    "\n",
    "        outs = self.conv(outs)\n",
    "        \n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "# D.weight_init(.0, 0.02)\n",
    "# G.weight_init(.0, 0.02)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "d_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "g_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_condition_wgan_gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"save_images/cnn_condition_wgan_img\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_label = np.arange(10)\n",
    "# condition_noise = np.random.randn(condition_label.shape[0], z_dimension)\n",
    "# condition_noise[:, 0] += condition_label\n",
    "# # condition_noise = condition_noise / np.linalg.norm(condition_noise)\n",
    "# condition_noise = torch.from_numpy(condition_noise).float()\n",
    "condition_noise = gen_noise(condition_label.shape[0], condition_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a992c9600b440208c51cfc2a8cf5559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch[1/100], Step:  38400, d_loss: -12.671673, g_loss: -23.820839 real_scores: 35.367889, fake_scores: 21.427956, W: -13.939934\n",
      "Finish Epoch [1/100], D Loss: -1776.297395, G Loss: -3061.520319, W: -2249.989502\n",
      "  Epoch[2/100], Step:  38400, d_loss: -3.681674, g_loss: -27.096870 real_scores: 21.486483, fake_scores: 17.171963, W: -4.314520\n",
      "Finish Epoch [2/100], D Loss: -263.601709, G Loss: -1645.014354, W: -297.374115\n",
      "  Epoch[3/100], Step:  38400, d_loss: -3.958251, g_loss: -12.576652 real_scores: 2.839991, fake_scores: -1.529711, W: -4.369701\n",
      "Finish Epoch [3/100], D Loss: -168.199848, G Loss: -533.338990, W: -194.944809\n",
      "  Epoch[4/100], Step:  38400, d_loss: -4.826548, g_loss: -6.638592 real_scores: -3.817691, fake_scores: -9.443663, W: -5.625971\n",
      "Finish Epoch [4/100], D Loss: -153.744658, G Loss: -218.715411, W: -178.484131\n",
      "  Epoch[5/100], Step:  38400, d_loss: -5.729529, g_loss: -6.530180 real_scores: -5.236649, fake_scores: -12.123692, W: -6.887043\n",
      "Finish Epoch [5/100], D Loss: -152.310701, G Loss: -172.178001, W: -178.066269\n",
      "  Epoch[6/100], Step:  38400, d_loss: -6.410870, g_loss: -6.697784 real_scores: -4.949164, fake_scores: -12.609945, W: -7.660781\n",
      "Finish Epoch [6/100], D Loss: -147.845852, G Loss: -130.384482, W: -173.978745\n",
      "  Epoch[7/100], Step:  38400, d_loss: -7.710885, g_loss: -6.662025 real_scores: -5.693793, fake_scores: -15.054646, W: -9.360852\n",
      "Finish Epoch [7/100], D Loss: -140.689483, G Loss: -109.765869, W: -166.374573\n",
      "  Epoch[8/100], Step:  38400, d_loss: -6.730096, g_loss: -4.407526 real_scores: -9.807211, fake_scores: -19.690527, W: -9.883316\n",
      "Finish Epoch [8/100], D Loss: -133.323448, G Loss: -82.179343, W: -159.161972\n",
      "  Epoch[9/100], Step:  38400, d_loss: -8.392215, g_loss: -4.925552 real_scores: -8.238638, fake_scores: -19.826515, W: -11.587877\n",
      "Finish Epoch [9/100], D Loss: -133.016969, G Loss: -81.299003, W: -160.236069\n",
      "  Epoch[10/100], Step:  38400, d_loss: -9.281322, g_loss: -5.284195 real_scores: -8.155103, fake_scores: -20.709400, W: -12.554297\n",
      "Finish Epoch [10/100], D Loss: -129.141660, G Loss: -67.405883, W: -156.400742\n",
      "  Epoch[11/100], Step:  38400, d_loss: -10.956808, g_loss: -4.999220 real_scores: -8.833575, fake_scores: -22.690962, W: -13.857387\n",
      "Finish Epoch [11/100], D Loss: -130.071942, G Loss: -63.569925, W: -158.858551\n",
      "  Epoch[12/100], Step:  38400, d_loss: -11.464846, g_loss: -4.008476 real_scores: -10.790255, fake_scores: -24.457708, W: -13.667454\n",
      "Finish Epoch [12/100], D Loss: -129.987433, G Loss: -62.073968, W: -159.748322\n",
      "  Epoch[13/100], Step:  38400, d_loss: -12.314881, g_loss: -3.303955 real_scores: -10.921556, fake_scores: -29.497807, W: -18.576250\n",
      "Finish Epoch [13/100], D Loss: -136.748245, G Loss: -62.234617, W: -170.155685\n",
      "  Epoch[14/100], Step:  38400, d_loss: -14.439989, g_loss: -7.758091 real_scores: -8.408894, fake_scores: -27.228714, W: -18.819820\n",
      "Finish Epoch [14/100], D Loss: -131.992752, G Loss: -55.155660, W: -165.121185\n",
      "  Epoch[15/100], Step:  38400, d_loss: -15.756069, g_loss: -4.942919 real_scores: -9.287939, fake_scores: -29.815680, W: -20.527740\n",
      "Finish Epoch [15/100], D Loss: -121.694814, G Loss: -46.382175, W: -152.444595\n",
      "  Epoch[16/100], Step:  38400, d_loss: -15.456617, g_loss: -6.312531 real_scores: -10.652492, fake_scores: -33.047447, W: -22.394955\n",
      "Finish Epoch [16/100], D Loss: -119.290831, G Loss: -55.916321, W: -149.869202\n",
      "  Epoch[17/100], Step:  38400, d_loss: -17.380468, g_loss: -10.199743 real_scores: -6.858657, fake_scores: -26.445627, W: -19.586971\n",
      "Finish Epoch [17/100], D Loss: -117.047913, G Loss: -52.661518, W: -147.995239\n",
      "  Epoch[18/100], Step:  38400, d_loss: -18.331432, g_loss: -9.820972 real_scores: -7.543810, fake_scores: -28.894878, W: -21.351068\n",
      "Finish Epoch [18/100], D Loss: -113.949608, G Loss: -52.530804, W: -144.342270\n",
      "  Epoch[19/100], Step:  38400, d_loss: -13.855578, g_loss: -5.717625 real_scores: -10.374745, fake_scores: -29.956429, W: -19.581684\n",
      "Finish Epoch [19/100], D Loss: -105.877862, G Loss: -46.920078, W: -134.132629\n",
      "  Epoch[20/100], Step:  38400, d_loss: -17.178379, g_loss: -10.740084 real_scores: -7.190274, fake_scores: -26.870073, W: -19.679800\n",
      "Finish Epoch [20/100], D Loss: -98.885928, G Loss: -46.413335, W: -125.190521\n",
      "  Epoch[21/100], Step:  38400, d_loss: -16.844198, g_loss: -9.716393 real_scores: -7.987320, fake_scores: -29.351482, W: -21.364162\n",
      "Finish Epoch [21/100], D Loss: -101.423254, G Loss: -51.906755, W: -129.041977\n",
      "  Epoch[22/100], Step:  38400, d_loss: -15.960827, g_loss: -10.323479 real_scores: -7.401565, fake_scores: -28.609165, W: -21.207600\n",
      "Finish Epoch [22/100], D Loss: -101.917630, G Loss: -52.443032, W: -130.013168\n",
      "  Epoch[23/100], Step:  38400, d_loss: -16.267630, g_loss: -8.774414 real_scores: -8.419681, fake_scores: -30.244534, W: -21.824852\n",
      "Finish Epoch [23/100], D Loss: -97.901652, G Loss: -45.112456, W: -125.459419\n",
      "  Epoch[24/100], Step:  38400, d_loss: -17.603415, g_loss: -9.091705 real_scores: -9.176497, fake_scores: -33.172100, W: -23.995604\n",
      "Finish Epoch [24/100], D Loss: -97.847052, G Loss: -47.427324, W: -125.409508\n",
      "  Epoch[25/100], Step:  38400, d_loss: -18.314621, g_loss: -8.847656 real_scores: -9.448668, fake_scores: -34.868694, W: -25.420027\n",
      "Finish Epoch [25/100], D Loss: -99.573739, G Loss: -50.027023, W: -128.495422\n",
      "  Epoch[26/100], Step:  38400, d_loss: -18.866659, g_loss: -9.558102 real_scores: -8.918487, fake_scores: -37.263603, W: -28.345116\n",
      "Finish Epoch [26/100], D Loss: -99.428576, G Loss: -52.809051, W: -128.808014\n",
      "  Epoch[27/100], Step:  38400, d_loss: -19.412319, g_loss: -11.170918 real_scores: -6.934989, fake_scores: -33.687572, W: -26.752583\n",
      "Finish Epoch [27/100], D Loss: -95.774504, G Loss: -58.851024, W: -123.707443\n",
      "  Epoch[28/100], Step:  38400, d_loss: -20.381697, g_loss: -9.708725 real_scores: -7.897100, fake_scores: -36.688675, W: -28.791574\n",
      "Finish Epoch [28/100], D Loss: -93.269405, G Loss: -54.709131, W: -120.712616\n",
      "  Epoch[29/100], Step:  38400, d_loss: -18.764923, g_loss: -14.347065 real_scores: -4.290774, fake_scores: -28.563953, W: -24.273178\n",
      "Finish Epoch [29/100], D Loss: -88.373875, G Loss: -50.571161, W: -114.235321\n",
      "  Epoch[30/100], Step:  38400, d_loss: -19.377569, g_loss: -11.873287 real_scores: -6.152672, fake_scores: -33.343857, W: -27.191185\n",
      "Finish Epoch [30/100], D Loss: -86.966188, G Loss: -54.433491, W: -112.380226\n",
      "  Epoch[31/100], Step:  38400, d_loss: -18.589533, g_loss: -13.153149 real_scores: -5.250137, fake_scores: -30.127586, W: -24.877449\n",
      "Finish Epoch [31/100], D Loss: -85.484997, G Loss: -48.977199, W: -110.844009\n",
      "  Epoch[32/100], Step:  38400, d_loss: -21.848297, g_loss: -9.628860 real_scores: -9.328408, fake_scores: -41.363861, W: -32.035454\n",
      "Finish Epoch [32/100], D Loss: -93.412062, G Loss: -52.682386, W: -122.448204\n",
      "  Epoch[33/100], Step:  38400, d_loss: -25.108395, g_loss: -14.635109 real_scores: -5.341911, fake_scores: -36.429001, W: -31.087090\n",
      "Finish Epoch [33/100], D Loss: -89.913816, G Loss: -53.895931, W: -117.944374\n",
      "  Epoch[34/100], Step:  38400, d_loss: -27.288292, g_loss: -17.605461 real_scores: -4.340233, fake_scores: -39.679462, W: -35.339230\n",
      "Finish Epoch [34/100], D Loss: -98.874172, G Loss: -56.389063, W: -131.559219\n",
      "  Epoch[35/100], Step:  38400, d_loss: -26.574560, g_loss: -18.531219 real_scores: -2.247580, fake_scores: -35.845161, W: -33.597580\n",
      "Finish Epoch [35/100], D Loss: -95.465697, G Loss: -58.320256, W: -127.017769\n",
      "  Epoch[36/100], Step:  38400, d_loss: -33.875599, g_loss: -14.637817 real_scores: -5.920023, fake_scores: -44.989021, W: -39.069000\n",
      "Finish Epoch [36/100], D Loss: -99.042341, G Loss: -63.110587, W: -132.443558\n",
      "  Epoch[37/100], Step:  38400, d_loss: -24.918484, g_loss: -17.269131 real_scores: -4.302376, fake_scores: -38.704769, W: -34.402393\n",
      "Finish Epoch [37/100], D Loss: -90.038843, G Loss: -59.723720, W: -120.150421\n",
      "  Epoch[38/100], Step:  38400, d_loss: -24.047527, g_loss: -19.243420 real_scores: -1.605580, fake_scores: -37.742241, W: -36.136662\n",
      "Finish Epoch [38/100], D Loss: -92.320336, G Loss: -57.655166, W: -123.481667\n",
      "  Epoch[39/100], Step:  38400, d_loss: -29.934494, g_loss: -22.276829 real_scores: -0.009680, fake_scores: -37.761551, W: -37.751869\n",
      "Finish Epoch [39/100], D Loss: -93.732847, G Loss: -63.574017, W: -125.682243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch[40/100], Step:  38400, d_loss: -29.534201, g_loss: -22.870922 real_scores: 1.659099, fake_scores: -36.024261, W: -37.683361\n",
      "Finish Epoch [40/100], D Loss: -87.248243, G Loss: -61.340076, W: -116.479950\n",
      "  Epoch[41/100], Step:  38400, d_loss: -26.232845, g_loss: -19.332722 real_scores: -1.286572, fake_scores: -37.561932, W: -36.275360\n",
      "Finish Epoch [41/100], D Loss: -85.666533, G Loss: -62.298330, W: -114.611221\n",
      "  Epoch[42/100], Step:  38400, d_loss: -29.546261, g_loss: -25.436085 real_scores: 2.705027, fake_scores: -36.178474, W: -38.883503\n",
      "Finish Epoch [42/100], D Loss: -90.572022, G Loss: -69.141909, W: -121.965126\n",
      "  Epoch[43/100], Step:  38400, d_loss: -33.352139, g_loss: -31.106491 real_scores: 6.445925, fake_scores: -36.595169, W: -43.041096\n",
      "Finish Epoch [43/100], D Loss: -96.062161, G Loss: -71.310397, W: -130.676895\n",
      "  Epoch[44/100], Step:  38400, d_loss: -33.019150, g_loss: -26.716805 real_scores: 3.740685, fake_scores: -38.903168, W: -42.643852\n",
      "Finish Epoch [44/100], D Loss: -95.085347, G Loss: -67.945781, W: -129.266266\n",
      "  Epoch[45/100], Step:  38400, d_loss: -29.734377, g_loss: -22.621140 real_scores: 1.136893, fake_scores: -45.285439, W: -46.422333\n",
      "Finish Epoch [45/100], D Loss: -88.972090, G Loss: -67.915807, W: -120.700325\n",
      "  Epoch[46/100], Step:  38400, d_loss: -29.503740, g_loss: -26.502453 real_scores: 4.434859, fake_scores: -36.955677, W: -41.390537\n",
      "Finish Epoch [46/100], D Loss: -84.779486, G Loss: -67.497427, W: -114.668304\n",
      "  Epoch[47/100], Step:  38400, d_loss: -27.640285, g_loss: -25.380970 real_scores: 2.074131, fake_scores: -37.598236, W: -39.672367\n",
      "Finish Epoch [47/100], D Loss: -81.838140, G Loss: -68.011628, W: -110.484406\n",
      "  Epoch[48/100], Step:  38400, d_loss: -34.919956, g_loss: -22.100227 real_scores: -0.248345, fake_scores: -39.042488, W: -38.794144\n",
      "Finish Epoch [48/100], D Loss: -83.204489, G Loss: -68.670035, W: -112.748779\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    w_dist_total = .0\n",
    "    for i, (imgs, labs) in enumerate(dataloader):\n",
    "        \n",
    "        real_imgs = imgs.cuda()\n",
    "        real_labs = labs.cuda()\n",
    "        \n",
    "        z = np.random.randn(imgs.size(0), z_dimension)\n",
    "        fake_labels = np.random.randint(0, 10, imgs.shape[0])\n",
    "#         z[:, 0] += fake_labels\n",
    "# #         z = z / np.linalg.norm(z)\n",
    "#         z = torch.from_numpy(z).float().cuda()\n",
    "        z = gen_noise(z.shape[0], fake_labels)\n",
    "        ########## G ##########\n",
    "#         for p in D.parameters():\n",
    "#             p.requires_grad_(False)\n",
    "        \n",
    "        fake_imgs = G(z)\n",
    "        fake_out, fake_out_labels = D(fake_imgs)\n",
    "        fake_labels_loss = criterion(fake_out_labels, torch.from_numpy(fake_labels).cuda()).mean()\n",
    "        fake_cost = fake_out.mean()\n",
    "        g_loss = 1 * fake_labels_loss + fake_cost\n",
    "\n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward(mone)\n",
    "        g_loss = -g_loss\n",
    "        g_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        \n",
    "        ########## D ##########\n",
    "#         for p in D.parameters():\n",
    "#             p.requires_grad_(True)\n",
    "        \n",
    "        real_out, real_labels = D(real_imgs)\n",
    "        real_labels_loss = criterion(real_labels, real_labs)\n",
    "        d_loss_real_labels = real_labels_loss.mean()\n",
    "        d_loss_real = real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_out, fake_out_labels = D(fake_imgs.detach())\n",
    "#         d_loss_fake_labels = criterion(fake_out_labels, torch.from_numpy(fake_labels).cuda()).mean()\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(D, real_imgs, fake_imgs)\n",
    "        \n",
    "        d_loss = d_loss_fake - d_loss_real + gradient_penalty # + 1 * d_loss_real_lab\n",
    "        \n",
    "        d_optimezer.zero_grad()\n",
    "#         d_loss.backward()\n",
    "        (d_loss + 1 * (d_loss_real_labels)).backward() # + d_loss_fake_labels\n",
    "        d_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        w_dist = d_loss_fake - d_loss_real\n",
    "        \n",
    "        d_loss_total += d_loss.item() * imgs.size(0)\n",
    "        g_loss_total += g_loss.item() * imgs.size(0)\n",
    "        w_dist_total += w_dist * imgs.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "            writer.add_scalar('Wasserstein Distance', w_dist.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('  Epoch[{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f} real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}, W: {:.6f}'.format(epoch+1, num_epochs, \n",
    "                                          (i+1) * BATCH_SIZE, \n",
    "                                          d_loss, g_loss, \n",
    "                                          real_scores.mean(), \n",
    "                                          fake_scores.mean(), w_dist))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    _w_dist_total = w_dist_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}, W: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total,\n",
    "                                                                             _w_dist_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_imgs.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    condition_imgs = G(condition_noise)\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_imgs.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    \n",
    "    fake_images = fake_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    save_image(condition_imgs, os.path.join(img_path, 'condition_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), './ser/condition_wgan_gp_discriminator_4.pt')\n",
    "torch.save(G.state_dict(), './ser/condition_wgan_gp_generator_4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.load_state_dict(torch.load('./ser/condition_wgan_gp_discriminator_4.pt'))\n",
    "G.load_state_dict(torch.load('./ser/condition_wgan_gp_generator_4.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = np.arange(10)\n",
    "z = gen_noise(words.shape[0], words)\n",
    "images = G(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
