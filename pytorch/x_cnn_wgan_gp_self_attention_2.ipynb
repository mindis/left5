{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "DIM = 56\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('~/data/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "#     fake_data = fake_data.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{array}\n",
       "{ll}H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n",
       "                    \\times (\\text{kernel_size}[0] - 1) + \\text{output_padding}[0] + 1\n",
       "\\end{array}\n",
       "\\begin{array}\n",
       "{ll}W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n",
       "                    \\times (\\text{kernel_size}[1] - 1) + \\text{output_padding}[1] + 1\n",
       "\n",
       "\\end{array}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{array}\n",
    "{ll}H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n",
    "                    \\times (\\text{kernel_size}[0] - 1) + \\text{output_padding}[0] + 1\n",
    "\\end{array}\n",
    "\\begin{array}\n",
    "{ll}W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n",
    "                    \\times (\\text{kernel_size}[1] - 1) + \\text{output_padding}[1] + 1\n",
    "\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        m_batchsize, C, width ,height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1) # B (N) C\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width * height) # B C (N)\n",
    "        energy = torch.bmm(proj_query, proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # B (N) (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width * height) # B C N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1)) # B C N\n",
    "        out = out.view(m_batchsize, C, width, height) # B C W H\n",
    "        \n",
    "        out = self.gamma * out + x\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(1, 256, 3, padding=1)),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            \n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 28 28\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(256, 128, 3, padding=1, stride=2)),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            \n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(128, 64, 3, padding=1, stride=2)),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(64, 32, 3, padding=1, stride=2)),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2),\n",
    "        ) # b 128 4 4\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(32, 16, 3, padding=1, stride=2)),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2),\n",
    "        ) # b 256 2 2\n",
    "        \n",
    "        self.att1 = SelfAttention(64)\n",
    "        self.att2 = SelfAttention(32)\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(16, 1, 2, padding=1, stride=2),\n",
    "#             nn.Tanh()\n",
    "#             nn.AvgPool2d(2, 2),\n",
    "        ) # b 256 2 2\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Linear(256 * 2 * 2, 1024), dim=0),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.utils.spectral_norm(nn.Linear(1024, 1), dim=0),\n",
    "#             nn.Sigmoid(),\n",
    "# #             nn.Tanh(),\n",
    "#         ) # b 1\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out, p1 = self.att1(out)\n",
    "        out = self.conv4(out)\n",
    "#         out, p2 = self.att2(out)\n",
    "        out = self.conv5(out)\n",
    "        \n",
    "        return out\n",
    "#         print(out.shape)\n",
    "#         return self.last(out)\n",
    "        \n",
    "#         out = out.view(x.size(0), -1)\n",
    "#         return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(inp_dim, num_feature),\n",
    "#             nn.Sigmoid(),\n",
    "#         ) # b h*w\n",
    "#         self.br = nn.Sequential(\n",
    "#             nn.BatchNorm2d(1),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#         ) # b 1 56 56\n",
    "        \n",
    "#         self.downsample1 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(1, 16, 3, padding=1)),\n",
    "# #             nn.BatchNorm2d(64),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#         ) # b 64 56 56\n",
    "        \n",
    "#         self.downsample2 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(16, 8, 3, padding=1)),\n",
    "#             nn.BatchNorm2d(8),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#         ) # b 32 56 56\n",
    "        \n",
    "#         self.downsample3 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(8, 1, 3, padding=1, stride=2)),\n",
    "#             nn.Tanh(),\n",
    "#         ) # b 1 28 28\n",
    "        \n",
    "#         self.att1 = SelfAttention(16)\n",
    "#         self.att2 = SelfAttention(8)\n",
    "        \n",
    "        self.upsample1 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(inp_dim, 256, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(),\n",
    "        ) # b c 2 2\n",
    "        \n",
    "        self.upsample2 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(256, 128, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(),\n",
    "        ) # b c 4 4\n",
    "        \n",
    "        self.upsample3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(128, 64, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(),\n",
    "        ) # b c 8 8\n",
    "        \n",
    "        self.upsample4 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(64, 32, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(),\n",
    "        ) # b c 16 16\n",
    "        \n",
    "        self.upsample5 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(32, 1, 4, 2, 3)),\n",
    "            nn.Tanh(),\n",
    "        ) # b c 28 28\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(16, 1, 3, padding=1, stride=1),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "        \n",
    "        self.att1 = SelfAttention(64)\n",
    "        self.att2 = SelfAttention(32)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "#         out = self.fc(x)\n",
    "        \n",
    "#         out = out.view(x.size(0), 1, 56, 56)\n",
    "#         out = self.br(out)\n",
    "#         out = self.downsample1(out)\n",
    "#         out, p1 = self.att1(out)\n",
    "#         out = self.downsample2(out)\n",
    "#         out, p2 = self.att2(out)\n",
    "#         out = self.downsample3(out)\n",
    "#         return out\n",
    "\n",
    "        out = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        out = self.upsample1(out)\n",
    "        out = self.upsample2(out)\n",
    "        out = self.upsample3(out)\n",
    "        out, p1 = self.att1(out)\n",
    "        out = self.upsample4(out)\n",
    "#         out, p2 = self.att2(out)\n",
    "        out = self.upsample5(out)\n",
    "#         out = self.conv1(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "# d.weight_init(.0, 0.02)\n",
    "# g.weight_init(.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=1e-4, betas=(0, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_wgan_gp_self_attention2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"save_images/cnn_wgan_img_self_attention2\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac569e8988c4c91ab5c6814396eab23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: -0.136853, g_loss: -0.135897, real_scores: 0.338046, fake_scores: 0.135714, w: -0.202333\n",
      "Finish Epoch [1/100], D Loss: 13.507156, G Loss: -14.639906\n",
      "Epoch [2/100], Step:  38400, d_loss: -0.050961, g_loss: -0.196344, real_scores: 0.461093, fake_scores: 0.196245, w: -0.264848\n",
      "Finish Epoch [2/100], D Loss: -9.716270, G Loss: -12.846075\n",
      "Epoch [3/100], Step:  38400, d_loss: -0.224367, g_loss: -0.350685, real_scores: 0.613066, fake_scores: 0.350625, w: -0.262442\n",
      "Finish Epoch [3/100], D Loss: -7.473197, G Loss: -11.755830\n",
      "Epoch [4/100], Step:  38400, d_loss: -0.204919, g_loss: -0.250320, real_scores: 0.491389, fake_scores: 0.250295, w: -0.241094\n",
      "Finish Epoch [4/100], D Loss: -5.807539, G Loss: -8.800686\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        ########## G ##########\n",
    "        z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        g_loss = -fake_out.mean()\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "#         g_loss.backward(mone)\n",
    "        g_loss.backward()\n",
    "#         g_loss = -g_loss\n",
    "        g_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_img = img.cuda()\n",
    "        \n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = -real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "#         z = torch.randn(img.size(0), z_dimension).cuda()\n",
    "#         fake_img = g(z) # .detach()\n",
    "        fake_out = d(fake_img.detach())\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(d, real_img, fake_img)\n",
    "        \n",
    "        d_loss = d_loss_fake + d_loss_real + gradient_penalty\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        w_dist = d_loss_fake + d_loss_real\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "            writer.add_scalar('Wasserstein Distance', w_dist.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}, w: {:.6f}'.format(epoch+1, num_epochs, (i+1) * BATCH_SIZE, d_loss, g_loss, real_scores.mean(), fake_scores.mean(), w_dist))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "\n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/wgan_gp_discriminator.pt')\n",
    "torch.save(g.state_dict(), './ser/wgan_gp_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.load_state_dict(torch.load('./ser/wgan_gp_discriminator.pt'))\n",
    "g.load_state_dict(torch.load('./ser/wgan_gp_generator.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn(10, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv36",
   "language": "python",
   "name": "venv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
