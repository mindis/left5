{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('/home/left5/datas/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates, _ = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise_label(batch_size):\n",
    "    label = np.random.randint(0, 10, batch_size)\n",
    "    #prefix = np.zeros((batch_size, 10))\n",
    "    #prefix[:, label] = 1\n",
    "    return label # prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, 10))\n",
    "    prefix[:, label] = 1\n",
    "    z = np.random.normal(0, 1, (batch_size, z_dimension))\n",
    "    prefix = prefix / np.linalg.norm(prefix)\n",
    "    z[:, :10] + prefix\n",
    "    return torch.from_numpy(z).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 14 14\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "        ) # b 64 7 7\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 10),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 10\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 28 28\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = out.view(x.size(0), -1)\n",
    "        img = self.fc1(out)\n",
    "        con = self.fc2(out)\n",
    "        return img, con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, num_feature),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b h*w\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 1 56 56\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 64 56 56\n",
    "        \n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b 32 56 56\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1, stride=2),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 28 28\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        out = out.view(x.size(0), 1, 56, 56)\n",
    "        out = self.br(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.downsample3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "D.weight_init(.0, 0.02)\n",
    "G.weight_init(.0, 0.02)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "d_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "g_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_condition_wgan_gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"cnn_condition_wgan_img\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_label = np.arange(10)\n",
    "condition_noise = gen_noise(10, condition_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaca7be3ef347b6a5fb216cae42e67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch[1/100], Step:  38400, d_loss: 5.946520, g_loss: 1.464088\n",
      "    real_scores: 0.407375, fake_scores: 0.377852, W: -0.029523\n",
      "Finish Epoch [1/100], D Loss: 944.058633, G Loss: 229.927297\n",
      "  Epoch[2/100], Step:  38400, d_loss: 2.357960, g_loss: 1.880117\n",
      "    real_scores: 0.423958, fake_scores: 0.639850, W: 0.215892\n",
      "Finish Epoch [2/100], D Loss: 298.515666, G Loss: 109.382032\n",
      "  Epoch[3/100], Step:  38400, d_loss: 3.546321, g_loss: 1.420549\n",
      "    real_scores: 0.185011, fake_scores: 0.224973, W: 0.039962\n",
      "Finish Epoch [3/100], D Loss: 136.468847, G Loss: 75.338650\n",
      "  Epoch[4/100], Step:  38400, d_loss: 1.551394, g_loss: 1.803343\n",
      "    real_scores: 0.615371, fake_scores: 0.628684, W: 0.013313\n",
      "Finish Epoch [4/100], D Loss: 79.697407, G Loss: 57.109810\n",
      "  Epoch[5/100], Step:  38400, d_loss: 1.501354, g_loss: 1.874864\n",
      "    real_scores: 0.599978, fake_scores: 0.583721, W: -0.016258\n",
      "Finish Epoch [5/100], D Loss: 57.500128, G Loss: 45.805412\n",
      "  Epoch[6/100], Step:  38400, d_loss: 1.499442, g_loss: 1.759292\n",
      "    real_scores: 0.598518, fake_scores: 0.576121, W: -0.022398\n",
      "Finish Epoch [6/100], D Loss: 43.798954, G Loss: 38.000250\n",
      "  Epoch[7/100], Step:  38400, d_loss: 1.448870, g_loss: 1.746302\n",
      "    real_scores: 0.493965, fake_scores: 0.429689, W: -0.064277\n",
      "Finish Epoch [7/100], D Loss: 34.135391, G Loss: 32.912163\n",
      "  Epoch[8/100], Step:  38400, d_loss: 1.430880, g_loss: 1.809016\n",
      "    real_scores: 0.621938, fake_scores: 0.530953, W: -0.090986\n",
      "Finish Epoch [8/100], D Loss: 29.517363, G Loss: 29.342301\n",
      "  Epoch[9/100], Step:  38400, d_loss: 1.399098, g_loss: 1.806169\n",
      "    real_scores: 0.604565, fake_scores: 0.497956, W: -0.106609\n",
      "Finish Epoch [9/100], D Loss: 25.089298, G Loss: 25.951088\n",
      "  Epoch[10/100], Step:  38400, d_loss: 1.329382, g_loss: 1.844234\n",
      "    real_scores: 0.661081, fake_scores: 0.505084, W: -0.155997\n",
      "Finish Epoch [10/100], D Loss: 21.917526, G Loss: 23.700535\n",
      "  Epoch[11/100], Step:  38400, d_loss: 1.331262, g_loss: 1.871079\n",
      "    real_scores: 0.613676, fake_scores: 0.464545, W: -0.149132\n",
      "Finish Epoch [11/100], D Loss: 19.590531, G Loss: 21.541160\n",
      "  Epoch[12/100], Step:  38400, d_loss: 1.366569, g_loss: 2.009226\n",
      "    real_scores: 0.609181, fake_scores: 0.455344, W: -0.153837\n",
      "Finish Epoch [12/100], D Loss: 17.512830, G Loss: 19.838135\n",
      "  Epoch[13/100], Step:  38400, d_loss: 1.397349, g_loss: 1.620754\n",
      "    real_scores: 0.790033, fake_scores: 0.673954, W: -0.116079\n",
      "Finish Epoch [13/100], D Loss: 15.709474, G Loss: 18.278784\n",
      "  Epoch[14/100], Step:  38400, d_loss: 1.294809, g_loss: 2.033484\n",
      "    real_scores: 0.657108, fake_scores: 0.452546, W: -0.204563\n",
      "Finish Epoch [14/100], D Loss: 14.297518, G Loss: 17.146489\n",
      "  Epoch[15/100], Step:  38400, d_loss: 1.282432, g_loss: 1.912262\n",
      "    real_scores: 0.640516, fake_scores: 0.448046, W: -0.192470\n",
      "Finish Epoch [15/100], D Loss: 13.234301, G Loss: 16.024662\n",
      "  Epoch[16/100], Step:  38400, d_loss: 1.317356, g_loss: 1.849268\n",
      "    real_scores: 0.657950, fake_scores: 0.467004, W: -0.190946\n",
      "Finish Epoch [16/100], D Loss: 12.402834, G Loss: 15.007266\n",
      "  Epoch[17/100], Step:  38400, d_loss: 1.301512, g_loss: 1.868719\n",
      "    real_scores: 0.680927, fake_scores: 0.492774, W: -0.188153\n",
      "Finish Epoch [17/100], D Loss: 11.534644, G Loss: 14.116310\n",
      "  Epoch[18/100], Step:  38400, d_loss: 1.314728, g_loss: 1.823716\n",
      "    real_scores: 0.632446, fake_scores: 0.443749, W: -0.188697\n",
      "Finish Epoch [18/100], D Loss: 10.741334, G Loss: 13.414209\n",
      "  Epoch[19/100], Step:  38400, d_loss: 1.608228, g_loss: 1.753787\n",
      "    real_scores: 0.650222, fake_scores: 0.514617, W: -0.135605\n",
      "Finish Epoch [19/100], D Loss: 10.499112, G Loss: 12.675297\n",
      "  Epoch[20/100], Step:  38400, d_loss: 1.336436, g_loss: 1.878127\n",
      "    real_scores: 0.602540, fake_scores: 0.419181, W: -0.183358\n",
      "Finish Epoch [20/100], D Loss: 9.626258, G Loss: 12.026066\n",
      "  Epoch[21/100], Step:  38400, d_loss: 1.470227, g_loss: 2.058464\n",
      "    real_scores: 0.745640, fake_scores: 0.586168, W: -0.159472\n",
      "Finish Epoch [21/100], D Loss: 9.099116, G Loss: 11.568189\n",
      "  Epoch[22/100], Step:  38400, d_loss: 1.376667, g_loss: 1.878096\n",
      "    real_scores: 0.699268, fake_scores: 0.554068, W: -0.145199\n",
      "Finish Epoch [22/100], D Loss: 8.606511, G Loss: 10.977073\n",
      "  Epoch[23/100], Step:  38400, d_loss: 1.307864, g_loss: 1.990796\n",
      "    real_scores: 0.553960, fake_scores: 0.374124, W: -0.179836\n",
      "Finish Epoch [23/100], D Loss: 8.223703, G Loss: 10.509600\n",
      "  Epoch[24/100], Step:  38400, d_loss: 1.408424, g_loss: 1.615201\n",
      "    real_scores: 0.513478, fake_scores: 0.313356, W: -0.200123\n",
      "Finish Epoch [24/100], D Loss: 7.788583, G Loss: 10.064914\n",
      "  Epoch[25/100], Step:  38400, d_loss: 1.256237, g_loss: 1.930845\n",
      "    real_scores: 0.650035, fake_scores: 0.428735, W: -0.221300\n",
      "Finish Epoch [25/100], D Loss: 7.351872, G Loss: 9.704045\n",
      "  Epoch[26/100], Step:  38400, d_loss: 1.314170, g_loss: 1.855435\n",
      "    real_scores: 0.621344, fake_scores: 0.408232, W: -0.213112\n",
      "Finish Epoch [26/100], D Loss: 7.131775, G Loss: 9.289132\n",
      "  Epoch[27/100], Step:  38400, d_loss: 1.267483, g_loss: 1.936585\n",
      "    real_scores: 0.657926, fake_scores: 0.444175, W: -0.213751\n",
      "Finish Epoch [27/100], D Loss: 6.790168, G Loss: 8.936162\n",
      "  Epoch[28/100], Step:  38400, d_loss: 1.228976, g_loss: 1.971866\n",
      "    real_scores: 0.653549, fake_scores: 0.394396, W: -0.259153\n",
      "Finish Epoch [28/100], D Loss: 6.466214, G Loss: 8.687537\n",
      "  Epoch[29/100], Step:  38400, d_loss: 1.246331, g_loss: 1.848294\n",
      "    real_scores: 0.737039, fake_scores: 0.499170, W: -0.237869\n",
      "Finish Epoch [29/100], D Loss: 6.241414, G Loss: 8.420817\n",
      "  Epoch[30/100], Step:  38400, d_loss: 1.227232, g_loss: 1.891073\n",
      "    real_scores: 0.641972, fake_scores: 0.374240, W: -0.267732\n",
      "Finish Epoch [30/100], D Loss: 5.895607, G Loss: 8.204440\n",
      "  Epoch[31/100], Step:  38400, d_loss: 1.260657, g_loss: 1.950707\n",
      "    real_scores: 0.646645, fake_scores: 0.406267, W: -0.240378\n",
      "Finish Epoch [31/100], D Loss: 5.770057, G Loss: 7.942659\n",
      "  Epoch[32/100], Step:  38400, d_loss: 1.240414, g_loss: 1.998519\n",
      "    real_scores: 0.714797, fake_scores: 0.452190, W: -0.262607\n",
      "Finish Epoch [32/100], D Loss: 5.530036, G Loss: 7.752633\n",
      "  Epoch[33/100], Step:  38400, d_loss: 1.160829, g_loss: 1.906182\n",
      "    real_scores: 0.751380, fake_scores: 0.416131, W: -0.335248\n",
      "Finish Epoch [33/100], D Loss: 5.356482, G Loss: 7.569373\n",
      "  Epoch[34/100], Step:  38400, d_loss: 1.635443, g_loss: 2.184860\n",
      "    real_scores: 0.698674, fake_scores: 0.383000, W: -0.315674\n",
      "Finish Epoch [34/100], D Loss: 5.169600, G Loss: 7.381915\n",
      "  Epoch[35/100], Step:  38400, d_loss: 1.697418, g_loss: 2.074450\n",
      "    real_scores: 0.529838, fake_scores: 0.477094, W: -0.052743\n",
      "Finish Epoch [35/100], D Loss: 5.200324, G Loss: 7.147817\n",
      "  Epoch[36/100], Step:  38400, d_loss: 1.055730, g_loss: 1.856195\n",
      "    real_scores: 0.940678, fake_scores: 0.518324, W: -0.422354\n",
      "Finish Epoch [36/100], D Loss: 5.523241, G Loss: 6.702792\n",
      "  Epoch[37/100], Step:  38400, d_loss: 1.462538, g_loss: 2.095145\n",
      "    real_scores: 0.693911, fake_scores: 0.344934, W: -0.348977\n",
      "Finish Epoch [37/100], D Loss: 4.631002, G Loss: 6.845076\n",
      "  Epoch[38/100], Step:  38400, d_loss: 1.375476, g_loss: 1.816769\n",
      "    real_scores: 0.667685, fake_scores: 0.498781, W: -0.168904\n",
      "Finish Epoch [38/100], D Loss: 4.715649, G Loss: 6.588767\n",
      "  Epoch[39/100], Step:  38400, d_loss: 1.144710, g_loss: 2.002244\n",
      "    real_scores: 0.695772, fake_scores: 0.364285, W: -0.331487\n",
      "Finish Epoch [39/100], D Loss: 4.525948, G Loss: 6.392532\n",
      "  Epoch[40/100], Step:  38400, d_loss: 0.949602, g_loss: 2.037453\n",
      "    real_scores: 0.935049, fake_scores: 0.409057, W: -0.525991\n",
      "Finish Epoch [40/100], D Loss: 4.636943, G Loss: 6.168205\n",
      "  Epoch[41/100], Step:  38400, d_loss: 1.346357, g_loss: 1.922213\n",
      "    real_scores: 0.686958, fake_scores: 0.426376, W: -0.260582\n",
      "Finish Epoch [41/100], D Loss: 4.448914, G Loss: 6.106162\n",
      "  Epoch[42/100], Step:  38400, d_loss: 1.292860, g_loss: 2.040849\n",
      "    real_scores: 0.712422, fake_scores: 0.382381, W: -0.330041\n",
      "Finish Epoch [42/100], D Loss: 4.277557, G Loss: 5.912267\n",
      "  Epoch[43/100], Step:  38400, d_loss: 1.142998, g_loss: 2.167919\n",
      "    real_scores: 0.614280, fake_scores: 0.256566, W: -0.357714\n",
      "Finish Epoch [43/100], D Loss: 3.995891, G Loss: 5.847612\n",
      "  Epoch[44/100], Step:  38400, d_loss: 1.271482, g_loss: 1.995652\n",
      "    real_scores: 0.544125, fake_scores: 0.336533, W: -0.207592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Epoch [44/100], D Loss: 4.248200, G Loss: 5.621100\n",
      "  Epoch[45/100], Step:  38400, d_loss: 1.029735, g_loss: 1.944366\n",
      "    real_scores: 0.896288, fake_scores: 0.407986, W: -0.488302\n",
      "Finish Epoch [45/100], D Loss: 3.996873, G Loss: 5.524126\n",
      "  Epoch[46/100], Step:  38400, d_loss: 0.939432, g_loss: 1.883379\n",
      "    real_scores: 0.945814, fake_scores: 0.366671, W: -0.579143\n",
      "Finish Epoch [46/100], D Loss: 4.021225, G Loss: 5.287908\n",
      "  Epoch[47/100], Step:  38400, d_loss: 1.909588, g_loss: 2.103267\n",
      "    real_scores: 0.897424, fake_scores: 0.734365, W: -0.163059\n",
      "Finish Epoch [47/100], D Loss: 3.708167, G Loss: 5.333675\n",
      "  Epoch[48/100], Step:  38400, d_loss: 1.271340, g_loss: 1.867571\n",
      "    real_scores: 0.620768, fake_scores: 0.420656, W: -0.200112\n",
      "Finish Epoch [48/100], D Loss: 3.745491, G Loss: 5.136730\n",
      "  Epoch[49/100], Step:  38400, d_loss: 0.991046, g_loss: 1.972330\n",
      "    real_scores: 0.979881, fake_scores: 0.486206, W: -0.493674\n",
      "Finish Epoch [49/100], D Loss: 3.770500, G Loss: 5.029596\n",
      "  Epoch[50/100], Step:  38400, d_loss: 1.005436, g_loss: 1.947005\n",
      "    real_scores: 0.865827, fake_scores: 0.367696, W: -0.498130\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, lab) in enumerate(dataloader):\n",
    "        \n",
    "        \n",
    "        ########## D ##########\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad_(True)\n",
    "            \n",
    "        label = gen_noise_label(img.size(0))\n",
    "        z = gen_noise(img.size(0), label)\n",
    "#         with torch.no_grad():\n",
    "#             zz = z\n",
    "        fake_img = G(z).detach() ###\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        real_lab = lab.cuda()\n",
    "        real_out, real_label = D(real_img)\n",
    "        real_lab_loss = criterion(real_label, real_lab)\n",
    "        d_loss_real_lab = real_lab_loss.mean()\n",
    "        d_loss_real = real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_img = G(z).detach()\n",
    "        fake_out, fake_label = D(fake_img)\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(D, real_img, fake_img)\n",
    "        \n",
    "        d_loss = d_loss_fake - d_loss_real + gradient_penalty + 1 * d_loss_real_lab\n",
    "        \n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        \n",
    "        #######################\n",
    "        w_dist = d_loss_fake - d_loss_real\n",
    "        \n",
    "        \n",
    "        ########## G ##########\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        \n",
    "        label = gen_noise_label(img.size(0))\n",
    "        z = gen_noise(img.size(0), label)\n",
    "        fake_img = G(z)\n",
    "        fake_out, fake_label = D(fake_img)\n",
    "\n",
    "        gen_label = torch.from_numpy(label).long().to(device)\n",
    "        gen_label_loss = criterion(fake_label, gen_label).mean()\n",
    "        gen_cost = -fake_out.mean()\n",
    "        g_loss = 1 * gen_label_loss + gen_cost\n",
    "\n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "            writer.add_scalar('Wasserstein Distance', w_dist.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('  Epoch[{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}\\n    real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}, W: {:.6f}'.format(epoch+1, num_epochs, \n",
    "                                          (i+1) * BATCH_SIZE, \n",
    "                                          d_loss, g_loss, \n",
    "                                          real_scores.mean(), \n",
    "                                          fake_scores.mean(), w_dist))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    condition_img = G(condition_noise)\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_img.view(-1, 1, 28, 28).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 28, 28).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 28, 28).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d.state_dict(), './ser/condition_wgan_gp_discriminator.pt')\n",
    "torch.save(g.state_dict(), './ser/condition_wgan_gp_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clabel = np.array([4,5,4,4,0])\n",
    "z = gen_noise(5, clabel)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
