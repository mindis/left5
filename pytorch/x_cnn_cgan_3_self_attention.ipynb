{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = (32, 4, 4) # 64 * 64\n",
    "\n",
    "img_shape = (1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('~/data/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        m_batchsize, C, width ,height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1) # B (N) C\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width * height) # B C (N)\n",
    "        energy = torch.bmm(proj_query, proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # B (N) (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width * height) # B C N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1)) # B C N\n",
    "        out = out.view(m_batchsize, C, width, height) # B C W H\n",
    "        \n",
    "        out = self.gamma * out + x\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, 10))\n",
    "    prefix[np.arange(batch_size), label.cpu().numpy()] = 1\n",
    "    z = np.random.normal(0, 1, (batch_size, z_dimension))\n",
    "    prefix = prefix / np.linalg.norm(prefix)\n",
    "    z[:, :10] = prefix\n",
    "    return torch.from_numpy(z).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_label_one_hot(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, 10))\n",
    "    prefix[np.arange(batch_size), label.cpu().numpy()] = 1\n",
    "    return torch.from_numpy(prefix).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "#         self.label_embedding = nn.Linear(10, np.prod(img_shape))\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(1, 32, 3, padding=1, stride=2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 16 16 16\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(32, 64, 3, padding=1, stride=2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 32 8 8\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(64, 128, 3, padding=1, stride=2)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 64 4 4\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(128, 256, 3, padding=1, stride=2)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.AvgPool2d(2, 2), \n",
    "        ) # b 128 2 2\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 2 * 2, 1024),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "#             nn.Tanh(),\n",
    "        ) # b 1\n",
    "        \n",
    "        self.label = nn.Sequential(\n",
    "            nn.Linear(256 * 2 * 2, 10),\n",
    "            nn.Sigmoid(),\n",
    "#             nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.att1 = SelfAttention(128)\n",
    "        self.att2 = SelfAttention(256)\n",
    "\n",
    "    def forward(self, imgs): # b 1 32 32\n",
    "        \n",
    "#         _imgs = torch.cat((imgs, self.label_embedding(labels.reshape([imgs.size(0), -1])).reshape(imgs.size(0), *img_shape)), 1)\n",
    "\n",
    "        outs = self.conv1(imgs)\n",
    "        outs = self.conv2(outs)\n",
    "        outs = self.conv3(outs)\n",
    "        outs, p1 = self.att1(outs)\n",
    "        outs = self.conv4(outs)\n",
    "#         outs, p1 = self.att2(outs)\n",
    "        outs = outs.view(imgs.size(0), -1)\n",
    "        img = self.fc(outs)\n",
    "        lab = self.label(outs)\n",
    "        \n",
    "        return img, lab # b 1 1 1, b 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, num_feature):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "#         self.label_emb = nn.Linear(10, 10)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(inp_dim, np.prod(num_feature)),\n",
    "#             nn.Sigmoid(),\n",
    "        ) # b *num_feature  b 32 4 4\n",
    "        \n",
    "        self.upsample1 = nn.Sequential(\n",
    "#             nn.BatchNorm2d(128),\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(32, 64, 4, 2, 1)),\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(32, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(True),\n",
    "        ) # b 16 8 8\n",
    "        \n",
    "        self.upsample2 = nn.Sequential(\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(64, 32, 4, 2, 1)),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(True),\n",
    "        ) # b 8 16 16\n",
    "        \n",
    "        self.upsample3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(32, 16, 4, 2, 1)),\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(8, 4, 3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "#             nn.ReLU(True),\n",
    "        ) # b 4 32 32\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "#             nn.functional.interpolate(scale_factor=2),\n",
    "            nn.utils.spectral_norm(nn.Conv2d(16, 1, 3, padding=1, stride=1)),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 32 32\n",
    "        \n",
    "        self.att1 = SelfAttention(32)\n",
    "        self.att2 = SelfAttention(16)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, noise):\n",
    "        \n",
    "#         gen_input = torch.cat((labels.reshape(noise.size(0), -1), noise), -1)\n",
    "#         gen_input = torch.cat((self.label_emb(labels.reshape([noise.size(0), -1])), noise), -1)\n",
    "        \n",
    "        outs = self.fc(noise)\n",
    "        outs = outs.view(noise.size(0), *num_feature)\n",
    "        outs = self.upsample1(outs)\n",
    "        outs = self.upsample2(outs)\n",
    "        outs, p1 = self.att1(outs)\n",
    "        outs = self.upsample3(outs)\n",
    "#         outs, p1 = self.att2(outs)\n",
    "        \n",
    "        outs = self.conv(outs)\n",
    "        \n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(z_dimension, num_feature).to(device)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "adversarial_loss = nn.MSELoss()\n",
    "auxiliary_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "D_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "G_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = torch.from_numpy(np.arange(10)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/cnn_cgan_self_attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"save_images/cnn_cgan_self_attention\"\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a47422ea4d342d2864a0008f4794ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 8.811182, g_loss: 3.339332, real_scores: 0.805647, fake_scores: 0.000263\n",
      "Finish Epoch [1/100], D Loss: 1243.710517, G Loss: 375.096904\n",
      "Epoch [2/100], Step:  38400, d_loss: 9.793233, g_loss: 3.295992, real_scores: 0.913027, fake_scores: 0.036068\n",
      "Finish Epoch [2/100], D Loss: 605.359779, G Loss: 196.550961\n",
      "Epoch [3/100], Step:  38400, d_loss: 8.552980, g_loss: 3.401115, real_scores: 0.895378, fake_scores: 0.000000\n",
      "Finish Epoch [3/100], D Loss: 398.537447, G Loss: 139.032581\n",
      "Epoch [4/100], Step:  38400, d_loss: 9.737263, g_loss: 3.311111, real_scores: 0.906962, fake_scores: 0.000869\n",
      "Finish Epoch [4/100], D Loss: 296.434372, G Loss: 107.182145\n",
      "Epoch [5/100], Step:  38400, d_loss: 7.966341, g_loss: 3.383729, real_scores: 0.872667, fake_scores: 0.000191\n",
      "Finish Epoch [5/100], D Loss: 235.936297, G Loss: 86.890012\n",
      "Epoch [6/100], Step:  38400, d_loss: 8.213473, g_loss: 3.420268, real_scores: 0.862048, fake_scores: 0.006574\n",
      "Finish Epoch [6/100], D Loss: 196.000653, G Loss: 72.681293\n",
      "Epoch [7/100], Step:  38400, d_loss: 8.933863, g_loss: 3.411634, real_scores: 0.924352, fake_scores: 0.000000\n",
      "Finish Epoch [7/100], D Loss: 167.888151, G Loss: 62.297408\n",
      "Epoch [8/100], Step:  38400, d_loss: 10.085583, g_loss: 3.403843, real_scores: 0.890876, fake_scores: 0.000000\n",
      "Finish Epoch [8/100], D Loss: 146.945023, G Loss: 54.459906\n",
      "Epoch [9/100], Step:  38400, d_loss: 10.012547, g_loss: 3.302066, real_scores: 0.886051, fake_scores: 0.000000\n",
      "Finish Epoch [9/100], D Loss: 130.380580, G Loss: 48.543296\n",
      "Epoch [10/100], Step:  38400, d_loss: 8.920440, g_loss: 3.497221, real_scores: 0.898438, fake_scores: 0.000000\n",
      "Finish Epoch [10/100], D Loss: 117.368674, G Loss: 43.657902\n",
      "Epoch [11/100], Step:  38400, d_loss: 8.349937, g_loss: 3.372587, real_scores: 0.914067, fake_scores: 0.000000\n",
      "Finish Epoch [11/100], D Loss: 106.579786, G Loss: 39.726021\n",
      "Epoch [12/100], Step:  38400, d_loss: 8.263338, g_loss: 3.396216, real_scores: 0.859374, fake_scores: 0.000000\n",
      "Finish Epoch [12/100], D Loss: 97.684281, G Loss: 36.433241\n",
      "Epoch [13/100], Step:  38400, d_loss: 9.356039, g_loss: 3.388224, real_scores: 0.953121, fake_scores: 0.000000\n",
      "Finish Epoch [13/100], D Loss: 90.195100, G Loss: 33.658347\n",
      "Epoch [14/100], Step:  38400, d_loss: 9.577119, g_loss: 3.435863, real_scores: 0.875004, fake_scores: 0.000019\n",
      "Finish Epoch [14/100], D Loss: 83.634462, G Loss: 31.234066\n",
      "Epoch [15/100], Step:  38400, d_loss: 9.048743, g_loss: 3.403846, real_scores: 0.882942, fake_scores: 0.000000\n",
      "Finish Epoch [15/100], D Loss: 78.021001, G Loss: 29.155404\n",
      "Epoch [16/100], Step:  38400, d_loss: 9.194338, g_loss: 3.474264, real_scores: 0.927756, fake_scores: 0.000000\n",
      "Finish Epoch [16/100], D Loss: 73.135901, G Loss: 27.346668\n",
      "Epoch [17/100], Step:  38400, d_loss: 9.246389, g_loss: 3.421437, real_scores: 0.921888, fake_scores: 0.000150\n",
      "Finish Epoch [17/100], D Loss: 68.907865, G Loss: 25.697380\n",
      "Epoch [18/100], Step:  38400, d_loss: 8.438050, g_loss: 3.474097, real_scores: 0.867188, fake_scores: 0.000000\n",
      "Finish Epoch [18/100], D Loss: 65.002021, G Loss: 24.345508\n",
      "Epoch [19/100], Step:  38400, d_loss: 10.857254, g_loss: 3.474159, real_scores: 0.890625, fake_scores: 0.000000\n",
      "Finish Epoch [19/100], D Loss: 61.565975, G Loss: 23.070011\n",
      "Epoch [20/100], Step:  38400, d_loss: 9.754963, g_loss: 3.410231, real_scores: 0.898438, fake_scores: 0.000000\n",
      "Finish Epoch [20/100], D Loss: 58.503644, G Loss: 21.875207\n",
      "Epoch [21/100], Step:  38400, d_loss: 8.730274, g_loss: 3.442909, real_scores: 0.890625, fake_scores: 0.000000\n",
      "Finish Epoch [21/100], D Loss: 55.691238, G Loss: 20.854284\n",
      "Epoch [22/100], Step:  38400, d_loss: 8.622755, g_loss: 3.457548, real_scores: 0.882813, fake_scores: 0.000000\n",
      "Finish Epoch [22/100], D Loss: 53.102148, G Loss: 19.916472\n",
      "Epoch [23/100], Step:  38400, d_loss: 9.748621, g_loss: 3.411591, real_scores: 0.906250, fake_scores: 0.000000\n",
      "Finish Epoch [23/100], D Loss: 50.789518, G Loss: 19.058207\n",
      "Epoch [24/100], Step:  38400, d_loss: 8.575640, g_loss: 3.435063, real_scores: 0.906250, fake_scores: 0.000000\n",
      "Finish Epoch [24/100], D Loss: 48.664366, G Loss: 18.264180\n",
      "Epoch [25/100], Step:  38400, d_loss: 10.811705, g_loss: 3.505410, real_scores: 0.898438, fake_scores: 0.000000\n",
      "Finish Epoch [25/100], D Loss: 46.707003, G Loss: 17.544226\n",
      "Epoch [26/100], Step:  38400, d_loss: 9.082111, g_loss: 3.450713, real_scores: 0.867188, fake_scores: 0.000000\n",
      "Finish Epoch [26/100], D Loss: 44.906579, G Loss: 16.870451\n",
      "Epoch [27/100], Step:  38400, d_loss: 8.405341, g_loss: 3.450798, real_scores: 0.915843, fake_scores: 0.000000\n",
      "Finish Epoch [27/100], D Loss: 43.258556, G Loss: 16.230982\n",
      "Epoch [28/100], Step:  38400, d_loss: 9.263996, g_loss: 3.481972, real_scores: 0.883516, fake_scores: 0.000000\n",
      "Finish Epoch [28/100], D Loss: 41.702976, G Loss: 15.658317\n",
      "Epoch [29/100], Step:  38400, d_loss: 8.817907, g_loss: 3.450692, real_scores: 0.867188, fake_scores: 0.000000\n",
      "Finish Epoch [29/100], D Loss: 40.269044, G Loss: 15.113388\n",
      "Epoch [30/100], Step:  38400, d_loss: 8.815906, g_loss: 3.349154, real_scores: 0.867188, fake_scores: 0.000000\n",
      "Finish Epoch [30/100], D Loss: 38.926026, G Loss: 14.609641\n",
      "Epoch [31/100], Step:  38400, d_loss: 8.496296, g_loss: 3.434999, real_scores: 0.914061, fake_scores: 0.000000\n",
      "Finish Epoch [31/100], D Loss: 37.675200, G Loss: 14.133598\n",
      "Epoch [32/100], Step:  38400, d_loss: 9.383017, g_loss: 3.427284, real_scores: 0.914062, fake_scores: 0.000000\n",
      "Finish Epoch [32/100], D Loss: 36.490296, G Loss: 13.696261\n",
      "Epoch [33/100], Step:  38400, d_loss: 8.351099, g_loss: 3.403847, real_scores: 0.875000, fake_scores: 0.000000\n",
      "Finish Epoch [33/100], D Loss: 35.394962, G Loss: 13.270843\n",
      "Epoch [34/100], Step:  38400, d_loss: 9.350429, g_loss: 3.528799, real_scores: 0.914062, fake_scores: 0.000000\n",
      "Finish Epoch [34/100], D Loss: 34.349994, G Loss: 12.883898\n",
      "Epoch [35/100], Step:  38400, d_loss: 7.789561, g_loss: 3.466317, real_scores: 0.875000, fake_scores: 0.000000\n",
      "Finish Epoch [35/100], D Loss: 33.373063, G Loss: 12.509897\n",
      "Epoch [36/100], Step:  38400, d_loss: 8.108389, g_loss: 3.427284, real_scores: 0.867188, fake_scores: 0.000000\n",
      "Finish Epoch [36/100], D Loss: 32.439016, G Loss: 12.169800\n",
      "Epoch [37/100], Step:  38400, d_loss: 8.802862, g_loss: 3.435097, real_scores: 0.890625, fake_scores: 0.000000\n",
      "Finish Epoch [37/100], D Loss: 31.559624, G Loss: 11.842603\n",
      "Epoch [38/100], Step:  38400, d_loss: 8.908854, g_loss: 3.403847, real_scores: 0.921875, fake_scores: 0.000000\n",
      "Finish Epoch [38/100], D Loss: 30.728836, G Loss: 11.531331\n",
      "Epoch [39/100], Step:  38400, d_loss: 9.585330, g_loss: 3.388055, real_scores: 0.945312, fake_scores: 0.000000\n",
      "Finish Epoch [39/100], D Loss: 29.936705, G Loss: 11.240071\n",
      "Epoch [40/100], Step:  38400, d_loss: 9.410365, g_loss: 3.396036, real_scores: 0.906250, fake_scores: 0.000000\n",
      "Finish Epoch [40/100], D Loss: 29.190506, G Loss: 10.955388\n",
      "Epoch [41/100], Step:  38400, d_loss: 10.511010, g_loss: 3.435097, real_scores: 0.929688, fake_scores: 0.000000\n",
      "Finish Epoch [41/100], D Loss: 28.472266, G Loss: 10.694257\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        real_imgs = imgs.cuda()\n",
    "        real_labels = labels.cuda()\n",
    "        \n",
    "#         real = torch.ones(imgs.size(0), 1).cuda()\n",
    "#         fake = torch.zeros(imgs.size(0), 1).cuda()\n",
    "        real = torch.ones(imgs.size(0), 1).cuda()\n",
    "        fake = torch.zeros(imgs.size(0), 1).cuda()\n",
    "        torch.random.rand\n",
    "        \n",
    "        fake_labels = torch.from_numpy(np.random.randint(0, 10, imgs.size(0))).cuda()\n",
    "        z = gen_noise(imgs.size(0), fake_labels)\n",
    "        \n",
    "        ########## G ##########\n",
    "        fake_imgs = G(z)\n",
    "        fake_out, fake_out_labels = D(fake_imgs)\n",
    "        g_loss = adversarial_loss(fake_out, real) + auxiliary_loss(fake_out_labels, fake_labels)\n",
    "        \n",
    "        D_optimezer.zero_grad()\n",
    "        G_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        G_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_out, real_out_label = D(real_imgs)\n",
    "        d_loss_real = adversarial_loss(real_out.view(imgs.size(0)), real_labels.float())\n",
    "        d_loss_real_label = auxiliary_loss(real_out_label, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_out, fake_out_labels = D(fake_imgs.detach())\n",
    "        d_loss_fake = adversarial_loss(fake_out, fake)\n",
    "        d_loss_fake_label = auxiliary_loss(fake_out_labels, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2 + d_loss_real_label - d_loss_fake_label\n",
    "        D_optimezer.zero_grad()\n",
    "        G_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        D_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * imgs.size(0)\n",
    "        g_loss_total += g_loss.item() * imgs.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    condition_noise = gen_noise(condition.shape[0], condition)\n",
    "    condition_images = G(condition_noise)\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_imgs.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_images.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    fake_images = fake_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    save_image(condition_images, os.path.join(img_path, 'condition_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), './ser/cgan_discriminator_3.pt')\n",
    "torch.save(G.state_dict(), './ser/cgan_generator_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.load_state_dict(torch.load('./ser/cgan_discriminator_3.pt'))\n",
    "G.load_state_dict(torch.load('./ser/cgan_generator_3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = torch.from_numpy(np.arange(10)).to(device)\n",
    "words = gen_label_one_hot(words.shape[0], words)\n",
    "z = torch.randn(words.size(0), z_dimension).to(device)\n",
    "images = G(z, words)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv36",
   "language": "python",
   "name": "venv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
