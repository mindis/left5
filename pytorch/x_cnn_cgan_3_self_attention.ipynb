{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "z_dimension = 100\n",
    "num_feature = (32, 4, 4) # 64 * 64\n",
    "\n",
    "img_shape = (1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('~/data/mnist', transform=img_transform) #, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        m_batchsize, C, width ,height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width * height).permute(0, 2, 1) # B (N) C\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width * height) # B C (N)\n",
    "        energy = torch.bmm(proj_query, proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # B (N) (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width * height) # B C N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1)) # B C N\n",
    "        out = out.view(m_batchsize, C, width, height) # B C W H\n",
    "        \n",
    "        out = self.gamma * out + x\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, 10))\n",
    "    prefix[np.arange(batch_size), label.cpu().numpy()] = 1\n",
    "    z = np.random.normal(0, .3, (batch_size, z_dimension))\n",
    "#     prefix = prefix / np.linalg.norm(prefix)\n",
    "    z[:, :10] = prefix\n",
    "    return torch.from_numpy(z).float().reshape(batch_size, z_dimension, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_label_one_hot(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, 10))\n",
    "    prefix[np.arange(batch_size), label.cpu().numpy()] = 1\n",
    "    return torch.from_numpy(prefix).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "        \n",
    "# #         self.label_embedding = nn.Linear(10, np.prod(img_shape))\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(1, 32, 3, padding=1, stride=2)),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.AvgPool2d(2, 2), \n",
    "#         ) # b 16 16 16\n",
    "        \n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(32, 64, 3, padding=1, stride=2)),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.AvgPool2d(2, 2), \n",
    "#         ) # b 32 8 8\n",
    "        \n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(64, 128, 3, padding=1, stride=2)),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.AvgPool2d(2, 2), \n",
    "#         ) # b 64 4 4\n",
    "        \n",
    "#         self.conv4 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(128, 256, 3, padding=1, stride=2)),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.AvgPool2d(2, 2), \n",
    "#         ) # b 128 2 2\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(256 * 2 * 2, 1024),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.Linear(1024, 1),\n",
    "#             nn.Sigmoid(),\n",
    "# #             nn.Tanh(),\n",
    "#         ) # b 1\n",
    "        \n",
    "#         self.label = nn.Sequential(\n",
    "#             nn.Linear(256 * 2 * 2, 10),\n",
    "#             nn.Sigmoid(),\n",
    "# #             nn.Tanh(),\n",
    "#         )\n",
    "        \n",
    "#         self.att1 = SelfAttention(128)\n",
    "#         self.att2 = SelfAttention(256)\n",
    "\n",
    "#     def forward(self, imgs): # b 1 32 32\n",
    "        \n",
    "# #         _imgs = torch.cat((imgs, self.label_embedding(labels.reshape([imgs.size(0), -1])).reshape(imgs.size(0), *img_shape)), 1)\n",
    "\n",
    "#         outs = self.conv1(imgs)\n",
    "#         outs = self.conv2(outs)\n",
    "#         outs = self.conv3(outs)\n",
    "#         outs, p1 = self.att1(outs)\n",
    "#         outs = self.conv4(outs)\n",
    "# #         outs, p1 = self.att2(outs)\n",
    "#         outs = outs.view(imgs.size(0), -1)\n",
    "#         img = self.fc(outs)\n",
    "#         lab = self.label(outs)\n",
    "        \n",
    "#         return img, lab # b 1 1 1, b 10\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Discriminator, self).__init__() # b d 32 32\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(1, d, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # d 16 16\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d, d*2, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*2),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # d*2 8 8\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d*2, d*4, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*4),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # d*4 4 4\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(1, d, 4, 2, 1) # d 16 16\n",
    "#         self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1) # d*2 8 8\n",
    "#         self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "#         self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1) # d*4 4 4\n",
    "#         self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(d*4, 1, 4, 2, 0),\n",
    "            nn.Sigmoid(),\n",
    "        ) # 1 1 1\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d * 4 * 4 * 4, 10),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 10\n",
    "        \n",
    "        self.att1 = SelfAttention(d)\n",
    "#         self.att2 = SelfAttention(d*2)\n",
    "#         self.att3 = SelfAttention(d*4)\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 32 32\n",
    "        outs = self.conv1(x)\n",
    "        outs, p1 = self.att1(outs)\n",
    "        outs = self.conv2(outs)\n",
    "#         outs, p1 = self.att2(outs)\n",
    "        outs = self.conv3(outs)\n",
    "#         outs, p1 = self.att3(outs)\n",
    "\n",
    "        img = torch.sigmoid(self.output(outs)) # F.sigmoid\n",
    "        con = self.fc(outs.view(x.size(0), -1))\n",
    "        \n",
    "        return img, con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, inp_dim, num_feature):\n",
    "#         super(Generator, self).__init__()\n",
    "\n",
    "# #         self.label_emb = nn.Linear(10, 10)\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(inp_dim, np.prod(num_feature)),\n",
    "# #             nn.Sigmoid(),\n",
    "#         ) # b *num_feature  b 32 4 4\n",
    "        \n",
    "#         self.upsample1 = nn.Sequential(\n",
    "# #             nn.BatchNorm2d(128),\n",
    "#             nn.utils.spectral_norm(nn.ConvTranspose2d(32, 64, 4, 2, 1)),\n",
    "# #             nn.functional.interpolate(scale_factor=2),\n",
    "# #             nn.Upsample(scale_factor=2),\n",
    "# #             nn.Conv2d(32, 16, 3, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.ReLU(True),\n",
    "#         ) # b 16 8 8\n",
    "        \n",
    "#         self.upsample2 = nn.Sequential(\n",
    "# #             nn.functional.interpolate(scale_factor=2),\n",
    "#             nn.utils.spectral_norm(nn.ConvTranspose2d(64, 32, 4, 2, 1)),\n",
    "# #             nn.Upsample(scale_factor=2),\n",
    "# #             nn.Conv2d(16, 8, 3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.ReLU(True),\n",
    "#         ) # b 8 16 16\n",
    "        \n",
    "#         self.upsample3 = nn.Sequential(\n",
    "#             nn.utils.spectral_norm(nn.ConvTranspose2d(32, 16, 4, 2, 1)),\n",
    "# #             nn.functional.interpolate(scale_factor=2),\n",
    "# #             nn.Upsample(scale_factor=2),\n",
    "# #             nn.Conv2d(8, 4, 3, padding=1, stride=1),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "# #             nn.ReLU(True),\n",
    "#         ) # b 4 32 32\n",
    "        \n",
    "#         self.conv = nn.Sequential(\n",
    "# #             nn.functional.interpolate(scale_factor=2),\n",
    "#             nn.utils.spectral_norm(nn.Conv2d(16, 1, 3, padding=1, stride=1)),\n",
    "#             nn.Tanh(),\n",
    "#         ) # b 1 32 32\n",
    "        \n",
    "#         self.att1 = SelfAttention(32)\n",
    "#         self.att2 = SelfAttention(16)\n",
    "        \n",
    "        \n",
    "\n",
    "#     def forward(self, noise):\n",
    "        \n",
    "# #         gen_input = torch.cat((labels.reshape(noise.size(0), -1), noise), -1)\n",
    "# #         gen_input = torch.cat((self.label_emb(labels.reshape([noise.size(0), -1])), noise), -1)\n",
    "        \n",
    "#         outs = self.fc(noise)\n",
    "#         outs = outs.view(noise.size(0), *num_feature)\n",
    "#         outs = self.upsample1(outs)\n",
    "#         outs = self.upsample2(outs)\n",
    "#         outs, p1 = self.att1(outs)\n",
    "#         outs = self.upsample3(outs)\n",
    "# #         outs, p1 = self.att2(outs)\n",
    "        \n",
    "#         outs = self.conv(outs)\n",
    "        \n",
    "#         return outs\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(z_dimension, d*4, 4, 2, 0)),\n",
    "            nn.BatchNorm2d(d*4),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*4 4 4\n",
    "        \n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*2),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*2 8 8\n",
    "        \n",
    "        self.deconv3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.ConvTranspose2d(d*2, d, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d 16 16\n",
    "        \n",
    "#         self.deconv1 = nn.ConvTranspose2d(z_dimension, d*4, 4, 2, 0) # b d*8 2 2\n",
    "#         self.deconv1_bn = nn.BatchNorm2d(d*4)\n",
    "#         self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1) # b d*2 4 4\n",
    "#         self.deconv2_bn = nn.BatchNorm2d(d*2)\n",
    "#         self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1) # b d 8 8\n",
    "#         self.deconv3_bn = nn.BatchNorm2d(d)\n",
    "        \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d, 1, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        ) # b 1 32 32\n",
    "        \n",
    "#         self.att1 = SelfAttention(d*4)\n",
    "#         self.att2 = SelfAttention(d*2)\n",
    "        self.att3 = SelfAttention(d)\n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 100 1 1\n",
    "        outs = self.deconv1(x)\n",
    "#         outs, p1 = self.att1(outs)\n",
    "        outs = self.deconv2(outs)\n",
    "#         outs, p1 = self.att2(outs)\n",
    "        outs = self.deconv3(outs)\n",
    "        outs, p1 = self.att3(outs)\n",
    "        \n",
    "        outs = self.output(outs)\n",
    "\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(128).to(device)\n",
    "G = Generator(128).to(device)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "adversarial_loss = nn.MSELoss()\n",
    "auxiliary_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "D_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "G_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = torch.from_numpy(np.arange(10)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join('./log/cnn_cgan_self_attention', str(now)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(\"save_images/cnn_cgan_self_attention\", str(now))\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1df86607a841f78eab01a99a4b7ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step:  38400, d_loss: 9.755344, g_loss: 2.656614, real_scores: 0.693999, fake_scores: 0.668387\n",
      "Finish Epoch [1/100], D Loss: 1347.842622, G Loss: 327.724140\n",
      "Epoch [2/100], Step:  38400, d_loss: 9.368597, g_loss: 2.288966, real_scores: 0.708189, fake_scores: 0.704836\n",
      "Finish Epoch [2/100], D Loss: 685.852835, G Loss: 159.086436\n",
      "Epoch [3/100], Step:  38400, d_loss: 11.519994, g_loss: 2.744350, real_scores: 0.711118, fake_scores: 0.621982\n",
      "Finish Epoch [3/100], D Loss: 454.123653, G Loss: 112.979136\n",
      "Epoch [4/100], Step:  38400, d_loss: 8.742670, g_loss: 2.886662, real_scores: 0.698946, fake_scores: 0.505592\n",
      "Finish Epoch [4/100], D Loss: 334.329773, G Loss: 86.073629\n",
      "Epoch [5/100], Step:  38400, d_loss: 8.551708, g_loss: 2.673651, real_scores: 0.705791, fake_scores: 0.500013\n",
      "Finish Epoch [5/100], D Loss: 265.838673, G Loss: 66.827299\n",
      "Epoch [6/100], Step:  38400, d_loss: 10.213568, g_loss: 2.725263, real_scores: 0.713735, fake_scores: 0.504141\n",
      "Finish Epoch [6/100], D Loss: 220.057017, G Loss: 56.626906\n",
      "Epoch [7/100], Step:  38400, d_loss: 9.780563, g_loss: 2.601866, real_scores: 0.716452, fake_scores: 0.500010\n",
      "Finish Epoch [7/100], D Loss: 188.254767, G Loss: 48.724729\n",
      "Epoch [8/100], Step:  38400, d_loss: 9.556519, g_loss: 2.731508, real_scores: 0.711628, fake_scores: 0.500181\n",
      "Finish Epoch [8/100], D Loss: 164.590399, G Loss: 42.683284\n",
      "Epoch [9/100], Step:  38400, d_loss: 10.915808, g_loss: 2.692907, real_scores: 0.712703, fake_scores: 0.500001\n",
      "Finish Epoch [9/100], D Loss: 146.139498, G Loss: 37.977072\n",
      "Epoch [10/100], Step:  38400, d_loss: 9.439528, g_loss: 2.606964, real_scores: 0.702112, fake_scores: 0.500001\n",
      "Finish Epoch [10/100], D Loss: 131.586367, G Loss: 34.159264\n",
      "Epoch [11/100], Step:  38400, d_loss: 10.404173, g_loss: 2.620729, real_scores: 0.710233, fake_scores: 0.530187\n",
      "Finish Epoch [11/100], D Loss: 119.455022, G Loss: 31.094299\n",
      "Epoch [12/100], Step:  38400, d_loss: 9.299297, g_loss: 2.716288, real_scores: 0.716629, fake_scores: 0.500024\n",
      "Finish Epoch [12/100], D Loss: 109.521954, G Loss: 28.516747\n",
      "Epoch [13/100], Step:  38400, d_loss: 9.671059, g_loss: 2.646026, real_scores: 0.709395, fake_scores: 0.500003\n",
      "Finish Epoch [13/100], D Loss: 101.066837, G Loss: 26.282782\n",
      "Epoch [14/100], Step:  38400, d_loss: 9.044849, g_loss: 2.630315, real_scores: 0.702419, fake_scores: 0.500022\n",
      "Finish Epoch [14/100], D Loss: 93.821429, G Loss: 24.418255\n",
      "Epoch [15/100], Step:  38400, d_loss: 9.926474, g_loss: 2.671884, real_scores: 0.709669, fake_scores: 0.504029\n",
      "Finish Epoch [15/100], D Loss: 87.566831, G Loss: 22.802786\n",
      "Epoch [16/100], Step:  38400, d_loss: 9.333477, g_loss: 2.614784, real_scores: 0.709308, fake_scores: 0.500000\n",
      "Finish Epoch [16/100], D Loss: 82.062408, G Loss: 21.383922\n",
      "Epoch [17/100], Step:  38400, d_loss: 11.587868, g_loss: 2.724157, real_scores: 0.709396, fake_scores: 0.500000\n",
      "Finish Epoch [17/100], D Loss: 77.225177, G Loss: 20.132392\n",
      "Epoch [18/100], Step:  38400, d_loss: 11.690104, g_loss: 2.669469, real_scores: 0.711302, fake_scores: 0.500000\n",
      "Finish Epoch [18/100], D Loss: 72.936475, G Loss: 19.005968\n",
      "Epoch [19/100], Step:  38400, d_loss: 10.795134, g_loss: 2.677281, real_scores: 0.712943, fake_scores: 0.500001\n",
      "Finish Epoch [19/100], D Loss: 69.090386, G Loss: 18.009440\n",
      "Epoch [20/100], Step:  38400, d_loss: 8.141232, g_loss: 2.685097, real_scores: 0.698127, fake_scores: 0.500000\n",
      "Finish Epoch [20/100], D Loss: 65.633436, G Loss: 17.099647\n",
      "Epoch [21/100], Step:  38400, d_loss: 11.841311, g_loss: 2.685097, real_scores: 0.707595, fake_scores: 0.500000\n",
      "Finish Epoch [21/100], D Loss: 62.511579, G Loss: 16.286854\n",
      "Epoch [22/100], Step:  38400, d_loss: 10.141018, g_loss: 2.716243, real_scores: 0.705780, fake_scores: 0.500049\n",
      "Finish Epoch [22/100], D Loss: 59.646821, G Loss: 15.559790\n",
      "Epoch [23/100], Step:  38400, d_loss: 11.583847, g_loss: 2.646030, real_scores: 0.713002, fake_scores: 0.500000\n",
      "Finish Epoch [23/100], D Loss: 57.075512, G Loss: 14.865062\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-33090c5a796c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0md_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mg_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        real_imgs = imgs.cuda()\n",
    "        real_labels = labels.cuda()\n",
    "        \n",
    "        real = torch.ones(imgs.size(0), 1).cuda()\n",
    "        fake = torch.zeros(imgs.size(0), 1).cuda()\n",
    "        \n",
    "        fake_labels = torch.from_numpy(np.random.randint(0, 10, imgs.size(0))).cuda()\n",
    "        z = gen_noise(imgs.size(0), fake_labels)\n",
    "        \n",
    "        ########## G ##########\n",
    "        fake_imgs = G(z)\n",
    "        fake_out, fake_out_labels = D(fake_imgs)\n",
    "        \n",
    "        g_loss = adversarial_loss(fake_out.view(imgs.size(0), 1), real) + auxiliary_loss(fake_out_labels, fake_labels)\n",
    "        \n",
    "        G_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        G_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        ########## D ##########\n",
    "        real_out, real_out_label = D(real_imgs)\n",
    "        d_loss_real = adversarial_loss(real_out.view(imgs.size(0), 1), real_labels.float().view(imgs.size(0), 1))\n",
    "        d_loss_real_label = auxiliary_loss(real_out_label, real_labels)\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_out, fake_out_labels = D(fake_imgs.detach())\n",
    "        d_loss_fake = adversarial_loss(fake_out.view(imgs.size(0), 1), fake)\n",
    "        d_loss_fake_label = auxiliary_loss(fake_out_labels, fake_labels)\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2 + d_loss_real_label - d_loss_fake_label\n",
    "        D_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        D_optimezer.step()\n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * imgs.size(0)\n",
    "        g_loss_total += g_loss.item() * imgs.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean()))\n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], Mean D Loss: {:.6f}, Mean G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    condition_noise = gen_noise(condition.shape[0], condition)\n",
    "    condition_images = G(condition_noise)\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_imgs.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_images.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    \n",
    "    fake_images = fake_imgs.view(-1, 1, 32, 32).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    save_image(condition_images, os.path.join(img_path, 'condition_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), './ser/cnn_cgan_3_self_attention_discriminator.pt')\n",
    "torch.save(G.state_dict(), './ser/cnn_cgan_3_self_attention_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.load_state_dict(torch.load('./ser/cnn_cgan_3_self_attention_discriminator.pt'))\n",
    "G.load_state_dict(torch.load('./ser/cnn_cgan_3_self_attention_generator.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 6, 9, 4, 0, 1, 1, 7, 2, 3, 2, 9, 2, 8, 4], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_labels = torch.from_numpy(np.random.randint(0, 10, 16)).cuda()\n",
    "z = gen_noise(16, fake_labels)\n",
    "print(fake_labels)\n",
    "images = G(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv36",
   "language": "python",
   "name": "venv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
