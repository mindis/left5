{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 1000\n",
    "\n",
    "z_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0] #, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = 64\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(wh),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('~/data/anime-faces', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module): # b 3 64 64\n",
    "    def __init__(self, d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(3, d, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b d 32 32\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d, d*2, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*2),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b d*2 16 16\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d*2, d*4, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*4),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b d*4 8 8\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d*4, d*8, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*8),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b d*8 4 4\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d*8, d*16, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(d*16),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b d*16 2 2\n",
    "        \n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d*16, d*32, 4, 2, 2)),\n",
    "            nn.BatchNorm2d(d*32),\n",
    "            nn.LeakyReLU(.2, True),\n",
    "        ) # b d*32 2 2\n",
    "        \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(d*32, 1, 4, 2, 1)),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 1 1 1\n",
    "        \n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "    \n",
    "    def forward(self, x): # b 3 w h\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        \n",
    "        return self.output(out).reshape(x.size(0), -1)\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, d=128):\n",
    "#         super(Discriminator, self).__init__() # b d 64 64\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, d, 4, 2, 2),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.BatchNorm2d(d),\n",
    "#         ) # d 32 32\n",
    "        \n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(d, d*2, 4, 2, 2),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.BatchNorm2d(d*2),\n",
    "#         ) # d 16 16\n",
    "        \n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(d*2, d*4, 4, 2, 1),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.BatchNorm2d(d*4),\n",
    "#         ) # d*4 8 8\n",
    "        \n",
    "#         self.conv4 = nn.Sequential(\n",
    "#             nn.Conv2d(d*4, d*8, 4, 2, 1),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.BatchNorm2d(d*8),\n",
    "#         ) # d*4 4 4\n",
    "        \n",
    "#         self.conv5 = nn.Sequential(\n",
    "#             nn.Conv2d(d*8, d*16, 4, 2, 1),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.BatchNorm2d(d*16),\n",
    "#         ) # d*4 2 2\n",
    "        \n",
    "        \n",
    "#         self.output = nn.Sequential(\n",
    "#             nn.Conv2d(d*16, 1, 4, 2, 1),\n",
    "#             nn.Sigmoid(),\n",
    "#         ) # 1 1 1\n",
    "        \n",
    "#     def weight_init(self, mean, std):\n",
    "#         for m in self._modules:\n",
    "#             normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "#     def forward(self, x): # b 1 32 32\n",
    "\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.conv3(out)\n",
    "#         out = self.conv4(out)\n",
    "#         out = self.conv5(out)\n",
    "        \n",
    "#         out = self.output(out)\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_dim, d=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(inp_dim, d*32, 4, 2, 1),\n",
    "            nn.BatchNorm2d(d*32),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*16 2 2\n",
    "        \n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d*32, d*16, 4, 2, 1),\n",
    "            nn.BatchNorm2d(d*16),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*16 2 2\n",
    "        \n",
    "        self.deconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d*16, d*8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(d*8),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*16 4 4\n",
    "        \n",
    "        self.deconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d*8, d*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(d*4),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*4 8 8\n",
    "        \n",
    "        self.deconv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d*4, d*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(d*2),\n",
    "            nn.ReLU(True),\n",
    "        ) # b d*2 16 16\n",
    "        \n",
    "#         self.deconv6 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(d*2, d, 4, 2, 1),\n",
    "#             nn.BatchNorm2d(d),\n",
    "#             nn.ReLU(True),\n",
    "#         ) # b d 32 32\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d*2, 3, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        ) # b 3 64 64\n",
    "        \n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.deconv1(x)\n",
    "        out = self.deconv2(out)\n",
    "        out = self.deconv3(out)\n",
    "        out = self.deconv4(out)\n",
    "        out = self.deconv5(out)\n",
    "#         out = self.deconv6(out)\n",
    "\n",
    "        out = self.output(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, z_dimension, d=128):\n",
    "#         super(Generator, self).__init__()\n",
    "        \n",
    "#         self.upsample1 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(z_dimension, d*16, 4, 2, 1),\n",
    "#             nn.BatchNorm2d(d*16),\n",
    "#             nn.ReLU(True),\n",
    "#         ) # b d 2 2 \n",
    "        \n",
    "#         self.upsample2 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(d*16, d*8, 4, 2, 1),\n",
    "#             nn.BatchNorm2d(d*8),\n",
    "#             nn.ReLU(True),\n",
    "#         ) # b d*8 4 4\n",
    "        \n",
    "#         self.upsample3 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(d*8, d*4, 4, 2, 1),\n",
    "#             nn.BatchNorm2d(d*4),\n",
    "#             nn.ReLU(True),\n",
    "#         ) # b d*8 8 8\n",
    "        \n",
    "#         self.upsample4 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(d*4, d*2, 4, 2, 1),\n",
    "#             nn.BatchNorm2d(d*2),\n",
    "#             nn.ReLU(True),\n",
    "#         ) # b d*2 16 16\n",
    "        \n",
    "#         self.upsample5 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(d*2, d, 4, 2, 1),\n",
    "#             nn.BatchNorm2d(d),\n",
    "#             nn.ReLU(True),\n",
    "#         ) # b d 32 32\n",
    "        \n",
    "#         self.output = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(d, 3, 4, 2, 1),\n",
    "#             nn.Tanh(),\n",
    "#         ) # b 3 64 64\n",
    "        \n",
    "#     def weight_init(self, mean, std):\n",
    "#         for m in self._modules:\n",
    "#             normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "#     def forward(self, x): # b 100 1 1\n",
    "\n",
    "#         outs = self.upsample1(x)\n",
    "#         outs = self.upsample2(outs)\n",
    "#         outs = self.upsample3(outs)\n",
    "#         outs = self.upsample4(outs)\n",
    "#         outs = self.upsample5(outs)\n",
    "        \n",
    "#         outs = self.output(outs)\n",
    "\n",
    "#         return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator(d=64)#.cuda(device_ids[0])\n",
    "g = Generator(z_dimension, d=64)#.cuda(device_ids[0])\n",
    "\n",
    "d.weight_init(0.0, 0.02)\n",
    "g.weight_init(0.0, 0.02)\n",
    "\n",
    "d = nn.DataParallel(d, device_ids=device_ids).to(device)\n",
    "g = nn.DataParallel(g, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_optimezer = optim.Adam(d.parameters(), lr=2e-4)\n",
    "# d_optimezer = nn.DataParallel(d_optimezer, device_ids=device_ids)\n",
    "g_optimezer = optim.Adam(g.parameters(), lr=2e-4)\n",
    "# g_optimezer = nn.DataParallel(g_optimezer, device_ids=device_ids)\n",
    "\n",
    "# one = torch.FloatTensor([1])\n",
    "# mone = one * -1\n",
    "# one = one.to(device)\n",
    "# mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join('./log/cnn_wgan_gp_faces', str(now)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(\"save_images/cnn_wgan_gp_faces\", str(now))\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5c494efe1d4d7daeb4541cc9177dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step:  25600, d_loss: 2.867093, g_loss: -0.593351, real_scores: 0.249294, fake_scores: 0.593351, W: 0.344057\n",
      "Epoch [1/1000], Step:  51200, d_loss: 2.406201, g_loss: -0.576729, real_scores: 0.196455, fake_scores: 0.576729, W: 0.380273\n",
      "Epoch [1/1000], Step:  76800, d_loss: 2.476454, g_loss: -0.234531, real_scores: 0.166005, fake_scores: 0.234531, W: 0.068526\n",
      "Epoch [1/1000], Step: 102400, d_loss: 2.452682, g_loss: -0.469254, real_scores: 0.104390, fake_scores: 0.469254, W: 0.364864\n",
      "Finish Epoch [1/1000], D Loss: 590.254739, G Loss: -63.776675\n",
      "Epoch [2/1000], Step:  25600, d_loss: 2.169613, g_loss: -0.186922, real_scores: 0.136537, fake_scores: 0.186922, W: 0.050385\n",
      "Epoch [2/1000], Step:  51200, d_loss: 5.621141, g_loss: -0.408960, real_scores: 0.014727, fake_scores: 0.408960, W: 0.394233\n",
      "Epoch [2/1000], Step:  76800, d_loss: 2.888328, g_loss: -0.984035, real_scores: 0.474159, fake_scores: 0.984035, W: 0.509876\n",
      "Epoch [2/1000], Step: 102400, d_loss: 3.061282, g_loss: -0.996845, real_scores: 0.567719, fake_scores: 0.996845, W: 0.429126\n",
      "Finish Epoch [2/1000], D Loss: 262.755420, G Loss: -37.899806\n",
      "Epoch [3/1000], Step:  25600, d_loss: 2.667093, g_loss: -0.818716, real_scores: 0.854081, fake_scores: 0.818717, W: -0.035364\n",
      "Epoch [3/1000], Step:  51200, d_loss: 2.647092, g_loss: -0.726572, real_scores: 0.603632, fake_scores: 0.726572, W: 0.122940\n",
      "Epoch [3/1000], Step:  76800, d_loss: 5.875758, g_loss: -0.549848, real_scores: 0.201383, fake_scores: 0.549848, W: 0.348465\n",
      "Epoch [3/1000], Step: 102400, d_loss: 7.679658, g_loss: -0.552061, real_scores: 0.197581, fake_scores: 0.552061, W: 0.354480\n",
      "Finish Epoch [3/1000], D Loss: 168.111774, G Loss: -29.491941\n",
      "Epoch [4/1000], Step:  25600, d_loss: 3.205236, g_loss: -0.461253, real_scores: 0.155008, fake_scores: 0.461253, W: 0.306245\n",
      "Epoch [4/1000], Step:  51200, d_loss: 5.493463, g_loss: -0.387831, real_scores: 0.174794, fake_scores: 0.387831, W: 0.213038\n",
      "Epoch [4/1000], Step:  76800, d_loss: 8.571640, g_loss: -0.483406, real_scores: 0.156348, fake_scores: 0.483406, W: 0.327058\n",
      "Epoch [4/1000], Step: 102400, d_loss: 2.095114, g_loss: -0.411502, real_scores: 0.052280, fake_scores: 0.411502, W: 0.359222\n",
      "Finish Epoch [4/1000], D Loss: 152.532501, G Loss: -13.822956\n",
      "Epoch [5/1000], Step:  25600, d_loss: 3.306659, g_loss: -0.277023, real_scores: 0.130462, fake_scores: 0.277023, W: 0.146561\n",
      "Epoch [5/1000], Step:  51200, d_loss: 7.976671, g_loss: -0.709733, real_scores: 0.169480, fake_scores: 0.709733, W: 0.540252\n",
      "Epoch [5/1000], Step:  76800, d_loss: 2.279709, g_loss: -0.364284, real_scores: 0.261677, fake_scores: 0.364284, W: 0.102607\n",
      "Epoch [5/1000], Step: 102400, d_loss: 1.679485, g_loss: -0.393505, real_scores: 0.263046, fake_scores: 0.393505, W: 0.130458\n",
      "Finish Epoch [5/1000], D Loss: 83.234700, G Loss: -9.471964\n",
      "Epoch [6/1000], Step:  25600, d_loss: 3.112580, g_loss: -0.277639, real_scores: 0.056695, fake_scores: 0.277639, W: 0.220944\n",
      "Epoch [6/1000], Step:  51200, d_loss: 1.185722, g_loss: -0.357085, real_scores: 0.125791, fake_scores: 0.357085, W: 0.231294\n",
      "Epoch [6/1000], Step:  76800, d_loss: 3.801923, g_loss: -0.459975, real_scores: 0.223252, fake_scores: 0.459975, W: 0.236724\n",
      "Epoch [6/1000], Step: 102400, d_loss: 2.249820, g_loss: -0.508986, real_scores: 0.107769, fake_scores: 0.508986, W: 0.401217\n",
      "Finish Epoch [6/1000], D Loss: 62.029754, G Loss: -8.177385\n",
      "Epoch [7/1000], Step:  25600, d_loss: 2.218650, g_loss: -0.271286, real_scores: 0.144358, fake_scores: 0.271286, W: 0.126928\n",
      "Epoch [7/1000], Step:  51200, d_loss: 3.367088, g_loss: -0.419167, real_scores: 0.223673, fake_scores: 0.419167, W: 0.195494\n",
      "Epoch [7/1000], Step:  76800, d_loss: 1.242037, g_loss: -0.314745, real_scores: 0.164135, fake_scores: 0.314745, W: 0.150610\n",
      "Epoch [7/1000], Step: 102400, d_loss: 4.686213, g_loss: -0.391888, real_scores: 0.147116, fake_scores: 0.391888, W: 0.244773\n",
      "Finish Epoch [7/1000], D Loss: 53.481831, G Loss: -6.863018\n",
      "Epoch [8/1000], Step:  25600, d_loss: 0.958761, g_loss: -0.351975, real_scores: 0.119001, fake_scores: 0.351975, W: 0.232974\n",
      "Epoch [8/1000], Step:  51200, d_loss: 1.004957, g_loss: -0.387089, real_scores: 0.248114, fake_scores: 0.387089, W: 0.138976\n",
      "Epoch [8/1000], Step:  76800, d_loss: 2.480219, g_loss: -0.112776, real_scores: 0.022060, fake_scores: 0.112776, W: 0.090716\n",
      "Epoch [8/1000], Step: 102400, d_loss: 1.763736, g_loss: -0.443605, real_scores: 0.124561, fake_scores: 0.443605, W: 0.319044\n",
      "Finish Epoch [8/1000], D Loss: 49.364611, G Loss: -6.278904\n",
      "Epoch [9/1000], Step:  25600, d_loss: 4.083713, g_loss: -0.557694, real_scores: 0.146829, fake_scores: 0.557694, W: 0.410865\n",
      "Epoch [9/1000], Step:  51200, d_loss: 2.824445, g_loss: -0.384752, real_scores: 0.263236, fake_scores: 0.384752, W: 0.121516\n",
      "Epoch [9/1000], Step:  76800, d_loss: 3.685422, g_loss: -0.329840, real_scores: 0.314101, fake_scores: 0.329840, W: 0.015739\n",
      "Epoch [9/1000], Step: 102400, d_loss: 1.632957, g_loss: -0.294009, real_scores: 0.142157, fake_scores: 0.294009, W: 0.151852\n",
      "Finish Epoch [9/1000], D Loss: 39.594914, G Loss: -5.724576\n",
      "Epoch [10/1000], Step:  25600, d_loss: 0.992021, g_loss: -0.474641, real_scores: 0.242700, fake_scores: 0.474641, W: 0.231941\n",
      "Epoch [10/1000], Step:  51200, d_loss: 0.905190, g_loss: -0.418604, real_scores: 0.201930, fake_scores: 0.418604, W: 0.216674\n",
      "Epoch [10/1000], Step:  76800, d_loss: 0.823282, g_loss: -0.498071, real_scores: 0.277719, fake_scores: 0.498071, W: 0.220352\n",
      "Epoch [10/1000], Step: 102400, d_loss: 0.976585, g_loss: -0.357214, real_scores: 0.179600, fake_scores: 0.357214, W: 0.177614\n",
      "Finish Epoch [10/1000], D Loss: 15.306359, G Loss: -5.443380\n",
      "Epoch [11/1000], Step:  25600, d_loss: 0.550220, g_loss: -0.305241, real_scores: 0.175497, fake_scores: 0.305241, W: 0.129744\n",
      "Epoch [11/1000], Step:  51200, d_loss: 1.745908, g_loss: -0.577823, real_scores: 0.232554, fake_scores: 0.577823, W: 0.345269\n",
      "Epoch [11/1000], Step:  76800, d_loss: 0.828696, g_loss: -0.393936, real_scores: 0.324007, fake_scores: 0.393936, W: 0.069929\n",
      "Epoch [11/1000], Step: 102400, d_loss: 0.472255, g_loss: -0.370004, real_scores: 0.283897, fake_scores: 0.370004, W: 0.086107\n",
      "Finish Epoch [11/1000], D Loss: 11.388034, G Loss: -4.863860\n",
      "Epoch [12/1000], Step:  25600, d_loss: 0.551755, g_loss: -0.392667, real_scores: 0.343420, fake_scores: 0.392667, W: 0.049247\n",
      "Epoch [12/1000], Step:  51200, d_loss: 0.646832, g_loss: -0.440424, real_scores: 0.299196, fake_scores: 0.440424, W: 0.141228\n",
      "Epoch [12/1000], Step:  76800, d_loss: 0.322906, g_loss: -0.360963, real_scores: 0.233621, fake_scores: 0.360963, W: 0.127342\n",
      "Epoch [12/1000], Step: 102400, d_loss: 0.364496, g_loss: -0.420965, real_scores: 0.340329, fake_scores: 0.420965, W: 0.080635\n",
      "Finish Epoch [12/1000], D Loss: 7.766242, G Loss: -4.356189\n",
      "Epoch [13/1000], Step:  25600, d_loss: 2.601152, g_loss: -0.433677, real_scores: 0.193741, fake_scores: 0.433677, W: 0.239936\n",
      "Epoch [13/1000], Step:  51200, d_loss: 0.460526, g_loss: -0.300226, real_scores: 0.241252, fake_scores: 0.300226, W: 0.058975\n",
      "Epoch [13/1000], Step:  76800, d_loss: 0.422968, g_loss: -0.352032, real_scores: 0.217920, fake_scores: 0.352032, W: 0.134113\n",
      "Epoch [13/1000], Step: 102400, d_loss: 0.590116, g_loss: -0.373591, real_scores: 0.321435, fake_scores: 0.373591, W: 0.052156\n",
      "Finish Epoch [13/1000], D Loss: 5.961302, G Loss: -3.701545\n",
      "Epoch [14/1000], Step:  25600, d_loss: 0.276762, g_loss: -0.386955, real_scores: 0.392485, fake_scores: 0.386955, W: -0.005530\n",
      "Epoch [14/1000], Step:  51200, d_loss: 0.321740, g_loss: -0.247938, real_scores: 0.265316, fake_scores: 0.247938, W: -0.017378\n",
      "Epoch [14/1000], Step:  76800, d_loss: 0.255573, g_loss: -0.374354, real_scores: 0.401760, fake_scores: 0.374354, W: -0.027407\n",
      "Epoch [14/1000], Step: 102400, d_loss: 0.563515, g_loss: -0.242858, real_scores: 0.191159, fake_scores: 0.242858, W: 0.051699\n",
      "Finish Epoch [14/1000], D Loss: 4.692524, G Loss: -3.532081\n",
      "Epoch [15/1000], Step:  25600, d_loss: 0.551603, g_loss: -0.388035, real_scores: 0.253147, fake_scores: 0.388035, W: 0.134888\n",
      "Epoch [15/1000], Step:  51200, d_loss: 1.528059, g_loss: -0.252901, real_scores: 0.120895, fake_scores: 0.252901, W: 0.132006\n",
      "Epoch [15/1000], Step:  76800, d_loss: 8.030368, g_loss: -0.614018, real_scores: 0.387824, fake_scores: 0.614018, W: 0.226193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000], Step: 102400, d_loss: 1.765272, g_loss: -0.433336, real_scores: 0.375794, fake_scores: 0.433336, W: 0.057542\n",
      "Finish Epoch [15/1000], D Loss: 20.702914, G Loss: -3.597482\n",
      "Epoch [16/1000], Step:  25600, d_loss: 2.910476, g_loss: -0.522824, real_scores: 0.312776, fake_scores: 0.522824, W: 0.210048\n",
      "Epoch [16/1000], Step:  51200, d_loss: 1.244490, g_loss: -0.415155, real_scores: 0.207889, fake_scores: 0.415155, W: 0.207266\n",
      "Epoch [16/1000], Step:  76800, d_loss: 2.111396, g_loss: -0.435174, real_scores: 0.257718, fake_scores: 0.435174, W: 0.177456\n",
      "Epoch [16/1000], Step: 102400, d_loss: 1.097329, g_loss: -0.329194, real_scores: 0.197479, fake_scores: 0.329194, W: 0.131716\n",
      "Finish Epoch [16/1000], D Loss: 7.544042, G Loss: -3.017168\n",
      "Epoch [17/1000], Step:  25600, d_loss: 0.473427, g_loss: -0.544262, real_scores: 0.297366, fake_scores: 0.544262, W: 0.246896\n",
      "Epoch [17/1000], Step:  51200, d_loss: 0.271410, g_loss: -0.395777, real_scores: 0.403841, fake_scores: 0.395777, W: -0.008064\n",
      "Epoch [17/1000], Step:  76800, d_loss: 0.233539, g_loss: -0.389910, real_scores: 0.323494, fake_scores: 0.389910, W: 0.066416\n",
      "Epoch [17/1000], Step: 102400, d_loss: 0.397006, g_loss: -0.370034, real_scores: 0.248966, fake_scores: 0.370034, W: 0.121068\n",
      "Finish Epoch [17/1000], D Loss: 4.085077, G Loss: -3.145251\n",
      "Epoch [18/1000], Step:  25600, d_loss: 0.198790, g_loss: -0.331951, real_scores: 0.208763, fake_scores: 0.331951, W: 0.123188\n",
      "Epoch [18/1000], Step:  51200, d_loss: 0.241764, g_loss: -0.360210, real_scores: 0.297715, fake_scores: 0.360210, W: 0.062494\n",
      "Epoch [18/1000], Step:  76800, d_loss: 0.094409, g_loss: -0.255970, real_scores: 0.220745, fake_scores: 0.255970, W: 0.035224\n",
      "Epoch [18/1000], Step: 102400, d_loss: 0.178713, g_loss: -0.349979, real_scores: 0.300824, fake_scores: 0.349979, W: 0.049155\n",
      "Finish Epoch [18/1000], D Loss: 1.927951, G Loss: -2.361913\n",
      "Epoch [19/1000], Step:  25600, d_loss: 0.219645, g_loss: -0.279959, real_scores: 0.214981, fake_scores: 0.279959, W: 0.064978\n",
      "Epoch [19/1000], Step:  51200, d_loss: 0.061497, g_loss: -0.353404, real_scores: 0.360764, fake_scores: 0.353404, W: -0.007360\n",
      "Epoch [19/1000], Step:  76800, d_loss: 0.220875, g_loss: -0.346801, real_scores: 0.279541, fake_scores: 0.346801, W: 0.067260\n",
      "Epoch [19/1000], Step: 102400, d_loss: 0.128090, g_loss: -0.341910, real_scores: 0.329856, fake_scores: 0.341910, W: 0.012054\n",
      "Finish Epoch [19/1000], D Loss: 1.310902, G Loss: -2.124005\n",
      "Epoch [20/1000], Step:  25600, d_loss: 0.023573, g_loss: -0.246941, real_scores: 0.298835, fake_scores: 0.246941, W: -0.051894\n",
      "Epoch [20/1000], Step:  51200, d_loss: 0.079850, g_loss: -0.393580, real_scores: 0.391226, fake_scores: 0.393580, W: 0.002355\n",
      "Epoch [20/1000], Step:  76800, d_loss: 0.060817, g_loss: -0.365398, real_scores: 0.363279, fake_scores: 0.365398, W: 0.002119\n",
      "Epoch [20/1000], Step: 102400, d_loss: 0.059571, g_loss: -0.427672, real_scores: 0.425944, fake_scores: 0.427672, W: 0.001728\n",
      "Finish Epoch [20/1000], D Loss: 1.014760, G Loss: -2.370087\n",
      "Epoch [21/1000], Step:  25600, d_loss: 0.138123, g_loss: -0.329646, real_scores: 0.323995, fake_scores: 0.329646, W: 0.005651\n",
      "Epoch [21/1000], Step:  51200, d_loss: 0.056232, g_loss: -0.342190, real_scores: 0.382659, fake_scores: 0.342190, W: -0.040469\n",
      "Epoch [21/1000], Step:  76800, d_loss: 0.094834, g_loss: -0.364409, real_scores: 0.373185, fake_scores: 0.364409, W: -0.008776\n",
      "Epoch [21/1000], Step: 102400, d_loss: 0.043093, g_loss: -0.246311, real_scores: 0.318006, fake_scores: 0.246311, W: -0.071695\n",
      "Finish Epoch [21/1000], D Loss: 0.858948, G Loss: -2.020423\n",
      "Epoch [22/1000], Step:  25600, d_loss: 0.271232, g_loss: -0.434734, real_scores: 0.430432, fake_scores: 0.434734, W: 0.004302\n",
      "Epoch [22/1000], Step:  51200, d_loss: 0.316081, g_loss: -0.476515, real_scores: 0.363095, fake_scores: 0.476515, W: 0.113419\n",
      "Epoch [22/1000], Step:  76800, d_loss: 0.115381, g_loss: -0.421477, real_scores: 0.386998, fake_scores: 0.421477, W: 0.034479\n",
      "Epoch [22/1000], Step: 102400, d_loss: -0.005579, g_loss: -0.359908, real_scores: 0.418716, fake_scores: 0.359908, W: -0.058809\n",
      "Finish Epoch [22/1000], D Loss: 0.639633, G Loss: -2.041030\n",
      "Epoch [23/1000], Step:  25600, d_loss: 0.752695, g_loss: -0.549090, real_scores: 0.464219, fake_scores: 0.549090, W: 0.084871\n",
      "Epoch [23/1000], Step:  51200, d_loss: 0.956619, g_loss: -0.214944, real_scores: 0.234187, fake_scores: 0.214944, W: -0.019243\n",
      "Epoch [23/1000], Step:  76800, d_loss: 0.157491, g_loss: -0.385925, real_scores: 0.370617, fake_scores: 0.385925, W: 0.015308\n",
      "Epoch [23/1000], Step: 102400, d_loss: 0.109045, g_loss: -0.295486, real_scores: 0.317251, fake_scores: 0.295486, W: -0.021766\n",
      "Finish Epoch [23/1000], D Loss: 1.252277, G Loss: -1.860542\n",
      "Epoch [24/1000], Step:  25600, d_loss: 0.064745, g_loss: -0.285264, real_scores: 0.287186, fake_scores: 0.285264, W: -0.001922\n",
      "Epoch [24/1000], Step:  51200, d_loss: 0.014564, g_loss: -0.262531, real_scores: 0.337529, fake_scores: 0.262531, W: -0.074998\n",
      "Epoch [24/1000], Step:  76800, d_loss: 0.044089, g_loss: -0.309075, real_scores: 0.363864, fake_scores: 0.309075, W: -0.054789\n",
      "Epoch [24/1000], Step: 102400, d_loss: 0.055623, g_loss: -0.315342, real_scores: 0.363766, fake_scores: 0.315342, W: -0.048424\n",
      "Finish Epoch [24/1000], D Loss: 0.630227, G Loss: -1.669135\n",
      "Epoch [25/1000], Step:  25600, d_loss: -0.042326, g_loss: -0.231719, real_scores: 0.356400, fake_scores: 0.231719, W: -0.124681\n",
      "Epoch [25/1000], Step:  51200, d_loss: 0.073210, g_loss: -0.373747, real_scores: 0.390104, fake_scores: 0.373747, W: -0.016357\n",
      "Epoch [25/1000], Step:  76800, d_loss: 0.062380, g_loss: -0.365171, real_scores: 0.368928, fake_scores: 0.365171, W: -0.003757\n",
      "Epoch [25/1000], Step: 102400, d_loss: 0.067053, g_loss: -0.240351, real_scores: 0.325899, fake_scores: 0.240351, W: -0.085548\n",
      "Finish Epoch [25/1000], D Loss: 0.590640, G Loss: -1.738703\n",
      "Epoch [26/1000], Step:  25600, d_loss: -0.064771, g_loss: -0.229035, real_scores: 0.375926, fake_scores: 0.229035, W: -0.146890\n",
      "Epoch [26/1000], Step:  51200, d_loss: 0.061902, g_loss: -0.379796, real_scores: 0.394886, fake_scores: 0.379796, W: -0.015090\n",
      "Epoch [26/1000], Step:  76800, d_loss: 0.106351, g_loss: -0.316694, real_scores: 0.384952, fake_scores: 0.316694, W: -0.068258\n",
      "Epoch [26/1000], Step: 102400, d_loss: -0.042988, g_loss: -0.255769, real_scores: 0.362726, fake_scores: 0.255769, W: -0.106957\n",
      "Finish Epoch [26/1000], D Loss: 0.283106, G Loss: -1.680365\n",
      "Epoch [27/1000], Step:  25600, d_loss: -0.122531, g_loss: -0.303022, real_scores: 0.500962, fake_scores: 0.303022, W: -0.197940\n",
      "Epoch [27/1000], Step:  51200, d_loss: 0.053543, g_loss: -0.328672, real_scores: 0.381289, fake_scores: 0.328672, W: -0.052617\n",
      "Epoch [27/1000], Step:  76800, d_loss: 0.186108, g_loss: -0.375291, real_scores: 0.475912, fake_scores: 0.375291, W: -0.100621\n",
      "Epoch [27/1000], Step: 102400, d_loss: 0.115246, g_loss: -0.325341, real_scores: 0.312439, fake_scores: 0.325341, W: 0.012903\n",
      "Finish Epoch [27/1000], D Loss: 0.322301, G Loss: -1.682888\n",
      "Epoch [28/1000], Step:  25600, d_loss: 0.160080, g_loss: -0.247876, real_scores: 0.212462, fake_scores: 0.247876, W: 0.035415\n",
      "Epoch [28/1000], Step:  51200, d_loss: -0.098910, g_loss: -0.301587, real_scores: 0.481022, fake_scores: 0.301587, W: -0.179435\n",
      "Epoch [28/1000], Step:  76800, d_loss: 0.167479, g_loss: -0.526512, real_scores: 0.534368, fake_scores: 0.526512, W: -0.007856\n",
      "Epoch [28/1000], Step: 102400, d_loss: -0.043236, g_loss: -0.540652, real_scores: 0.693663, fake_scores: 0.540652, W: -0.153011\n",
      "Finish Epoch [28/1000], D Loss: 0.236280, G Loss: -1.823992\n",
      "Epoch [29/1000], Step:  25600, d_loss: 0.642973, g_loss: -0.333213, real_scores: 0.416159, fake_scores: 0.333213, W: -0.082946\n",
      "Epoch [29/1000], Step:  51200, d_loss: 0.096403, g_loss: -0.530301, real_scores: 0.559490, fake_scores: 0.530301, W: -0.029189\n",
      "Epoch [29/1000], Step:  76800, d_loss: 0.076620, g_loss: -0.475497, real_scores: 0.470790, fake_scores: 0.475497, W: 0.004708\n",
      "Epoch [29/1000], Step: 102400, d_loss: -0.019045, g_loss: -0.457684, real_scores: 0.533722, fake_scores: 0.457684, W: -0.076038\n",
      "Finish Epoch [29/1000], D Loss: 0.354907, G Loss: -2.127981\n",
      "Epoch [30/1000], Step:  25600, d_loss: -0.089730, g_loss: -0.393424, real_scores: 0.562782, fake_scores: 0.393424, W: -0.169357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/1000], Step:  51200, d_loss: -0.146049, g_loss: -0.323078, real_scores: 0.536036, fake_scores: 0.323078, W: -0.212957\n",
      "Epoch [30/1000], Step:  76800, d_loss: 0.215865, g_loss: -0.405306, real_scores: 0.388321, fake_scores: 0.405306, W: 0.016985\n",
      "Epoch [30/1000], Step: 102400, d_loss: -0.006345, g_loss: -0.425302, real_scores: 0.617292, fake_scores: 0.425302, W: -0.191990\n",
      "Finish Epoch [30/1000], D Loss: 0.100050, G Loss: -1.600790\n",
      "Epoch [31/1000], Step:  25600, d_loss: -0.042016, g_loss: -0.365759, real_scores: 0.519796, fake_scores: 0.365759, W: -0.154038\n",
      "Epoch [31/1000], Step:  51200, d_loss: 0.101848, g_loss: -0.438727, real_scores: 0.574701, fake_scores: 0.438727, W: -0.135975\n",
      "Epoch [31/1000], Step:  76800, d_loss: 0.684580, g_loss: -0.210469, real_scores: 0.291605, fake_scores: 0.210469, W: -0.081136\n",
      "Epoch [31/1000], Step: 102400, d_loss: -0.158750, g_loss: -0.424362, real_scores: 0.666478, fake_scores: 0.424362, W: -0.242116\n",
      "Finish Epoch [31/1000], D Loss: -0.038106, G Loss: -1.618078\n",
      "Epoch [32/1000], Step:  25600, d_loss: -0.192429, g_loss: -0.178070, real_scores: 0.481414, fake_scores: 0.178070, W: -0.303344\n",
      "Epoch [32/1000], Step:  51200, d_loss: -0.128587, g_loss: -0.377298, real_scores: 0.605574, fake_scores: 0.377298, W: -0.228275\n",
      "Epoch [32/1000], Step:  76800, d_loss: 0.050593, g_loss: -0.353075, real_scores: 0.543947, fake_scores: 0.353075, W: -0.190872\n",
      "Epoch [32/1000], Step: 102400, d_loss: -0.118756, g_loss: -0.384950, real_scores: 0.624383, fake_scores: 0.384950, W: -0.239433\n",
      "Finish Epoch [32/1000], D Loss: 0.006000, G Loss: -1.555697\n",
      "Epoch [33/1000], Step:  25600, d_loss: 0.111905, g_loss: -0.388570, real_scores: 0.470080, fake_scores: 0.388570, W: -0.081511\n",
      "Epoch [33/1000], Step:  51200, d_loss: -0.055501, g_loss: -0.429802, real_scores: 0.538483, fake_scores: 0.429802, W: -0.108681\n",
      "Epoch [33/1000], Step:  76800, d_loss: -0.133202, g_loss: -0.331884, real_scores: 0.526363, fake_scores: 0.331884, W: -0.194479\n",
      "Epoch [33/1000], Step: 102400, d_loss: 0.085837, g_loss: -0.577540, real_scores: 0.612366, fake_scores: 0.577540, W: -0.034826\n",
      "Finish Epoch [33/1000], D Loss: 0.081207, G Loss: -1.549923\n",
      "Epoch [34/1000], Step:  25600, d_loss: 0.176019, g_loss: -0.422642, real_scores: 0.570349, fake_scores: 0.422642, W: -0.147707\n",
      "Epoch [34/1000], Step:  51200, d_loss: -0.231779, g_loss: -0.349568, real_scores: 0.636975, fake_scores: 0.349568, W: -0.287407\n",
      "Epoch [34/1000], Step:  76800, d_loss: -0.024604, g_loss: -0.202694, real_scores: 0.354921, fake_scores: 0.202694, W: -0.152227\n",
      "Epoch [34/1000], Step: 102400, d_loss: -0.037591, g_loss: -0.520752, real_scores: 0.611083, fake_scores: 0.520752, W: -0.090330\n",
      "Finish Epoch [34/1000], D Loss: -0.048843, G Loss: -1.579488\n",
      "Epoch [35/1000], Step:  25600, d_loss: 0.082375, g_loss: -0.734719, real_scores: 0.700329, fake_scores: 0.734719, W: 0.034390\n",
      "Epoch [35/1000], Step:  51200, d_loss: -0.223063, g_loss: -0.412166, real_scores: 0.719774, fake_scores: 0.412166, W: -0.307608\n",
      "Epoch [35/1000], Step:  76800, d_loss: 0.001554, g_loss: -0.308807, real_scores: 0.454064, fake_scores: 0.308807, W: -0.145257\n",
      "Epoch [35/1000], Step: 102400, d_loss: -0.082938, g_loss: -0.323265, real_scores: 0.469627, fake_scores: 0.323265, W: -0.146363\n",
      "Finish Epoch [35/1000], D Loss: -0.118926, G Loss: -1.460993\n",
      "Epoch [36/1000], Step:  25600, d_loss: -0.013409, g_loss: -0.251439, real_scores: 0.354157, fake_scores: 0.251438, W: -0.102719\n",
      "Epoch [36/1000], Step:  51200, d_loss: -0.038021, g_loss: -0.524542, real_scores: 0.755164, fake_scores: 0.524542, W: -0.230622\n",
      "Epoch [36/1000], Step:  76800, d_loss: -0.155193, g_loss: -0.271036, real_scores: 0.488083, fake_scores: 0.271036, W: -0.217048\n",
      "Epoch [36/1000], Step: 102400, d_loss: -0.105338, g_loss: -0.370918, real_scores: 0.565066, fake_scores: 0.370918, W: -0.194148\n",
      "Finish Epoch [36/1000], D Loss: -0.128920, G Loss: -1.298389\n",
      "Epoch [37/1000], Step:  25600, d_loss: 0.082234, g_loss: -0.543649, real_scores: 0.543111, fake_scores: 0.543649, W: 0.000538\n",
      "Epoch [37/1000], Step:  51200, d_loss: -0.258880, g_loss: -0.315855, real_scores: 0.653814, fake_scores: 0.315855, W: -0.337959\n",
      "Epoch [37/1000], Step:  76800, d_loss: -0.077166, g_loss: -0.330270, real_scores: 0.466837, fake_scores: 0.330270, W: -0.136567\n",
      "Epoch [37/1000], Step: 102400, d_loss: -0.284059, g_loss: -0.337255, real_scores: 0.703054, fake_scores: 0.337255, W: -0.365799\n",
      "Finish Epoch [37/1000], D Loss: -0.031177, G Loss: -1.294657\n",
      "Epoch [38/1000], Step:  25600, d_loss: -0.234041, g_loss: -0.204031, real_scores: 0.532410, fake_scores: 0.204031, W: -0.328379\n",
      "Epoch [38/1000], Step:  51200, d_loss: -0.085398, g_loss: -0.387983, real_scores: 0.532679, fake_scores: 0.387983, W: -0.144696\n",
      "Epoch [38/1000], Step:  76800, d_loss: -0.131878, g_loss: -0.502294, real_scores: 0.781445, fake_scores: 0.502294, W: -0.279151\n",
      "Epoch [38/1000], Step: 102400, d_loss: -0.131069, g_loss: -0.277689, real_scores: 0.549381, fake_scores: 0.277689, W: -0.271692\n",
      "Finish Epoch [38/1000], D Loss: -0.085247, G Loss: -1.304058\n",
      "Epoch [39/1000], Step:  25600, d_loss: 0.113306, g_loss: -0.631591, real_scores: 0.838340, fake_scores: 0.631591, W: -0.206749\n",
      "Epoch [39/1000], Step:  51200, d_loss: 0.071344, g_loss: -0.582339, real_scores: 0.615261, fake_scores: 0.582339, W: -0.032922\n",
      "Epoch [39/1000], Step:  76800, d_loss: -0.268853, g_loss: -0.352947, real_scores: 0.715820, fake_scores: 0.352947, W: -0.362873\n",
      "Epoch [39/1000], Step: 102400, d_loss: -0.080047, g_loss: -0.420712, real_scores: 0.540879, fake_scores: 0.420712, W: -0.120167\n",
      "Finish Epoch [39/1000], D Loss: -0.135197, G Loss: -1.427105\n",
      "Epoch [40/1000], Step:  25600, d_loss: -0.045228, g_loss: -0.455722, real_scores: 0.563439, fake_scores: 0.455722, W: -0.107717\n",
      "Epoch [40/1000], Step:  51200, d_loss: -0.087949, g_loss: -0.573575, real_scores: 0.718701, fake_scores: 0.573575, W: -0.145125\n",
      "Epoch [40/1000], Step:  76800, d_loss: -0.179136, g_loss: -0.264850, real_scores: 0.510753, fake_scores: 0.264850, W: -0.245902\n",
      "Epoch [40/1000], Step: 102400, d_loss: 0.034023, g_loss: -0.289172, real_scores: 0.444210, fake_scores: 0.289172, W: -0.155038\n",
      "Finish Epoch [40/1000], D Loss: -0.222625, G Loss: -1.311840\n",
      "Epoch [41/1000], Step:  25600, d_loss: -0.025442, g_loss: -0.491445, real_scores: 0.568202, fake_scores: 0.491445, W: -0.076757\n",
      "Epoch [41/1000], Step:  51200, d_loss: 0.038507, g_loss: -0.394079, real_scores: 0.412162, fake_scores: 0.394079, W: -0.018082\n",
      "Epoch [41/1000], Step:  76800, d_loss: -0.000266, g_loss: -0.365562, real_scores: 0.442477, fake_scores: 0.365562, W: -0.076915\n",
      "Epoch [41/1000], Step: 102400, d_loss: -0.471680, g_loss: -0.131735, real_scores: 0.676027, fake_scores: 0.131735, W: -0.544292\n",
      "Finish Epoch [41/1000], D Loss: -0.180303, G Loss: -1.267341\n",
      "Epoch [42/1000], Step:  25600, d_loss: -0.303356, g_loss: -0.309923, real_scores: 0.678884, fake_scores: 0.309923, W: -0.368961\n",
      "Epoch [42/1000], Step:  51200, d_loss: 0.180359, g_loss: -0.658433, real_scores: 0.620678, fake_scores: 0.658433, W: 0.037754\n",
      "Epoch [42/1000], Step:  76800, d_loss: -0.072889, g_loss: -0.540582, real_scores: 0.673959, fake_scores: 0.540582, W: -0.133377\n",
      "Epoch [42/1000], Step: 102400, d_loss: -0.341013, g_loss: -0.369435, real_scores: 0.797427, fake_scores: 0.369435, W: -0.427992\n",
      "Finish Epoch [42/1000], D Loss: -0.125659, G Loss: -1.212666\n",
      "Epoch [43/1000], Step:  25600, d_loss: -0.188877, g_loss: -0.286061, real_scores: 0.535818, fake_scores: 0.286061, W: -0.249757\n",
      "Epoch [43/1000], Step:  51200, d_loss: 0.062054, g_loss: -0.380456, real_scores: 0.403226, fake_scores: 0.380456, W: -0.022770\n",
      "Epoch [43/1000], Step:  76800, d_loss: -0.031835, g_loss: -0.269773, real_scores: 0.352613, fake_scores: 0.269773, W: -0.082840\n",
      "Epoch [43/1000], Step: 102400, d_loss: 0.105157, g_loss: -0.307711, real_scores: 0.607563, fake_scores: 0.307711, W: -0.299852\n",
      "Finish Epoch [43/1000], D Loss: -0.042086, G Loss: -1.138050\n",
      "Epoch [44/1000], Step:  25600, d_loss: -0.177133, g_loss: -0.414046, real_scores: 0.726204, fake_scores: 0.414045, W: -0.312159\n",
      "Epoch [44/1000], Step:  51200, d_loss: -0.089051, g_loss: -0.586969, real_scores: 0.805192, fake_scores: 0.586969, W: -0.218223\n",
      "Epoch [44/1000], Step:  76800, d_loss: -0.207143, g_loss: -0.448350, real_scores: 0.789505, fake_scores: 0.448350, W: -0.341155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/1000], Step: 102400, d_loss: 0.042218, g_loss: -0.364858, real_scores: 0.662431, fake_scores: 0.364857, W: -0.297573\n",
      "Finish Epoch [44/1000], D Loss: -0.170685, G Loss: -1.215265\n",
      "Epoch [45/1000], Step:  25600, d_loss: -0.065854, g_loss: -0.157492, real_scores: 0.328739, fake_scores: 0.157492, W: -0.171247\n",
      "Epoch [45/1000], Step:  51200, d_loss: -0.105051, g_loss: -0.341810, real_scores: 0.512028, fake_scores: 0.341810, W: -0.170218\n",
      "Epoch [45/1000], Step:  76800, d_loss: 0.544959, g_loss: -0.496788, real_scores: 0.751535, fake_scores: 0.496788, W: -0.254747\n",
      "Epoch [45/1000], Step: 102400, d_loss: 0.167446, g_loss: -0.244480, real_scores: 0.478204, fake_scores: 0.244480, W: -0.233724\n",
      "Finish Epoch [45/1000], D Loss: -0.105724, G Loss: -1.157293\n",
      "Epoch [46/1000], Step:  25600, d_loss: -0.292613, g_loss: -0.492281, real_scores: 0.826865, fake_scores: 0.492281, W: -0.334584\n",
      "Epoch [46/1000], Step:  51200, d_loss: -0.017016, g_loss: -0.272439, real_scores: 0.381614, fake_scores: 0.272439, W: -0.109175\n",
      "Epoch [46/1000], Step:  76800, d_loss: -0.160180, g_loss: -0.222005, real_scores: 0.779142, fake_scores: 0.222005, W: -0.557137\n",
      "Epoch [46/1000], Step: 102400, d_loss: -0.166763, g_loss: -0.398935, real_scores: 0.625555, fake_scores: 0.398935, W: -0.226620\n",
      "Finish Epoch [46/1000], D Loss: -0.110138, G Loss: -1.135463\n",
      "Epoch [47/1000], Step:  25600, d_loss: -0.044069, g_loss: -0.497194, real_scores: 0.583071, fake_scores: 0.497194, W: -0.085877\n",
      "Epoch [47/1000], Step:  51200, d_loss: -0.103827, g_loss: -0.546094, real_scores: 0.704169, fake_scores: 0.546094, W: -0.158075\n",
      "Epoch [47/1000], Step:  76800, d_loss: 0.138995, g_loss: -0.505047, real_scores: 0.493732, fake_scores: 0.505047, W: 0.011315\n",
      "Epoch [47/1000], Step: 102400, d_loss: -0.113643, g_loss: -0.594827, real_scores: 0.831192, fake_scores: 0.594827, W: -0.236366\n",
      "Finish Epoch [47/1000], D Loss: -0.213371, G Loss: -1.198504\n",
      "Epoch [48/1000], Step:  25600, d_loss: 0.004879, g_loss: -0.464727, real_scores: 0.609005, fake_scores: 0.464727, W: -0.144278\n",
      "Epoch [48/1000], Step:  51200, d_loss: -0.319792, g_loss: -0.311883, real_scores: 0.683451, fake_scores: 0.311883, W: -0.371567\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    _step = epoch * total_count\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        z = torch.randn(img.size(0), z_dimension, 1, 1).cuda()\n",
    "        \n",
    "#         real_labels = torch.ones(img.size(0), 1).cuda()\n",
    "#         fake_labels = torch.zeros(img.size(0), 1).cuda()\n",
    "        \n",
    "        real_labels = torch.from_numpy(np.random.normal(.95, .02, [img.size(0), 1])).float().to(device)\n",
    "        fake_labels = torch.from_numpy(np.random.normal(.05, .02, [img.size(0), 1])).float().to(device)\n",
    "        \n",
    "#         ################### G ###################\n",
    "        fake_img = g(z)\n",
    "        fake_out = d(fake_img)\n",
    "        \n",
    "        g_loss = -fake_out.mean()\n",
    "        \n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "#         #########################################\n",
    "        \n",
    "#         ################### D ###################\n",
    "        real_out = d(real_img)\n",
    "        d_loss_real = real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_out = d(fake_img.detach())\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(d, real_img, fake_img)\n",
    "        \n",
    "        d_loss = d_loss_fake - d_loss_real + gradient_penalty\n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "#         #########################################\n",
    "\n",
    "        ################### G ###################\n",
    "#         fake_img = g(z)\n",
    "#         fake_out = d(fake_img)\n",
    "#         g_loss = criterion(fake_out, real_labels)\n",
    "        \n",
    "#         g_optimezer.zero_grad()\n",
    "#         g_loss.backward()\n",
    "#         g_optimezer.step()\n",
    "        #########################################\n",
    "        \n",
    "        ################### D ###################\n",
    "#         real_out = d(real_img)\n",
    "#         d_loss_real = criterion(real_out, real_labels)\n",
    "#         real_scores = real_out\n",
    "        \n",
    "#         fake_out = d(fake_img.detach())\n",
    "#         d_loss_fake = criterion(fake_out, fake_labels)\n",
    "#         fake_scores = fake_out\n",
    "        \n",
    "#         d_loss = d_loss_real + d_loss_fake\n",
    "#         d_optimezer.zero_grad()\n",
    "#         d_loss.backward()\n",
    "#         d_optimezer.step()\n",
    "        #########################################\n",
    "        \n",
    "        w_dist = d_loss_fake - d_loss_real\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 200 == 0:\n",
    "            tqdm.write('Epoch [{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}, real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}, W: {:.6f}'.format(epoch+1, num_epochs, (i+1) * batch_size, d_loss, g_loss, real_scores.mean(), fake_scores.mean(), w_dist))\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            fake_images = fake_img.view(-1, 3, wh, wh)[:8].cpu().data\n",
    "            save_image(fake_images, os.path.join(img_path, 'fake_images_{:04d}_{:06d}.png'.format(epoch + 1, i + 1)))\n",
    "        \n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 3, wh, wh).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "\n",
    "    fake_images = fake_img.view(-1, 3, wh, wh).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{:03d}.png'.format(epoch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-722b0a94f886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./ser/cnn_wgan_gp_faces_discriminator_1117.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./ser/cnn_wgan_gp_faces_generator_1117.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(d.state_dict(), './ser/cnn_wgan_gp_faces_discriminator.pkl')\n",
    "torch.save(g.state_dict(), './ser/cnn_wgan_gp_faces_generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.load_state_dict(torch.load('./ser/cnn_wgan_gp_faces_discriminator.pt'))\n",
    "g.load_state_dict(torch.load('./ser/cnn_wgan_gp_faces_generator.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(4, z_dimension).to(device)\n",
    "images = g(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv36",
   "language": "python",
   "name": "venv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
